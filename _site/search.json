[
  {
    "objectID": "license.html",
    "href": "license.html",
    "title": "LICENSE: CC-BY",
    "section": "",
    "text": "My blog posts are released under a Creative Commons Attribution 4.0 International (CC BY 4.0) license.\n\n\n\nCode associated with the blog and repository are released under the MIT license."
  },
  {
    "objectID": "talks/index.html",
    "href": "talks/index.html",
    "title": "Talks",
    "section": "",
    "text": "Suggestions for successful scRNA-seq analysis\n\n\n\n\n\n\nsingle-cell\n\n\nrna-seq\n\n\nanalysis\n\n\nbest practices\n\n\n\nPresentation at the 9th German Pharm-Tox Summit on planning a successful scRNA-seq experiment from the analysts perspective\n\n\n\n\n\nMar 13, 2024\n\n\n\n\n\n\n\nSuccessful scRNA-seq analysis\n\n\n\n\n\n\nsingle-cell\n\n\nrna-seq\n\n\nanalysis\n\n\nbest practices\n\n\n\nPresentation at the ILC Summer School 2022 on planning a successful scRNA-seq experiment\n\n\n\n\n\nJun 30, 2022\n\n\n\n\n\n\n\nInteroperability between Bioconductor and Python for scRNA-seq analysis\n\n\n\n\n\n\nsingle-cell\n\n\nrna-seq\n\n\nsoftware\n\n\ninteroperability\n\n\nR\n\n\npython\n\n\nBioconductor\n\n\n\nInvited keynote at the European Bioconductor meeting 2020\n\n\n\n\n\nDec 18, 2020\n\n\n\n\n\n\n\nTools and techniques for single-cell RNA sequencing data\n\n\n\n\n\n\nsingle-cell\n\n\nrna-seq\n\n\nsimulation\n\n\ndatabase\n\n\nvisualisation\n\n\nkidney\n\n\norganoids\n\n\nanalysis\n\n\nsoftware\n\n\nsplatter\n\n\nclustree\n\n\nscRNA-tools\n\n\nPhD\n\n\n\nMy PhD completion seminar\n\n\n\n\n\nMar 22, 2019\n\n\n\n\n\n\n\nTools, simulations and trees for scRNA-seq\n\n\n\n\n\n\nsingle-cell\n\n\nrna-seq\n\n\nsimulation\n\n\ndatabase\n\n\nvisualisation\n\n\nsplatter\n\n\nclustree\n\n\nscrna-tools\n\n\nsoftware\n\n\nkidney\n\n\norganoids\n\n\nanalysis\n\n\nPhD\n\n\n\nPresentation at the Institute of Computational Biology where I described my PhD projects\n\n\n\n\n\nSep 27, 2018\n\n\n\n\n\n\n\nUsing clustering trees to visualise scRNA-seq data\n\n\n\n\n\n\nsingle-cell\n\n\nrna-seq\n\n\nclustering\n\n\nvisualisation\n\n\nsoftware\n\n\nclustree\n\n\nR\n\n\nCRAN\n\n\n\nSelected talk at the Genome Informatics 2018 conference where I described how clustering trees can be used with scRNA-seq data\n\n\n\n\n\nSep 17, 2018\n\n\n\n\n\n\n\nclustree: producing clustering trees using ggraph\n\n\n\n\n\n\nvisualisation\n\n\nsoftware\n\n\nR\n\n\n\nPresentation at the userR! 2018 conference introducing the clustree package and demonstrating how it makes use of the ggraph package\n\n\n\n\n\nJul 21, 2018\n\n\n\n\n\n\n\nClustering trees for visualising scRNA-seq data\n\n\n\n\n\n\nvisualisation\n\n\nclustering\n\n\nsoftware\n\n\nclustree\n\n\nR\n\n\nCRAN\n\n\n\nSelected talk at the Oz Single Cells 2018 conference where I presented clustering trees and the clustree package\n\n\n\n\n\nJul 16, 2018\n\n\n\n\n\n\n\nSplatter, a package for simulating single-cell RNA sequencing data\n\n\n\n\n\n\nsingle-cell\n\n\nRNA-seq\n\n\nsimulation\n\n\nsoftware\n\n\nsplatter\n\n\nR\n\n\nbioconductor\n\n\n\nSelected talk at the 2017 Bioconductor Asia Meeting where I presented technical details of the Splatter package\n\n\n\n\n\nNov 17, 2017\n\n\n\n\n\n\n\nSimulation and analysis tools for single-cell RNA sequencing data\n\n\n\n\n\n\nsingle-cell\n\n\nrna-seq\n\n\nsimulation\n\n\ndatabase\n\n\nsplatter\n\n\nscRNA-tools\n\n\nsoftware\n\n\n\nSelected talk at the Genome Informatics 2017 conference describing Splatter and the scRNA-tools database\n\n\n\n\n\nNov 1, 2017\n\n\n\n\n\n\n\nSingle cells, simulation and kidneys in a dish\n\n\n\n\n\n\nsingle-cell\n\n\nrna-seq\n\n\nsimulation\n\n\nkidney\n\n\norganoids\n\n\nvisualisation\n\n\nscrna-tools\n\n\ndatabase\n\n\nsplatter\n\n\n\nPresentation at the Berkeley Statistics and Genomics Seminar describing my PhD projects\n\n\n\n\n\nOct 27, 2017\n\n\n\n\n\n\n\nBuilding a clustering tree\n\n\n\n\n\n\nvisualisation\n\n\nclustering\n\n\n\nJoining the Dots Visualisation Symposium talk describing the clustering tree visualisation algorithm\n\n\n\n\n\nAug 18, 2017\n\n\n\n\n\n\n\nSingle-cells, simulation and kidneys in a dish\n\n\n\n\n\n\nsingle-cell\n\n\nrna-seq\n\n\nsimulation\n\n\nvisualisation\n\n\ndatabase\n\n\norganoids\n\n\nkidney\n\n\nsoftware\n\n\nsplatter\n\n\nscRNA-tools\n\n\nR\n\n\nPhD\n\n\n\nWEHI Bioinformatics seminar series presenting my PhD projects\n\n\n\n\n\nJul 17, 2017\n\n\n\n\n\n\n\nSimplifying simulation of single-cell RNA-seq\n\n\n\n\n\n\nsingle-cell\n\n\nrna-seq\n\n\nsimulation\n\n\nsoftware\n\n\nsplatter\n\n\nR\n\n\n\nPresentation at the 2016 COMBINE student symposium introducing the Splatter package and the Splat scRNA-seq simulation model\n\n\n\n\n\nOct 31, 2016\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "projects/tidydirectory/index.html",
    "href": "projects/tidydirectory/index.html",
    "title": "tidydirectory",
    "section": "",
    "text": "tidydirectory is a Python script for tidying directories which I wrote for automatically sorting my downloads folder. It checks the date that files in a directory were created or last accessed and moves old files to an archive directory. Separately, old files in the archive are deleted.\nFiles in the archive are organised based on a custom mapping between file extensions and categories, for example to move all .R, .py and .sh files to a code directory.\nAvailable from my GitHub https://github.com/lazappi/tidydirectory."
  },
  {
    "objectID": "projects/r-pkg-dev/index.html",
    "href": "projects/r-pkg-dev/index.html",
    "title": "R Package Development Workshop",
    "section": "",
    "text": "COMBINE is an Australian organisation for student in bioinformatics, computational biology and related fields. One way in which COMBINE aims to support the student community is by providing training. I was the lead author on the materials for this workshop which covers an introduction to developing an R package and were produced using bookdown. The workshop was first run in Melbourne in September 2019 where I was the lead instructor."
  },
  {
    "objectID": "projects/doilinker/index.html",
    "href": "projects/doilinker/index.html",
    "title": "doilinker",
    "section": "",
    "text": "{doilinker} allows you to link related DOIs. Usually this is to find the published version of a preprint (or the reverse) It does this by querying the Crossref database using {rcrossref} and matching DOIs using the method described by Cabanac, Oikonomidi and Boutron."
  },
  {
    "objectID": "projects/scanpy-in-R/index.html",
    "href": "projects/scanpy-in-R/index.html",
    "title": "Scanpy in R",
    "section": "",
    "text": "This tutorial covers how to set up a environment that lets you interact with Scanpy from R. This includes converting Python AnnData objects to R SingleCellExperiment and Seurat objects as well as interacting with a Python environment directly in an R Markdown document. It demonstrates some of the functions in Scanpy but doesn‚Äôt cover everything the package can do or how best to use Scanpy for your analysis."
  },
  {
    "objectID": "projects/clamour/index.html",
    "href": "projects/clamour/index.html",
    "title": "clamour",
    "section": "",
    "text": "The {clamour} packages provides a template for setting up a website to display the results of analysis of Twitter hashtags, usually associated with an event such as an academic conference. More details can be found on the project website (https://lazappi.github.io/clamour/index.html). There is also an example website showing what the results look like (https://lazappi.github.io/clamour-example/) or you can have a look at my personal Twitter stats site (https://lazappi.github.io/twitter-stats/)."
  },
  {
    "objectID": "projects/prettytc/index.html",
    "href": "projects/prettytc/index.html",
    "title": "prettytc",
    "section": "",
    "text": "TeXcount is excellent and by far the best way to produce wordcounts of LaTeX documents but I found the output became hard to read for large documents.\nprettytc is a Python script that runs TeXcount and parses the output in a way that shows more of the document structure and provides totals at each level. It can be run from the command line and any options are passed to TeXcount.\nAvailable from my GitHub https://github.com/lazappi/prettytc."
  },
  {
    "objectID": "projects/twitter-stats/index.html",
    "href": "projects/twitter-stats/index.html",
    "title": "Twitter stats",
    "section": "",
    "text": "Website displaying analysis of Twitter activity from various event hashtags, usually academic conferences (https://lazappi.github.io/twitter-stats/index.html). Includes information such as when people were tweeting, who there were connected to and the most common topics during the event."
  },
  {
    "objectID": "projects/scRNA-tools/index.html",
    "href": "projects/scRNA-tools/index.html",
    "title": "scRNA-tools",
    "section": "",
    "text": "The scRNA-tools database and website (https://www.scRNA-tools.org) is a catalogue of software tools for the analysis of single-cell RNA sequencing data. We record details about what the tools can be used as well as where they are available and any associated publications. This is designed to be an open resource and we welcome submissions and other contributions from the community."
  },
  {
    "objectID": "projects/oecd-housing/index.html",
    "href": "projects/oecd-housing/index.html",
    "title": "OECD housing",
    "section": "",
    "text": "A short analysis of housing data from the Organisation for Economic Co-operation and Development (OECD). I looked at two aspects, the cost and affordability of housing and the amount of taxation associated with it. I was interested both in how this aspects have changed in different countries over time but also how they relate to each other. For example it could be that countries with higher rates of housing taxation have lower housing costs (because taxation increases the cost of purchasing a house) or that that countries with higher tax rates are encouraged to increase the cost of housing in order to generate more tax revenue. I highlighted a few countries of interest that stand out in the dataset, specifically New Zealand, Canada, Sweden and Japan. The analysis was performed in Python with the final analysis displayed in a Quarto document."
  },
  {
    "objectID": "publications/2021-zappia-1000-tools/index.html",
    "href": "publications/2021-zappia-1000-tools/index.html",
    "title": "Over 1000 tools reveal trends in the single-cell RNA-seq analysis landscape",
    "section": "",
    "text": "CitationBibTeX citation:@article{zappia2021,\n  author = {Zappia, Luke and J Theis, Fabian},\n  title = {Over 1000 Tools Reveal Trends in the Single-Cell {RNA-seq}\n    Analysis Landscape},\n  journal = {Genome biology},\n  volume = {22},\n  number = {1},\n  pages = {301},\n  date = {2021-10-29},\n  url = {https://lazappi.id.au/publications/2021-zappia-1000-tools/},\n  doi = {10.1186/s13059-021-02519-4},\n  issn = {1465-6906},\n  langid = {en},\n  abstract = {Recent years have seen a revolution in single-cell\n    RNA-sequencing (scRNA-seq) technologies, datasets, and analysis\n    methods. Since 2016, the scRNA-tools database has cataloged software\n    tools for analyzing scRNA-seq data. With the number of tools in the\n    database passing 1000, we provide an update on the state of the\n    project and the field. This data shows the evolution of the field\n    and a change of focus from ordering cells on continuous trajectories\n    to integrating multiple samples and making use of reference\n    datasets. We also find that open science practices reward developers\n    with increased recognition and help accelerate the field.}\n}\nFor attribution, please cite this work as:\nZappia, Luke, and Fabian J Theis. 2021. ‚ÄúOver 1000 Tools Reveal\nTrends in the Single-Cell RNA-Seq Analysis Landscape.‚Äù Genome\nBiology 22 (1): 301. https://doi.org/10.1186/s13059-021-02519-4."
  },
  {
    "objectID": "publications/2023-hrovatin-MIA/index.html",
    "href": "publications/2023-hrovatin-MIA/index.html",
    "title": "Delineating mouse Œ≤-cell identity during lifetime and in diabetes with a single cell atlas",
    "section": "",
    "text": "CitationBibTeX citation:@article{hrovatin2023,\n  author = {Hrovatin, Karin and Bastidas-Ponce, Aim√©e and Bakhti,\n    Mostafa and Zappia, Luke and B√ºttner, Maren and Sallino, Ciro and\n    Sterr, Michael and B√∂ttcher, Anika and Migliorini, Adriana and\n    Lickert, Heiko and J Theis, Fabian},\n  title = {Delineating Mouse Œ≤-Cell Identity During Lifetime and in\n    Diabetes with a Single Cell Atlas},\n  journal = {Nature Metabolism},\n  volume = {5},\n  number = {1},\n  pages = {1615-1637},\n  date = {2023-09-11},\n  url = {https://lazappi.id.au/publications/2023-hrovatin-MIA/},\n  doi = {10.1038/s42255-023-00876-x},\n  issn = {2522-5812},\n  langid = {en},\n  abstract = {Although multiple pancreatic islet single-cell\n    RNA-sequencing (scRNA-seq) datasets have been generated, a consensus\n    on pancreatic cell states in development, homeostasis and diabetes\n    as well as the value of preclinical animal models is missing. Here,\n    we present an scRNA-seq cross-condition mouse islet atlas (MIA), a\n    curated resource for interactive exploration and computational\n    querying. We integrate over 300,000 cells from nine scRNA-seq\n    datasets consisting of 56 samples, varying in age, sex and diabetes\n    models, including an autoimmune type 1 diabetes model (NOD), a\n    glucotoxicity/lipotoxicity type 2 diabetes model (db/db) and a\n    chemical streptozotocin Œ≤-cell ablation model. The Œ≤-cell landscape\n    of MIA reveals new cell states during disease progression and\n    cross-publication differences between previously suggested marker\n    genes. We show that Œ≤-cells in the streptozotocin model\n    transcriptionally correlate with those in human type 2 diabetes and\n    mouse db/db models, but are less similar to human type 1 diabetes\n    and mouse NOD Œ≤-cells. We also report pathways that are shared\n    between Œ≤-cells in immature, aged and diabetes models. MIA enables a\n    comprehensive analysis of Œ≤-cell responses to different stressors,\n    providing a roadmap for the understanding of Œ≤-cell plasticity,\n    compensation and demise.}\n}\nFor attribution, please cite this work as:\nHrovatin, Karin, Aim√©e Bastidas-Ponce, Mostafa Bakhti, Luke Zappia,\nMaren B√ºttner, Ciro Sallino, Michael Sterr, et al. 2023.\n‚ÄúDelineating Mouse Œ≤-Cell Identity During Lifetime and in Diabetes\nwith a Single Cell Atlas.‚Äù Nature Metabolism 5 (9):\n1615‚Äì37. https://doi.org/10.1038/s42255-023-00876-x."
  },
  {
    "objectID": "publications/2024-huemos-ehrapy/index.html",
    "href": "publications/2024-huemos-ehrapy/index.html",
    "title": "An open-source framework for end-to-end analysis of electronic health record data",
    "section": "",
    "text": "CitationBibTeX citation:@article{heumos2024,\n  author = {Heumos, Lukas and Ehmele, Philipp and Treis, Tim and Upmeier\n    zu Belzen, Julius and Roellin, Eljas and May, Lilly and Namsaraeva,\n    Altana and Horlava, Nastassya and A. Shitov, Vladimir and Zhang,\n    Xinyue and Zappia, Luke and Knoll, Rainer and J. Lang, Niklas and\n    Hetzel, Leon and Virshup, Isaac and Sikkema, Lisa and Curion,\n    Fabiola and Eils, Roland and B. Schiller, Herbert and Hilgendorff,\n    Anne and J. Theis, Fabian},\n  title = {An Open-Source Framework for End-to-End Analysis of\n    Electronic Health Record Data},\n  journal = {Nature Medicine},\n  pages = {1-12},\n  date = {2024-09-12},\n  url = {https://lazappi.id.au/publications/2024-huemos-ehrapy/},\n  doi = {10.1038/s41591-024-03214-0},\n  issn = {1078-8956},\n  langid = {en},\n  abstract = {With progressive digitalization of healthcare systems\n    worldwide, large-scale collection of electronic health records\n    (EHRs) has become commonplace. However, an extensible framework for\n    comprehensive exploratory analysis that accounts for data\n    heterogeneity is missing. Here we introduce ehrapy, a modular\n    open-source Python framework designed for exploratory analysis of\n    heterogeneous epidemiology and EHR data. ehrapy incorporates a\n    series of analytical steps, from data extraction and quality control\n    to the generation of low-dimensional representations. Complemented\n    by rich statistical modules, ehrapy facilitates associating patients\n    with disease states, differential comparison between patient\n    clusters, survival analysis, trajectory inference, causal inference\n    and more. Leveraging ontologies, ehrapy further enables data sharing\n    and training EHR deep learning models, paving the way for\n    foundational models in biomedical research. We demonstrate ehrapy‚Äôs\n    features in six distinct examples. We applied ehrapy to stratify\n    patients affected by unspecified pneumonia into finer-grained\n    phenotypes. Furthermore, we reveal biomarkers for significant\n    differences in survival among these groups. Additionally, we\n    quantify medication-class effects of pneumonia medications on length\n    of stay We further leveraged ehrapy to analyze cardiovascular risks\n    across different data modalities. We reconstructed disease state\n    trajectories in patients with severe acute respiratory syndrome\n    coronavirus 2 (SARS-CoV-2) based on imaging data. Finally, we\n    conducted a case study to demonstrate how ehrapy can detect and\n    mitigate biases in EHR data. ehrapy, thus, provides a framework that\n    we envision will standardize analysis pipelines on EHR data and\n    serve as a cornerstone for the community.}\n}\nFor attribution, please cite this work as:\nHeumos, Lukas, Philipp Ehmele, Tim Treis, Julius Upmeier zu Belzen,\nEljas Roellin, Lilly May, Altana Namsaraeva, et al. 2024. ‚ÄúAn\nOpen-Source Framework for End-to-End Analysis of Electronic Health\nRecord Data.‚Äù Nature Medicine, September, 1‚Äì12. https://doi.org/10.1038/s41591-024-03214-0."
  },
  {
    "objectID": "publications/2019-combes-kidney-organoids/index.html",
    "href": "publications/2019-combes-kidney-organoids/index.html",
    "title": "Single-cell analysis reveals congruence between kidney organoids and human fetal kidney",
    "section": "",
    "text": "CitationBibTeX citation:@article{n_combes2019,\n  author = {N Combes, Alexander and Zappia, Luke and Xuan Er, Pei and\n    Oshlack, Alicia and H Little, Melissa},\n  title = {Single-Cell Analysis Reveals Congruence Between Kidney\n    Organoids and Human Fetal Kidney},\n  journal = {Genome medicine},\n  volume = {11},\n  number = {1},\n  pages = {3},\n  date = {2019-01-01},\n  url = {https://lazappi.id.au/publications/2019-combes-kidney-organoids/},\n  doi = {10.1186/s13073-019-0615-0},\n  issn = {1756-994X},\n  langid = {en},\n  abstract = {**Background** Human kidney organoids hold promise for\n    studying development, disease modelling and drug screening. However,\n    the utility of stem cell-derived kidney tissues will depend on how\n    faithfully these replicate normal fetal development at the level of\n    cellular identity and complexity. **Methods** Here, we present an\n    integrated analysis of single cell datasets from human kidney\n    organoids and human fetal kidney to assess similarities and\n    differences between the component cell types. **Results** Clusters\n    in the combined dataset contained cells from both organoid and fetal\n    kidney with transcriptional congruence for key stromal, endothelial\n    and nephron cell type-specific markers. Organoid enriched neural,\n    glial and muscle progenitor populations were also evident. Major\n    transcriptional differences between organoid and human tissue were\n    likely related to technical artefacts. Cell type-specific\n    comparisons revealed differences in stromal, endothelial and nephron\n    progenitor cell types including expression of WNT2B in the human\n    fetal kidney stroma. **Conclusions** This study supports the\n    fidelity of kidney organoids as models of the developing kidney and\n    affirms their potential in disease modelling and drug screening.}\n}\nFor attribution, please cite this work as:\nN Combes, Alexander, Luke Zappia, Pei Xuan Er, Alicia Oshlack, and\nMelissa H Little. 2019. ‚ÄúSingle-Cell Analysis Reveals Congruence\nBetween Kidney Organoids and Human Fetal Kidney.‚Äù Genome\nMedicine 11 (January): 3. https://doi.org/10.1186/s13073-019-0615-0."
  },
  {
    "objectID": "publications/2017-phipson-gene-length/index.html",
    "href": "publications/2017-phipson-gene-length/index.html",
    "title": "Gene length and detection bias in single cell RNA sequencing protocols",
    "section": "",
    "text": "CitationBibTeX citation:@article{phipson2017,\n  author = {Phipson, Belinda and Zappia, Luke and Oshlack, Alicia},\n  title = {Gene Length and Detection Bias in Single Cell {RNA}\n    Sequencing Protocols},\n  journal = {F1000Research},\n  volume = {6},\n  date = {2017-04-01},\n  url = {https://lazappi.id.au/publications/2017-phipson-gene-length/},\n  doi = {10.12688/f1000research.11290.1},\n  langid = {en},\n  abstract = {**Background** Single cell RNA sequencing (scRNA-seq) has\n    rapidly gained popularity for profiling transcriptomes of hundreds\n    to thousands of single cells. This technology has led to the\n    discovery of novel cell types and revealed insights into the\n    development of complex tissues. However, many technical challenges\n    need to be overcome during data generation. Due to minute amounts of\n    starting material, samples undergo extensive amplification,\n    increasing technical variability. A solution for mitigating\n    amplification biases is to include unique molecular identifiers\n    (UMIs), which tag individual molecules. Transcript abundances are\n    then estimated from the number of unique UMIs aligning to a specific\n    gene, with PCR duplicates resulting in copies of the UMI not\n    included in expression estimates. **Methods** Here we investigate\n    the effect of gene length bias in scRNA-Seq across a variety of\n    datasets that differ in terms of capture technology, library\n    preparation, cell types and species. **Results** We find that\n    scRNA-seq datasets that have been sequenced using a full-length\n    transcript protocol exhibit gene length bias akin to bulk RNA-seq\n    data. Specifically, shorter genes tend to have lower counts and a\n    higher rate of dropout. In contrast, protocols that include UMIs do\n    not exhibit gene length bias, with a mostly uniform rate of dropout\n    across genes of varying length. Across four different scRNA-Seq\n    datasets profiling mouse embryonic stem cells (mESCs), we found the\n    subset of genes that are only detected in the UMI datasets tended to\n    be shorter, while the subset of genes detected only in the\n    full-length datasets tended to be longer. **Conclusions** We find\n    that the choice of scRNA-seq protocol influences the detection rate\n    of genes, and that full-length datasets exhibit gene-length bias. In\n    addition, despite clear differences between UMI and full-length\n    transcript data, we illustrate that full-length and UMI data can be\n    combined to reveal the underlying biology influencing expression of\n    mESCs.}\n}\nFor attribution, please cite this work as:\nPhipson, Belinda, Luke Zappia, and Alicia Oshlack. 2017. ‚ÄúGene\nLength and Detection Bias in Single Cell RNA Sequencing\nProtocols.‚Äù F1000Research 6 (April). https://doi.org/10.12688/f1000research.11290.1."
  },
  {
    "objectID": "publications/2019-kumar-micro-organoids/index.html",
    "href": "publications/2019-kumar-micro-organoids/index.html",
    "title": "Kidney micro-organoids in suspension culture as a scalable source of human pluripotent stem cell-derived kidney cells",
    "section": "",
    "text": "CitationBibTeX citation:@article{v_kumar2019,\n  author = {V Kumar, Santhosh and X Er, Pei and T Lawlor, Kynan and\n    Motazedian, Ali and Scurr, Michelle and Ghobrial, Irene and N\n    Combes, Alexander and Zappia, Luke and Oshlack, Alicia and G\n    Stanley, Edouard and H Little, Melissa},\n  title = {Kidney Micro-Organoids in Suspension Culture as a Scalable\n    Source of Human Pluripotent Stem Cell-Derived Kidney Cells},\n  journal = {Development},\n  volume = {146},\n  number = {5},\n  date = {2019-03-01},\n  url = {https://lazappi.id.au/publications/2019-kumar-micro-organoids/},\n  doi = {10.1242/dev.172361},\n  issn = {0950-1991, 1477-9129},\n  langid = {en},\n  abstract = {Kidney organoids have potential uses in disease modelling,\n    drug screening and regenerative medicine. However, novel\n    cost-effective techniques are needed to enable scaled-up production\n    of kidney cell types in vitro. We describe here a modified\n    suspension culture method for the generation of kidney\n    micro-organoids from human pluripotent stem cells. Optimisation of\n    differentiation conditions allowed the formation of micro-organoids,\n    each containing six to ten nephrons that were surrounded by\n    endothelial and stromal populations. Single cell transcriptional\n    profiling confirmed the presence and transcriptional equivalence of\n    all anticipated renal cell types consistent with a previous organoid\n    culture method. This suspension culture micro-organoid methodology\n    resulted in a three- to fourfold increase in final cell yield\n    compared with static culture, thereby representing an economical\n    approach to the production of kidney cells for various biological\n    applications.}\n}\nFor attribution, please cite this work as:\nV Kumar, Santhosh, Pei X Er, Kynan T Lawlor, Ali Motazedian, Michelle\nScurr, Irene Ghobrial, Alexander N Combes, et al. 2019. ‚ÄúKidney\nMicro-Organoids in Suspension Culture as a Scalable Source of Human\nPluripotent Stem Cell-Derived Kidney Cells.‚Äù Development\n146 (March). https://doi.org/10.1242/dev.172361."
  },
  {
    "objectID": "publications/2021-azodi-splatPop/index.html",
    "href": "publications/2021-azodi-splatPop/index.html",
    "title": "splatPop: simulating population scale single-cell RNA sequencing data",
    "section": "",
    "text": "CitationBibTeX citation:@article{b_azodi2021,\n  author = {B Azodi, Christina and Zappia, Luke and Oshlack, Alicia and\n    J McCarthy, Davis},\n  title = {splatPop: Simulating Population Scale Single-Cell {RNA}\n    Sequencing Data},\n  journal = {Genome biology},\n  volume = {22},\n  number = {1},\n  pages = {341},\n  date = {2021-12-15},\n  url = {https://lazappi.id.au/publications/2021-azodi-splatPop/},\n  doi = {10.1186/s13059-021-02546-1},\n  issn = {1465-6906},\n  langid = {en},\n  abstract = {Population-scale single-cell RNA sequencing (scRNA-seq) is\n    now viable, enabling finer resolution functional genomics studies\n    and leading to a rush to adapt bulk methods and develop new\n    single-cell-specific methods to perform these studies. Simulations\n    are useful for developing, testing, and benchmarking methods but\n    current scRNA-seq simulation frameworks do not simulate\n    population-scale data with genetic effects. Here, we present\n    splatPop, a model for flexible, reproducible, and well-documented\n    simulation of population-scale scRNA-seq data with known expression\n    quantitative trait loci. splatPop can also simulate complex batch,\n    cell group, and conditional effects between individuals from\n    different cohorts as well as genetically-driven co-expression.}\n}\nFor attribution, please cite this work as:\nB Azodi, Christina, Luke Zappia, Alicia Oshlack, and Davis J McCarthy.\n2021. ‚ÄúsplatPop: Simulating Population Scale Single-Cell RNA\nSequencing Data.‚Äù Genome Biology 22 (1): 341. https://doi.org/10.1186/s13059-021-02546-1."
  },
  {
    "objectID": "publications/2016-grillet-colorectal-CTCs/index.html",
    "href": "publications/2016-grillet-colorectal-CTCs/index.html",
    "title": "Circulating tumour cells from patients with colorectal cancer have cancer stem cell hallmarks in ex vivo culture",
    "section": "",
    "text": "CitationBibTeX citation:@article{grillet2016,\n  author = {Grillet, Fanny and Bayet, Elsa and Villeronce, Olivia and\n    Zappia, Luke and Louise Lagerqvist, Ebba and Lunke, Sebastian and\n    Charafe-Jauffret, Emmanuelle and Pham, Kym and Molck, Christina and\n    Rolland, Nathalie and Fran√ßois Bourgaux, Jean and Prudhomme, Michel\n    and Philippe, Claire and Bravo, Sophie and Christophe Boyer, Jean\n    and Canterel-Thouennon, Lucile and Roy Taylor, Graham and Hsu,\n    Arthur and Marc Pascussi, Jean and Hollande, Fr√©d√©ric and Pannequin,\n    Julie},\n  title = {Circulating Tumour Cells from Patients with Colorectal Cancer\n    Have Cancer Stem Cell Hallmarks in Ex Vivo Culture},\n  journal = {Gut},\n  date = {2016-07-01},\n  url = {https://lazappi.id.au/publications/2016-grillet-colorectal-CTCs/},\n  doi = {10.1136/gutjnl-2016-311447},\n  issn = {0017-5749, 1468-3288},\n  langid = {en},\n  abstract = {**Objective** Although counting of circulating tumour\n    cells (CTC) has attracted a broad interest as potential markers of\n    tumour progression and treatment response, the lack of functional\n    characterisation of these cells had become a bottleneck in taking\n    these observations to the clinic. Our objective was to culture these\n    cells in order to understand them and exploit their therapeutic\n    potential to the full. **Design** Here, hypothesising that some CTC\n    potentially have cancer stem cell (CSC) phenotype, we generated\n    several CTC lines from the blood of patients with advanced\n    metastatic colorectal cancer (CRC) based on their self-renewal\n    abilities. Multiple standard tests were then employed to\n    characterise these cells. **Results** Our CTC lines self-renew,\n    express CSC markers and have multilineage differentiation ability,\n    both in vitro and in vivo. Patient-derived CTC lines are tumorigenic\n    in subcutaneous xenografts and are also able to colonise the liver\n    after intrasplenic injection. RNA sequencing analyses strikingly\n    demonstrate that drug metabolising pathways represent the most\n    upregulated feature among CTC lines in comparison with primary CRC\n    cells grown under similar conditions. This result is corroborated by\n    the high resistance of the CTC lines to conventional cytotoxic\n    compounds. **Conclusions** Taken together, our results directly\n    demonstrate the existence of patient-derived colorectal CTCs that\n    bear all the functional attributes of CSCs. The CTC culture model\n    described here is simple and takes \\textless1 month from blood\n    collection to drug testing, therefore, routine clinical application\n    could facilitate access to personalised medicine.}\n}\nFor attribution, please cite this work as:\nGrillet, Fanny, Elsa Bayet, Olivia Villeronce, Luke Zappia, Ebba Louise\nLagerqvist, Sebastian Lunke, Emmanuelle Charafe-Jauffret, et al. 2016.\n‚ÄúCirculating Tumour Cells from Patients with Colorectal Cancer\nHave Cancer Stem Cell Hallmarks in Ex Vivo Culture.‚Äù\nGut, July. https://doi.org/10.1136/gutjnl-2016-311447."
  },
  {
    "objectID": "publications/2023-heumos-best-practices/index.html",
    "href": "publications/2023-heumos-best-practices/index.html",
    "title": "Best practices for single-cell analysis across modalities",
    "section": "",
    "text": "CitationBibTeX citation:@article{heumos2023,\n  author = {Heumos, Lukas and C. Schaar, Anna and Lance, Christopher and\n    Litinetskaya, Anastasia and Drost, Felix and Zappia, Luke and D.\n    L√ºcken, Malte and C. Strobl, Daniel and Henao, Juan and Curion,\n    Fabiola and Best Practices Consortium, Single-cell and B. Schiller,\n    Herbert and J. Theis, Fabian},\n  title = {Best Practices for Single-Cell Analysis Across Modalities},\n  journal = {Nature reviews genetics},\n  pages = {1-23},\n  date = {2023-03-31},\n  url = {https://lazappi.id.au/publications/2023-heumos-best-practices/},\n  doi = {10.1038/s41576-023-00586-w},\n  issn = {1471-0056},\n  langid = {en},\n  abstract = {Recent advances in single-cell technologies have enabled\n    high-throughput molecular profiling of cells across modalities and\n    locations. Single-cell transcriptomics data can now be complemented\n    by chromatin accessibility, surface protein expression, adaptive\n    immune receptor repertoire profiling and spatial information. The\n    increasing availability of single-cell data across modalities has\n    motivated the development of novel computational methods to help\n    analysts derive biological insights. As the field grows, it becomes\n    increasingly difficult to navigate the vast landscape of tools and\n    analysis steps. Here, we summarize independent benchmarking studies\n    of unimodal and multimodal single-cell analysis across modalities to\n    suggest comprehensive best-practice workflows for the most common\n    analysis steps. Where independent benchmarks are not available, we\n    review and contrast popular methods. Our article serves as an entry\n    point for novices in the field of single-cell (multi-)omic analysis\n    and guides advanced users to the most recent best practices.}\n}\nFor attribution, please cite this work as:\nHeumos, Lukas, Anna C. Schaar, Christopher Lance, Anastasia\nLitinetskaya, Felix Drost, Luke Zappia, Malte D. L√ºcken, et al. 2023.\n‚ÄúBest Practices for Single-Cell Analysis Across\nModalities.‚Äù Nature Reviews Genetics, March, 1‚Äì23. https://doi.org/10.1038/s41576-023-00586-w."
  },
  {
    "objectID": "publications/2020-amarasinghe-long-read-tools/index.html",
    "href": "publications/2020-amarasinghe-long-read-tools/index.html",
    "title": "Opportunities and challenges in long-read sequencing data analysis",
    "section": "",
    "text": "CitationBibTeX citation:@article{l_amarasinghe2020,\n  author = {L Amarasinghe, Shanika and Su, Shian and Dong, Xueyi and\n    Zappia, Luke and E Ritchie, Matthew and Gouil, Quentin},\n  title = {Opportunities and Challenges in Long-Read Sequencing Data\n    Analysis},\n  journal = {Genome biology},\n  volume = {21},\n  number = {1},\n  pages = {30},\n  date = {2020-02-01},\n  url = {https://lazappi.id.au/publications/2020-amarasinghe-long-read-tools/},\n  doi = {10.1186/s13059-020-1935-5},\n  issn = {1465-6906},\n  langid = {en},\n  abstract = {Long-read technologies are overcoming early limitations in\n    accuracy and throughput, broadening their application domains in\n    genomics. Dedicated analysis tools that take into account the\n    characteristics of long-read data are thus required, but the fast\n    pace of development of such tools can be overwhelming. To assist in\n    the design and analysis of long-read sequencing projects, we review\n    the current landscape of available tools and present an online\n    interactive database, long-read-tools.org, to facilitate their\n    browsing. We further focus on the principles of error correction,\n    base modification detection, and long-read transcriptomics analysis\n    and highlight the challenges that remain.}\n}\nFor attribution, please cite this work as:\nL Amarasinghe, Shanika, Shian Su, Xueyi Dong, Luke Zappia, Matthew E\nRitchie, and Quentin Gouil. 2020. ‚ÄúOpportunities and Challenges in\nLong-Read Sequencing Data Analysis.‚Äù Genome Biology 21\n(February): 30. https://doi.org/10.1186/s13059-020-1935-5."
  },
  {
    "objectID": "publications/2023-ji-distance-metrics/index.html",
    "href": "publications/2023-ji-distance-metrics/index.html",
    "title": "Optimal distance metrics for single-cell RNA-seq populations",
    "section": "",
    "text": "CitationBibTeX citation:@misc{ji2023,\n  author = {Ji, Yuge and D. Green, Tessa and Peidli, Stefan and Bahrami,\n    Mojtaba and Liu,, Meiqi and Zappia, Luke and Hrovatin, Karin and\n    Sander, Chris and J. Theis, Fabian},\n  title = {Optimal Distance Metrics for Single-Cell {RNA-seq}\n    Populations},\n  date = {2023-12-26},\n  url = {https://lazappi.id.au/publications/2023-ji-distance-metrics/},\n  doi = {10.1101/2023.12.26.572833},\n  langid = {en},\n  abstract = {In single-cell data workflows and modeling, distance\n    metrics are commonly used in loss functions, model evaluation, and\n    subpopulation analysis. However, these metrics behave differently\n    depending on the source of variation, conditions and subpopulations\n    in single-cell expression profiles due to data sparsity and high\n    dimensionality. Thus, the metrics used for downstream tasks in this\n    domain should be carefully selected. We establish a set of\n    benchmarks with three evaluation measures, capturing desirable\n    facets of absolute and relative distance behavior. Based on seven\n    datasets using perturbation as ground truth, we evaluated 16\n    distance metrics applied to scRNA-seq data and demonstrated their\n    application to three use cases. We find that linear metrics such as\n    mean squared error (MSE) performed best across our three evaluation\n    criteria. Therefore, we recommend the use of MSE for comparing\n    single-cell RNA-seq populations and evaluating gene expression\n    prediction models.}\n}\nFor attribution, please cite this work as:\nJi, Yuge, Tessa D. Green, Stefan Peidli, Mojtaba Bahrami, Meiqi Liu,\nLuke Zappia, Karin Hrovatin, Chris Sander, and Fabian J. Theis. 2023.\n‚ÄúOptimal Distance Metrics for Single-Cell RNA-Seq\nPopulations.‚Äù bioRxiv. https://doi.org/10.1101/2023.12.26.572833."
  },
  {
    "objectID": "publications/2018-zappia-scRNAtools/index.html",
    "href": "publications/2018-zappia-scRNAtools/index.html",
    "title": "Exploring the single-cell RNA-seq analysis landscape with the scRNA-tools database",
    "section": "",
    "text": "CitationBibTeX citation:@article{zappia2018,\n  author = {Zappia, Luke and Phipson, Belinda and Oshlack, Alicia},\n  title = {Exploring the Single-Cell {RNA-seq} Analysis Landscape with\n    the {scRNA-tools} Database},\n  journal = {PLoS computational biology},\n  volume = {14},\n  number = {6},\n  pages = {e1006245},\n  date = {2018-06-01},\n  url = {https://lazappi.id.au/publications/2018-zappia-scRNAtools/},\n  doi = {10.1371/journal.pcbi.1006245},\n  issn = {1553-734X, 1553-7358},\n  langid = {en},\n  abstract = {As single-cell RNA-sequencing (scRNA-seq) datasets have\n    become more widespread the number of tools designed to analyse these\n    data has dramatically increased. Navigating the vast sea of tools\n    now available is becoming increasingly challenging for researchers.\n    In order to better facilitate selection of appropriate analysis\n    tools we have created the scRNA-tools database (www.scRNA-tools.org)\n    to catalogue and curate analysis tools as they become available. Our\n    database collects a range of information on each scRNA-seq analysis\n    tool and categorises them according to the analysis tasks they\n    perform. Exploration of this database gives insights into the areas\n    of rapid development of analysis methods for scRNA-seq data. We see\n    that many tools perform tasks specific to scRNA-seq analysis,\n    particularly clustering and ordering of cells. We also find that the\n    scRNA-seq community embraces an open-source and open-science\n    approach, with most tools available under open-source licenses and\n    preprints being extensively used as a means to describe methods. The\n    scRNA-tools database provides a valuable resource for researchers\n    embarking on scRNA-seq analysis and records the growth of the field\n    over time.}\n}\nFor attribution, please cite this work as:\nZappia, Luke, Belinda Phipson, and Alicia Oshlack. 2018.\n‚ÄúExploring the Single-Cell RNA-Seq Analysis Landscape with the\nscRNA-Tools Database.‚Äù PLoS Computational Biology 14\n(June): e1006245. https://doi.org/10.1371/journal.pcbi.1006245."
  },
  {
    "objectID": "publications/2021-luecken-scIB/index.html",
    "href": "publications/2021-luecken-scIB/index.html",
    "title": "Benchmarking atlas-level data integration in single-cell genomics",
    "section": "",
    "text": "CitationBibTeX citation:@article{d_luecken2021,\n  author = {D Luecken, Malte and B√ºttner, Maren and Chaichoompu,\n    Kridsadakorn and Danese, Anna and Interlandi, Marta and F Mueller,\n    Michaela and C Strobl, Daniel and Zappia, Luke and Dugas, Martin and\n    Colom√©-Tatch√©, Maria and J Theis, Fabian},\n  title = {Benchmarking Atlas-Level Data Integration in Single-Cell\n    Genomics},\n  journal = {Nature methods},\n  date = {2021-12-23},\n  url = {https://lazappi.id.au/publications/2021-luecken-scIB/},\n  doi = {10.1038/s41592-021-01336-8},\n  issn = {1548-7091},\n  langid = {en},\n  abstract = {Single-cell atlases often include samples that span\n    locations, laboratories and conditions, leading to complex, nested\n    batch effects in data. Thus, joint analysis of atlas datasets\n    requires reliable data integration. To guide integration method\n    choice, we benchmarked 68 method and preprocessing combinations on\n    85 batches of gene expression, chromatin accessibility and\n    simulation data from 23 publications, altogether representing\n    \\textgreater1.2 million cells distributed in 13 atlas-level\n    integration tasks. We evaluated methods according to scalability,\n    usability and their ability to remove batch effects while retaining\n    biological variation using 14 evaluation metrics. We show that\n    highly variable gene selection improves the performance of data\n    integration methods, whereas scaling pushes methods to prioritize\n    batch removal over conservation of biological variation. Overall,\n    scANVI, Scanorama, scVI and scGen perform well, particularly on\n    complex integration tasks, while single-cell ATAC-sequencing\n    integration performance is strongly affected by choice of feature\n    space. Our freely available Python module and benchmarking pipeline\n    can identify optimal data integration methods for new data,\n    benchmark new methods and improve method development.}\n}\nFor attribution, please cite this work as:\nD Luecken, Malte, Maren B√ºttner, Kridsadakorn Chaichoompu, Anna Danese,\nMarta Interlandi, Michaela F Mueller, Daniel C Strobl, et al. 2021.\n‚ÄúBenchmarking Atlas-Level Data Integration in Single-Cell\nGenomics.‚Äù Nature Methods, December. https://doi.org/10.1038/s41592-021-01336-8."
  },
  {
    "objectID": "posts/2016-03-30-extracting-alignment-statistics-using-python/index.html",
    "href": "posts/2016-03-30-extracting-alignment-statistics-using-python/index.html",
    "title": "Extracting alignment statistics using Python",
    "section": "",
    "text": "Recently this paper by Ilicic et al.¬†suggested a method for assessing the quality of individual cells in a single-cell RNA-seq experiment. The basic idea is to extract various biological and technical features from each the reads for each cell, then use PCA with outlier detection or a SVM to classify cells as ‚Äúhigh‚Äù or ‚Äúlow‚Äù quality. There are two pieces of software associated with the paper: cellity, an R package that performs the classification and Celloline, a Python script that performs alignment, summarisation and extraction of alignment statistics such as the number of reads aligned to exons, introns, intergenic regions etc. I was interested in using cellity but I didn‚Äôt want to change my whole workflow to use the Celloline pipeline, so instead I decided to take the part responsible for extracting alignment statistics (available here) and convert it to a stand-alone Python script.\nThe core processing remains the same (except I have removed read counting which I do with featureCounts), but I have added a few features:\n\nMultiple files - paths to multiple alignment files can now be provided as arguments on the command line.\nBAM files - the script can now handle BAM files as well as SAM using pysam. It will work if the BAM is unsorted, but the output can be slightly different.\nIndex - reading the GTF annotation file can take a significant amount of time, particularly for a single-cell experiment where there are a large number of files with relatively few reads. To limit this overhead the object holding the annotation can be pickled to disk for future use.\nParallel - multiple files can now be processed in parallel using joblib. This is fairly crude but it is a significant improvment, particularly when combined with a pickled index.\nArgument handling - now performed by argparse, complete with handy help message.\nLogging - progress and error messages.\n\nPutting it all together I can now extract alignment statistics from multiple BAM files in parallel with a single command:\nalignStats -o stats.csv -g annotation.gtf -i annotation.index -t bam -p 10 *.bam\nThe script is available on Github."
  },
  {
    "objectID": "posts/2024-03-04-scRNAtools-low-maintenance/index.html",
    "href": "posts/2024-03-04-scRNAtools-low-maintenance/index.html",
    "title": "scRNA-tools low-maintenance mode",
    "section": "",
    "text": "You are probably here because you have seen or heard that the scRNA-tools database will be entering low-maintenance mode. This post explains a bit more about what that means and some of the motivation behind the decision."
  },
  {
    "objectID": "posts/2024-03-04-scRNAtools-low-maintenance/index.html#hang-on-whats-scrna-tools",
    "href": "posts/2024-03-04-scRNAtools-low-maintenance/index.html#hang-on-whats-scrna-tools",
    "title": "scRNA-tools low-maintenance mode",
    "section": "Hang on, what‚Äôs scRNA-tools?",
    "text": "Hang on, what‚Äôs scRNA-tools?\nscRNA-tools is a database that catalogues software tools for analysing scRNA-seq data which I created during my PhD and have curated and maintained ever since. You can read more about it on the project page, in the original paper and in our analysis of the first 1000 tools in the database."
  },
  {
    "objectID": "posts/2024-03-04-scRNAtools-low-maintenance/index.html#so-whats-happening",
    "href": "posts/2024-03-04-scRNAtools-low-maintenance/index.html#so-whats-happening",
    "title": "scRNA-tools low-maintenance mode",
    "section": "So, what‚Äôs happening?",
    "text": "So, what‚Äôs happening?\nIn May 2024 I will be putting scRNA-tools into what I am calling ‚Äúlow-maintenance mode‚Äù. Basically, this means I will stop actively seeking out new tools to add to the database and updates for existing tools. I will still make changes based on user submissions and the existing automated checks but the rate of updates will significantly decrease. Upgrades to the database, website and other code are unlikely to happen unless things break."
  },
  {
    "objectID": "posts/2024-03-04-scRNAtools-low-maintenance/index.html#thats-sad-why-now",
    "href": "posts/2024-03-04-scRNAtools-low-maintenance/index.html#thats-sad-why-now",
    "title": "scRNA-tools low-maintenance mode",
    "section": "That‚Äôs sad üòø, why now?",
    "text": "That‚Äôs sad üòø, why now?\nI‚Äôm moving onto the next step in my career and can no longer justify the 2-3 hours per week it takes review new papers, curate them and add tools to the database. Transiting to low-maintenance mode means less frequent updates and should reduce the commitment to something I can keep up with, similar to the software packages I maintain. I would love to keep scRNA-tools running as it has but the continuous, ongoing nature of the curation makes it difficult when you can no-longer justify it as ‚Äúwork‚Äù, and this will only increase as the field continuous to grow.\nI also have to acknowledge that I haven‚Äôt developed scRNA-tools as I would have liked over the last few years. There are several new categories and features I wanted to add but, as the typical academic says, I never found the time."
  },
  {
    "objectID": "posts/2024-03-04-scRNAtools-low-maintenance/index.html#maybe-someone-else-could-take-over",
    "href": "posts/2024-03-04-scRNAtools-low-maintenance/index.html#maybe-someone-else-could-take-over",
    "title": "scRNA-tools low-maintenance mode",
    "section": "Maybe someone else could take over?",
    "text": "Maybe someone else could take over?\nI always wanted scRNA-tools to be a community project so I am definitely open to this but I would need to be convinced that whoever takes over would be able to commit to actively maintaining the project. In the past I have had people reach out to contribute, and even recruited a team to help with curation and expanding the database, but that always petered out after a few weeks or months. I totally don‚Äôt blame anyone for that, there is very little for a PhD student to gain from contributing to a project like this, but it does make me cautious about handing over the project to someone who may not end up putting more time into it than I can."
  },
  {
    "objectID": "posts/2024-03-04-scRNAtools-low-maintenance/index.html#last-thoughts",
    "href": "posts/2024-03-04-scRNAtools-low-maintenance/index.html#last-thoughts",
    "title": "scRNA-tools low-maintenance mode",
    "section": "Last thoughts",
    "text": "Last thoughts\nscRNA-tools has helped record the first years of the single-cell genomics revolution and has been a big part of my work life for the last eight or so years. While I think it is a valuable resource it is also limited, especially as the field expands into other modalities. It will be sad it see it not updated as frequently but it‚Äôs time for us both to move on."
  },
  {
    "objectID": "posts/2020-04-29-bioconductor-3-11-wrap-up/index.html",
    "href": "posts/2020-04-29-bioconductor-3-11-wrap-up/index.html",
    "title": "Bioconductor 3.11 wrap-up",
    "section": "",
    "text": "The Bioconductor 3.11 release was yesterday. Here is my wrap-up of new packages and updates. This is only the things I found interesting based on the release and they don‚Äôt come with any particular endorsement. If there is something else you are looking for have a look at the release notes here.\n\nNew packages\n\n{basilisk} - installs a self-contained Python instance that is maintained by the R installation\n{BiocDockerManager} - management of Bioconductor Docker images\n{CiteFuse} - suite of methods for working with CITE-seq data\n{clustifyr} - classify cells in scRNA-seq data using external references\n{cmapR} - interface for the Broad Institute Connectivity Map resource of gene perturbation expression profiles\n{ctgGEM} - streamlines building of cell-state hierarchies from single-cell gene expression data\n{distinct} - differential testing of distributions\n{dittoSeq} - user friendly visualisation of bulk and single-cell RNA-seq data including consideration of colour blindness\n{Dune} - merges pairs of clusters to increase ARI and improve reproducibility\n{frenchFISH} - Poisson models for DNA copy number from FISH data (bonus points for the excellent name)\n{GeneTonic} - Shiny app for looking at enrichment results from expression data (another great name)\n{HIPPO} - scRNA-seq feature selection and clustering\n{ISEEu} - extensions for the {iSEE} shiny app\n{mitch} - multi-contrast enrichment analysis\n{peco} - predicting cell-cycle progression using scRNA-seq data\n{scClassify} - multi-scale classification of scRNA-seq data using cell hierarchies\n{scHOT} - testing changes in higher-order structure of gene expression such as across (pseudo) time or space\n{scry} - count-based feature selection and dimensionality reduction for small count data\n{scTHI} - identify active ligand-receptor pairs in scRNA-seq data\n{SingleCellSignalR} - clustering of scRNA-seq data and inference of cell-cell interactions\n{sparseMatrixStats} - high-performance functions for row and column operations on sparse matrices, inspired by {matrixStats}\n{tidybulk} - tidy wrappers for bulk RNA-seq analysis\n\n\n\nUpdates\n\n{BASiCS} - many updates and release of version 2\n{batchelor} - support of arbitrary design matrices and extension of MNN integration to cluster centroids\n{DropletUtils} - down sampling of batches, writing to 10x format, removal of chimeric reads, demultiplexing of cell hashing experiments\n{edgeR} - integration of the limma voom-lmFit pipeline, support for {SummarizedExperiment} objects\n{iSEE} - support of extensions such as those in {ISEEu}\n{limma} - changeLog() function can be used with any package, improved treatment of NA values\n{missMethyl} - bug fixes and fract.counts argument\n{PCAtools} - functions for choosing the ideal number of components to retain\n{scater} - multi-feature set UMAP and various new arguments\n{scran} - new functions for sub-clustering and cluster bootstrapping, wrappers for graph-based clustering, updates to marker identification functions\n{SummarizedExperiment} - support for assays with more than four dimensions, changes to assay getters and setters to check dimnames\n{tximeta} - functions for splitting {SummarizedExperiment} objects and conversion to DGEList\n{tximport} - improved support for importing Alevin output\n\n\n\nWorkflow packages\n\n{fluentGenomics} - extended workflow using the {plyranges} and {tximeta} packages for fluent genomic analysis"
  },
  {
    "objectID": "posts/2015-09-13-my-markdown-thesis/index.html",
    "href": "posts/2015-09-13-my-markdown-thesis/index.html",
    "title": "My Markdown thesis",
    "section": "",
    "text": "It‚Äôs come to the stage in my Master‚Äôs where I have to start thinking about writing my thesis. Apart from all the analysis I have to do before I can do that there is also the question of what I am going to use to construct the document itself.\nFor the last year or so I have been writing using Markdown which is converted to Tex using Pandoc then used to produce a PDF. I have found this a really good way to work combining the speed and clarity of Markdown with the ability to include LaTeX directly when I need extra flexibility. I have been using the Uberdoc tool to set up projects and combine multiple Markdown files but unfortunately it‚Äôs not quite flexible enough for a complex document like a thesis.\nI wanted to be able to be able to incorporate my Tex, particularly so I could use John Papandriopoulos‚Äô thesis template. Ideally I wanted to build my own tool (probably in Python or Perl) that would manage projects, including git commits, as well as produce statistics but time doesn‚Äôt permit so I have ended up with a Make based solution.\nThe setup allows me to be flexible with how I set up my directory as the whole project is searched for Markdown files which are converted to LaTeX in a build directory. The directory structure is flattened at this stage which means I don‚Äôt have to write the full path when including files. Figures are treated similarly and there are folders for additional LaTeX files (such as styles and templates) and bibliography files. I also have a core Tex file which is used to tie everything together. The PDF is constructed using latexmk and I can use texcount for keeping track of my word count. So when I run make for the first time the following steps occur:\n\nThe build directory is created with the necessary subdirectories.\nThe project directory is searched for Markdown files which are converted to TeX files in the build directory.\nTeX files are copied from the template directory to the build directory.\nAll files are copied from the style directory to a style subdirectory inside the build directory.\nAll files are copied from the bibliography directory to a bibliography subdirectory inside the build directory.\nThe figures directory is searched for image files which are copied to a figures subdirectory inside the build directory.\nlatexmk is used to build the output file in the build directory.\nThe output PDF is copied to the main directory.\n\nIt‚Äôs not perfect, for example there is a bug that means make needs to be run more than once when you add a new file which isn‚Äôt ideal, but it mostly does what I want and hopefully it will get me through. If you want to check it out the code is available on Github."
  },
  {
    "objectID": "posts/2017-07-19-building-a-clustering-tree/index.html",
    "href": "posts/2017-07-19-building-a-clustering-tree/index.html",
    "title": "Building a clustering tree",
    "section": "",
    "text": "For my PhD I am working on methods for analysing single-cell RNA-sequencing (scRNA-seq) data which measure the expression of genes in individual cells. One of the most common analyses done on this type of data is to cluster the cells, often in an attempt to find out what cell types are present in a sample.\nIn a recent seminar I showed some images of what I am calling a ‚Äúclustering tree‚Äù (you can see the slides here if you are interested). This is a visualisation I came up with to show the relationship between clusterings as the number of clusters is increased. A few people asked how I had made it so here is a short example."
  },
  {
    "objectID": "posts/2017-07-19-building-a-clustering-tree/index.html#setup",
    "href": "posts/2017-07-19-building-a-clustering-tree/index.html#setup",
    "title": "Building a clustering tree",
    "section": "Setup",
    "text": "Setup\nFirst we need to load the libraries we are going to use:\n# Simulation\nlibrary(splatter)\n\n# Clustering\nlibrary(Seurat) # Installed from https://github.com/satijalab/seurat\n\n# Graphs\nlibrary(igraph)\n\n# Plotting\nlibrary(ggraph)\nlibrary(viridis)\n\n# Data manipulation\nlibrary(tidyverse)\nFor this example I am going to simulate some scRNA-seq data with eight different groups with different numbers of cells using Splatter.\nsim &lt;- splatSimulateGroups(groupCells = c(100, 80, 60, 50, 30, 20, 20, 15),\n                            seed = 10, verbose = FALSE)\nLet‚Äôs take a quick look at this to see if it is anything like we would expect:\nplotTSNE(sim, colour_by = \"Group\")\n\nHere we can see the different groups, so there should be something for our clustering analysis to find.\nThe clustering pacakge we are going to use is Seurat which uses it‚Äôs own object to store the data. Here is a small function I have written to convert from the SCESet object produced by Splatter to the Seurat object required by Seurat.\nSCESetToSeurat &lt;- function(sce) {\n    if (!is(sce,'SCESet')) {\n        stop(\"sce must be an SCESet object\")\n    }\n\n    counts &lt;- scater::counts(sce)\n\n    if (is.null(counts)) {\n        stop(\"sce must contain counts to convert to Seurat\")\n    }\n\n    seurat &lt;- new(\"seurat\",\n                    raw.data = counts,\n                    is.expr = sce@lowerDetectionLimit,\n                    data.info = Biobase::pData(sce),\n                    cell.names = Biobase::sampleNames(sce))\n\n    return(seurat)\n}\nNow to convert the dataset.\nseurat &lt;- SCESetToSeurat(sim)"
  },
  {
    "objectID": "posts/2017-07-19-building-a-clustering-tree/index.html#clustering",
    "href": "posts/2017-07-19-building-a-clustering-tree/index.html#clustering",
    "title": "Building a clustering tree",
    "section": "Clustering",
    "text": "Clustering\nWe now have a dataset in the format required by Seurat. Before we do any clustering we need to run through some setup steps. I‚Äôm not going to explain what they are doing here, if you want to now the details refer to the Seurat tutorials.\nseurat &lt;- Setup(seurat, project = \"Example\", meta.data = seurat@data.info)\nseurat &lt;- MeanVarPlot(seurat, fxn.x = expMean, fxn.y = logVarDivMean,\n                        x.low.cutoff = 0.1, x.high.cutoff = 3,\n                        y.cutoff = 0.5, do.contour = FALSE)\n\nseurat &lt;- PCA(seurat, pc.genes = seurat@var.genes, do.print = FALSE)\nNow we can do the clustering. The parameter we are interested in is the resolution parameter which controls how many clusters Seurat returns. I start by setting resolution = 0. This will create a cluster containing all cells that will serve as the root of our tree. We also ask Seurat to store some of the intermediate calculations so we don‚Äôt have to do them again when we cluster with different resolutions:\nseurat &lt;- FindClusters(seurat, pc.use = 1:20, resolution = 0, algorithm = 3,\n                        print.output = FALSE, save.SNN = TRUE)\nWe can now loop over a range of resolutions that we are interested in. I have only tried a few values here but if this was a real dataset you might want to try some more.\nfor (res in c(0.3, 0.6, 0.9, 1.2)) {\n    seurat &lt;- FindClusters(seurat, resolution = res, algorithm = 3,\n                            print.output = FALSE)\n}"
  },
  {
    "objectID": "posts/2017-07-19-building-a-clustering-tree/index.html#get-results",
    "href": "posts/2017-07-19-building-a-clustering-tree/index.html#get-results",
    "title": "Building a clustering tree",
    "section": "Get results",
    "text": "Get results\nSeurat stores the cluster labels in the data.info slot in columns starting with res.. This is the only part we are interested in so let‚Äôs extract just those columns.\nclusterings &lt;- seurat@data.info %&gt;% select(contains(\"res.\"))\n\nhead(clusterings)\n\n##       res.0 res.0.3 res.0.6 res.0.9 res.1.2\n## Cell1     0       1       0       0       0\n## Cell2     0       1       0       0       0\n## Cell3     0       1       0       0       0\n## Cell4     0       1       0       0       0\n## Cell5     0       1       0       0       0\n## Cell6     0       1       0       0       0\nWe now know which cluster each cell was assigned to at each resolution but to build the tree we need some more information. This next function looks at two neighbouring resolutions and works out how many cells moved from a cluster in the lower resolution to each cluster in the higher resolution. These transitions are going to form the edges of our tree.\ngetEdges &lt;- function(clusterings) {\n\n    # Loop over the different resolutions\n    transitions &lt;- lapply(1:(ncol(clusterings) - 1), function(i) {\n\n        # Extract two neighbouring clusterings\n        from.res &lt;- sort(colnames(clusterings))[i]\n        to.res &lt;- sort(colnames(clusterings))[i + 1]\n\n        # Get the cluster names\n        from.clusters &lt;- sort(unique(clusterings[, from.res]))\n        to.clusters &lt;- sort(unique(clusterings[, to.res]))\n\n        # Get all possible combinations\n        trans.df &lt;- expand.grid(FromClust = from.clusters,\n                                ToClust = to.clusters)\n\n        # Loop over the possible transitions\n        trans &lt;- apply(trans.df, 1, function(x) {\n            from.clust &lt;- x[1]\n            to.clust &lt;- x[2]\n\n            # Find the cells from those clusters\n            is.from &lt;- clusterings[, from.res] == from.clust\n            is.to &lt;- clusterings[, to.res] == to.clust\n\n            # Count them up\n            trans.count &lt;- sum(is.from & is.to)\n\n            # Get the sizes of the two clusters\n            from.size &lt;- sum(is.from)\n            to.size &lt;- sum(is.to)\n\n            # Get the proportions of cells moving along this edge\n            trans.prop.from &lt;- trans.count / from.size\n            trans.prop.to &lt;- trans.count / to.size\n\n            return(c(trans.count, trans.prop.from, trans.prop.to))\n        })\n\n        # Tidy up the results\n        trans.df$FromRes &lt;- as.numeric(gsub(\"res.\", \"\", from.res))\n        trans.df$ToRes &lt;- as.numeric(gsub(\"res.\", \"\", to.res))\n        trans.df$TransCount &lt;- trans[1, ]\n        trans.df$TransPropFrom &lt;- trans[2, ]\n        trans.df$TransPropTo &lt;- trans[3, ]\n\n        return(trans.df)\n    })\n\n    # Bind the results from the different resolutions together\n    transitions &lt;- do.call(\"rbind\", transitions)\n\n    # Tidy everything up\n    levs &lt;- sort(as.numeric(levels(transitions$ToClust)))\n    transitions &lt;- transitions %&gt;%\n        mutate(FromClust = factor(FromClust,\n                                    levels = levs))  %&gt;%\n        mutate(ToClust = factor(ToClust, levels = levs))\n\n    return(transitions)\n}\n\nedges &lt;- getEdges(clusterings)\nhead(edges)\n\n##   FromClust ToClust FromRes ToRes TransCount TransPropFrom TransPropTo\n## 1         0       0     0.0   0.3        135     0.3600000           1\n## 2         0       1     0.0   0.3        100     0.2666667           1\n## 3         0       2     0.0   0.3         60     0.1600000           1\n## 4         0       3     0.0   0.3         50     0.1333333           1\n## 5         0       4     0.0   0.3         30     0.0800000           1\n## 6         0       0     0.3   0.6          0     0.0000000           0\nSome of these columns are pretty obvious but the last three could do with an explanation. TransCount is the number of cells that move along this edge. TransPropFrom is the proportion of the cells in the lower resolution cluster that have made this transition and TransPropTo is the proportion of cells in the higher resolution cluster that came from this edge.\nGetting the information about the nodes of the tree is easier as these just represent the clusters. This function summarises the cluster information and converts it to long format.\ngetNodes &lt;- function(clusterings) {\n    nodes &lt;- clusterings %&gt;%\n        gather(key = Res, value = Cluster) %&gt;%\n        group_by(Res, Cluster) %&gt;%\n        summarise(Size = n()) %&gt;%\n        ungroup() %&gt;%\n        mutate(Res = stringr::str_replace(Res, \"res.\", \"\")) %&gt;%\n        mutate(Res = as.numeric(Res), Cluster = as.numeric(Cluster)) %&gt;%\n        mutate(Node = paste0(\"R\", Res, \"C\", Cluster)) %&gt;%\n        select(Node, everything())\n}\n\nnodes &lt;- getNodes(clusterings)\nhead(nodes)\n\n## # A tibble: 6 x 4\n##     Node   Res Cluster  Size\n##    &lt;chr&gt; &lt;dbl&gt;   &lt;dbl&gt; &lt;int&gt;\n## 1   R0C0   0.0       0   375\n## 2 R0.3C0   0.3       0   135\n## 3 R0.3C1   0.3       1   100\n## 4 R0.3C2   0.3       2    60\n## 5 R0.3C3   0.3       3    50\n## 6 R0.3C4   0.3       4    30\nEach node needs a unique ID which I have made by combining the resolution and cluster number. We also record the number of cells in each cluster.\nNow we can build the graph we will use as the starting point for our plot. Some of the possible edges between clusters will have no cells travelling along them so we filter them out. We also remove edges that correspond to a small proportion (&lt; 2%) of cells in the higher resolution cluster.\ngraph &lt;- edges %&gt;%\n    # Remove edges without any cell...\n    filter(TransCount &gt; 0) %&gt;%\n    # ...or making up only a small proportion of the new cluster\n    filter(TransPropTo &gt; 0.02) %&gt;%\n    # Rename the nodes\n    mutate(FromNode = paste0(\"R\", FromRes, \"C\", FromClust)) %&gt;%\n    mutate(ToNode = paste0(\"R\", ToRes, \"C\", ToClust)) %&gt;%\n    # Reorder columns\n    select(FromNode, ToNode, everything()) %&gt;%\n    # Build a graph using igraph\n    graph_from_data_frame(vertices = nodes)\n\nprint(graph)\n\n## IGRAPH b1b93c3 DN-- 23 23 --\n## + attr: name (v/c), Res (v/n), Cluster (v/n), Size (v/n),\n## | FromClust (e/c), ToClust (e/c), FromRes (e/n), ToRes (e/n),\n## | TransCount (e/n), TransPropFrom (e/n), TransPropTo (e/n)\n## + edges from b1b93c3 (vertex names):\n##  [1] R0C0  -&gt;R0.3C0 R0C0  -&gt;R0.3C1 R0C0  -&gt;R0.3C2 R0C0  -&gt;R0.3C3\n##  [5] R0C0  -&gt;R0.3C4 R0.3C1-&gt;R0.6C0 R0.3C0-&gt;R0.6C1 R0.3C4-&gt;R0.6C1\n##  [9] R0.3C0-&gt;R0.6C2 R0.3C2-&gt;R0.6C3 R0.3C3-&gt;R0.6C4 R0.6C0-&gt;R0.9C0\n## [13] R0.6C2-&gt;R0.9C1 R0.6C3-&gt;R0.9C2 R0.6C1-&gt;R0.9C3 R0.6C4-&gt;R0.9C4\n## [17] R0.6C1-&gt;R0.9C5 R0.9C0-&gt;R1.2C0 R0.9C1-&gt;R1.2C1 R0.9C2-&gt;R1.2C2\n## [21] R0.9C3-&gt;R1.2C3 R0.9C4-&gt;R1.2C4 R0.9C5-&gt;R1.2C5"
  },
  {
    "objectID": "posts/2017-07-19-building-a-clustering-tree/index.html#plot-the-tree",
    "href": "posts/2017-07-19-building-a-clustering-tree/index.html#plot-the-tree",
    "title": "Building a clustering tree",
    "section": "Plot the tree",
    "text": "Plot the tree\nThe last step is to pass our graph to the ggraph library for plotting.\n# Plot our graph using the `tree` layout\nggraph(graph, layout = \"tree\") +\n    # Plot the edges, colour is the number of cells and transparency is the\n    # proportion contribution to the new cluster\n    geom_edge_link(arrow = arrow(length = unit(1, 'mm')),\n                    end_cap = circle(3.5, \"mm\"), edge_width = 1,\n                    aes(colour = log(TransCount), alpha = TransPropTo)) +\n    # Plot the nodes, size is the number of cells\n    geom_node_point(aes(colour = factor(Res),\n                        size = Size)) +\n    geom_node_text(aes(label = Cluster), size = 3) +\n    # Adjust the scales\n    scale_size(range = c(4, 15)) +\n    scale_edge_colour_gradientn(colours = viridis(100)) +\n    # Add legend labels\n    guides(size = guide_legend(title = \"Cluster Size\", title.position = \"top\"),\n            colour = guide_legend(title = \"Clustering Resolution\",\n                                    title.position = \"top\"),\n            edge_colour = guide_edge_colorbar(title = \"Cell Count (log)\",\n                                                title.position = \"top\"),\n            edge_alpha = guide_legend(title = \"Cluster Prop\",\n                                        title.position = \"top\", nrow = 2)) +\n    # Remove the axes as they don't really mean anything\n    theme_void() +\n    theme(legend.position = \"bottom\")\n\nAnd here is the result! We can see that see that Seurat finds three of the clusters easily and that these don‚Äôt change as the resolution increases. A fourth group contains most of the cells and is sub-divided as we increase resolution. Interestingly at the lowest resolution there is a small cluster which is then absorbed into one of the other branches.\nThis tree is cleaner and has less branches than what we would be likely to see with a real dataset but the process to create it would be the same. I have used Seurat as the clustering method in this example but it should be easy to adapt the process to any other method that allows you to adjust the number of clusters. I have found this visualisation useful in my analysis particularly for looking at which clusters are very distinct and the relationships between different clusters and clusterings.\nGood luck creating your own clustering trees!\n\nSession information\ndevtools::session_info()\n\n## Session info -------------------------------------------------------------\n\n##  setting  value\n##  version  R version 3.4.1 (2017-06-30)\n##  system   x86_64, darwin15.6.0\n##  ui       RStudio (1.0.143)\n##  language (EN)\n##  collate  en_AU.UTF-8\n##  tz       Australia/Melbourne\n##  date     2017-07-19\n\n## Packages -----------------------------------------------------------------\n\n##  package        * version  date       source\n##  AnnotationDbi    1.38.1   2017-06-01 Bioconductor\n##  ape              4.1      2017-02-14 cran (@4.1)\n##  assertthat       0.2.0    2017-04-11 CRAN (R 3.4.0)\n##  backports        1.1.0    2017-05-22 CRAN (R 3.4.0)\n##  base           * 3.4.1    2017-07-07 local\n##  beeswarm         0.2.3    2016-04-25 CRAN (R 3.4.0)\n##  bindr            0.1      2016-11-13 CRAN (R 3.4.0)\n##  bindrcpp       * 0.2      2017-06-17 CRAN (R 3.4.0)\n##  Biobase        * 2.36.2   2017-05-04 Bioconductor\n##  BiocGenerics   * 0.22.0   2017-04-25 Bioconductor\n##  BiocParallel     1.10.1   2017-05-03 Bioconductor\n##  biomaRt          2.32.1   2017-06-09 Bioconductor\n##  bit              1.1-12   2014-04-09 CRAN (R 3.4.0)\n##  bit64            0.9-7    2017-05-08 CRAN (R 3.4.0)\n##  bitops           1.0-6    2013-08-17 CRAN (R 3.4.0)\n##  blob             1.1.0    2017-06-17 CRAN (R 3.4.0)\n##  broom            0.4.2    2017-02-13 CRAN (R 3.4.0)\n##  car              2.1-5    2017-07-04 cran (@2.1-5)\n##  caret            6.0-76   2017-04-18 cran (@6.0-76)\n##  caTools          1.17.1   2014-09-10 cran (@1.17.1)\n##  cellranger       1.1.0    2016-07-27 CRAN (R 3.4.0)\n##  checkmate        1.8.3    2017-07-03 CRAN (R 3.4.1)\n##  class            7.3-14   2015-08-30 CRAN (R 3.4.1)\n##  cluster          2.0.6    2017-03-10 CRAN (R 3.4.1)\n##  codetools        0.2-15   2016-10-05 CRAN (R 3.4.1)\n##  colorspace       1.3-2    2016-12-14 CRAN (R 3.4.0)\n##  compiler         3.4.1    2017-07-07 local\n##  cowplot        * 0.7.0    2016-10-28 cran (@0.7.0)\n##  data.table       1.10.4   2017-02-01 CRAN (R 3.4.0)\n##  datasets       * 3.4.1    2017-07-07 local\n##  DBI              0.7      2017-06-18 CRAN (R 3.4.0)\n##  DEoptimR         1.0-8    2016-11-19 cran (@1.0-8)\n##  devtools         1.13.2   2017-06-02 CRAN (R 3.4.0)\n##  digest           0.6.12   2017-01-27 CRAN (R 3.4.0)\n##  diptest          0.75-7   2016-12-05 cran (@0.75-7)\n##  dplyr          * 0.7.1    2017-06-22 CRAN (R 3.4.1)\n##  edgeR            3.18.1   2017-05-06 Bioconductor\n##  evaluate         0.10.1   2017-06-24 CRAN (R 3.4.1)\n##  fastICA          1.2-1    2017-06-12 cran (@1.2-1)\n##  flexmix          2.3-14   2017-04-28 cran (@2.3-14)\n##  FNN              1.1      2013-07-31 cran (@1.1)\n##  forcats          0.2.0    2017-01-23 CRAN (R 3.4.0)\n##  foreach          1.4.3    2015-10-13 cran (@1.4.3)\n##  foreign          0.8-69   2017-06-22 CRAN (R 3.4.1)\n##  fpc              2.1-10   2015-08-14 cran (@2.1-10)\n##  gdata            2.18.0   2017-06-06 cran (@2.18.0)\n##  ggbeeswarm       0.5.3    2016-12-01 CRAN (R 3.4.0)\n##  ggforce          0.1.1    2016-11-28 CRAN (R 3.4.0)\n##  ggplot2        * 2.2.1    2016-12-30 CRAN (R 3.4.0)\n##  ggraph         * 1.0.0    2017-02-24 CRAN (R 3.4.0)\n##  ggrepel          0.6.5    2016-11-24 CRAN (R 3.4.0)\n##  glue             1.1.1    2017-06-21 CRAN (R 3.4.1)\n##  gplots           3.0.1    2016-03-30 cran (@3.0.1)\n##  graphics       * 3.4.1    2017-07-07 local\n##  grDevices      * 3.4.1    2017-07-07 local\n##  grid             3.4.1    2017-07-07 local\n##  gridExtra        2.2.1    2016-02-29 CRAN (R 3.4.0)\n##  gtable           0.2.0    2016-02-26 CRAN (R 3.4.0)\n##  gtools           3.5.0    2015-05-29 cran (@3.5.0)\n##  haven            1.1.0    2017-07-09 CRAN (R 3.4.1)\n##  hms              0.3      2016-11-22 CRAN (R 3.4.0)\n##  htmltools        0.3.6    2017-04-28 CRAN (R 3.4.0)\n##  httpuv           1.3.5    2017-07-04 CRAN (R 3.4.1)\n##  httr             1.2.1    2016-07-03 CRAN (R 3.4.0)\n##  igraph         * 1.1.1    2017-07-16 CRAN (R 3.4.1)\n##  IRanges          2.10.2   2017-05-25 Bioconductor\n##  irlba            2.2.1    2017-05-17 cran (@2.2.1)\n##  iterators        1.0.8    2015-10-13 cran (@1.0.8)\n##  jsonlite         1.5      2017-06-01 CRAN (R 3.4.0)\n##  kernlab          0.9-25   2016-10-03 cran (@0.9-25)\n##  KernSmooth       2.23-15  2015-06-29 CRAN (R 3.4.1)\n##  knitr            1.16     2017-05-18 CRAN (R 3.4.1)\n##  labeling         0.3      2014-08-23 CRAN (R 3.4.0)\n##  lars             1.2      2013-04-24 cran (@1.2)\n##  lattice          0.20-35  2017-03-25 CRAN (R 3.4.1)\n##  lazyeval         0.2.0    2016-06-12 CRAN (R 3.4.0)\n##  limma            3.32.3   2017-07-16 Bioconductor\n##  lme4             1.1-13   2017-04-19 cran (@1.1-13)\n##  locfit           1.5-9.1  2013-04-20 CRAN (R 3.4.0)\n##  lubridate        1.6.0    2016-09-13 CRAN (R 3.4.0)\n##  magrittr         1.5      2014-11-22 CRAN (R 3.4.0)\n##  MASS             7.3-47   2017-02-26 CRAN (R 3.4.1)\n##  Matrix           1.2-10   2017-05-03 CRAN (R 3.4.1)\n##  MatrixModels     0.4-1    2015-08-22 cran (@0.4-1)\n##  matrixStats      0.52.2   2017-04-14 CRAN (R 3.4.0)\n##  mclust           5.3      2017-05-21 cran (@5.3)\n##  memoise          1.1.0    2017-04-21 CRAN (R 3.4.0)\n##  methods        * 3.4.1    2017-07-07 local\n##  mgcv             1.8-17   2017-02-08 CRAN (R 3.4.1)\n##  mime             0.5      2016-07-07 CRAN (R 3.4.0)\n##  minqa            1.2.4    2014-10-09 cran (@1.2.4)\n##  mixtools         1.1.0    2017-03-10 cran (@1.1.0)\n##  mnormt           1.5-5    2016-10-15 CRAN (R 3.4.0)\n##  ModelMetrics     1.1.0    2016-08-26 cran (@1.1.0)\n##  modelr           0.1.0    2016-08-31 CRAN (R 3.4.0)\n##  modeltools       0.2-21   2013-09-02 cran (@0.2-21)\n##  munsell          0.4.3    2016-02-13 CRAN (R 3.4.0)\n##  mvtnorm          1.0-6    2017-03-02 cran (@1.0-6)\n##  nlme             3.1-131  2017-02-06 CRAN (R 3.4.1)\n##  nloptr           1.0.4    2014-08-04 cran (@1.0.4)\n##  nnet             7.3-12   2016-02-02 CRAN (R 3.4.1)\n##  numDeriv         2016.8-1 2016-08-27 cran (@2016.8-)\n##  parallel       * 3.4.1    2017-07-07 local\n##  pbapply          1.3-3    2017-07-04 cran (@1.3-3)\n##  pbkrtest         0.4-7    2017-03-15 cran (@0.4-7)\n##  pkgconfig        2.0.1    2017-03-21 CRAN (R 3.4.0)\n##  plyr             1.8.4    2016-06-08 CRAN (R 3.4.0)\n##  prabclus         2.2-6    2015-01-14 cran (@2.2-6)\n##  psych            1.7.5    2017-05-03 CRAN (R 3.4.1)\n##  purrr          * 0.2.2.2  2017-05-11 CRAN (R 3.4.0)\n##  quantreg         5.33     2017-04-18 cran (@5.33)\n##  R6               2.2.2    2017-06-17 CRAN (R 3.4.0)\n##  ranger           0.8.0    2017-06-20 cran (@0.8.0)\n##  RColorBrewer     1.1-2    2014-12-07 CRAN (R 3.4.0)\n##  Rcpp             0.12.12  2017-07-15 CRAN (R 3.4.1)\n##  RCurl            1.95-4.8 2016-03-01 CRAN (R 3.4.0)\n##  readr          * 1.1.1    2017-05-16 CRAN (R 3.4.0)\n##  readxl           1.0.0    2017-04-18 CRAN (R 3.4.0)\n##  reshape2         1.4.2    2016-10-22 CRAN (R 3.4.0)\n##  rhdf5            2.20.0   2017-04-25 Bioconductor\n##  rjson            0.2.15   2014-11-03 CRAN (R 3.4.0)\n##  rlang            0.1.1    2017-05-18 CRAN (R 3.4.0)\n##  rmarkdown        1.6      2017-06-15 CRAN (R 3.4.1)\n##  robustbase       0.92-7   2016-12-09 cran (@0.92-7)\n##  ROCR             1.0-7    2015-03-26 cran (@1.0-7)\n##  rprojroot        1.2      2017-01-16 CRAN (R 3.4.0)\n##  RSQLite          2.0      2017-06-19 CRAN (R 3.4.1)\n##  Rtsne            0.13     2017-04-14 cran (@0.13)\n##  rvest            0.3.2    2016-06-17 CRAN (R 3.4.0)\n##  S4Vectors        0.14.3   2017-06-03 Bioconductor\n##  scales           0.4.1    2016-11-09 CRAN (R 3.4.0)\n##  scater         * 1.4.0    2017-04-25 Bioconductor\n##  segmented        0.5-2.1  2017-06-14 cran (@0.5-2.1)\n##  Seurat         * 1.4.0.16 2017-07-19 Github (satijalab/seurat@3bd092a)\n##  shiny            1.0.3    2017-04-26 CRAN (R 3.4.0)\n##  shinydashboard   0.6.1    2017-06-14 CRAN (R 3.4.0)\n##  sn               1.5-0    2017-02-10 cran (@1.5-0)\n##  SparseM          1.77     2017-04-23 cran (@1.77)\n##  splatter       * 1.0.3    2017-05-27 Bioconductor\n##  splines          3.4.1    2017-07-07 local\n##  stats          * 3.4.1    2017-07-07 local\n##  stats4           3.4.1    2017-07-07 local\n##  stringi          1.1.5    2017-04-07 CRAN (R 3.4.0)\n##  stringr          1.2.0    2017-02-18 CRAN (R 3.4.0)\n##  survival         2.41-3   2017-04-04 CRAN (R 3.4.1)\n##  tclust           1.2-7    2017-06-30 cran (@1.2-7)\n##  tibble         * 1.3.3    2017-05-28 CRAN (R 3.4.0)\n##  tidyr          * 0.6.3    2017-05-15 CRAN (R 3.4.0)\n##  tidyverse      * 1.1.1    2017-01-27 CRAN (R 3.4.0)\n##  tools            3.4.1    2017-07-07 local\n##  trimcluster      0.1-2    2012-10-29 cran (@0.1-2)\n##  tsne             0.1-3    2016-07-15 cran (@0.1-3)\n##  tweenr           0.1.5    2016-10-10 CRAN (R 3.4.0)\n##  tximport         1.4.0    2017-04-25 Bioconductor\n##  udunits2         0.13     2016-11-17 CRAN (R 3.4.0)\n##  units            0.4-5    2017-06-15 CRAN (R 3.4.0)\n##  utils          * 3.4.1    2017-07-07 local\n##  VGAM             1.0-3    2017-01-11 cran (@1.0-3)\n##  vipor            0.4.5    2017-03-22 CRAN (R 3.4.0)\n##  viridis        * 0.4.0    2017-03-27 CRAN (R 3.4.0)\n##  viridisLite    * 0.2.0    2017-03-24 CRAN (R 3.4.0)\n##  withr            1.0.2    2016-06-20 CRAN (R 3.4.0)\n##  XML              3.98-1.9 2017-06-19 CRAN (R 3.4.1)\n##  xml2             1.1.1    2017-01-24 CRAN (R 3.4.0)\n##  xtable           1.8-2    2016-02-05 CRAN (R 3.4.0)\n##  yaml             2.1.14   2016-11-12 CRAN (R 3.4.0)\n##  zlibbioc         1.22.0   2017-04-25 Bioconductor"
  },
  {
    "objectID": "posts/2020-10-30-bioconductor-3-12-wrap-up/index.html",
    "href": "posts/2020-10-30-bioconductor-3-12-wrap-up/index.html",
    "title": "Bioconductor 3.12 wrap-up",
    "section": "",
    "text": "The Bioconductor 3.12 release was this week. Here is my wrap-up of new packages and updates. This is only the things I found interesting based on the release and they don‚Äôt come with any particular endorsement. If there is something else you are looking for have a look at the release notes here."
  },
  {
    "objectID": "posts/2020-10-30-bioconductor-3-12-wrap-up/index.html#splattersplatter",
    "href": "posts/2020-10-30-bioconductor-3-12-wrap-up/index.html#splattersplatter",
    "title": "Bioconductor 3.12 wrap-up",
    "section": "{splatter}",
    "text": "{splatter}\n\nAdd the splatPop simulation. This is a extension to the splat simulation contributed by Christina Azodi and Davis McCarthy that adds population effects. It allows you to specify relatedness between individuals and generate cell-type specific eQTL effects.\nAdd a batch.rmEffect parameter to the Splat simulation. This allows generation of a paired simulation without any batch effects.\nAdd a new minimiseSCE function which can be used to remove unneeded information from simulation output (or any SingleCellExperiment)\nAll simulations now return sparse assay matrices by default when they would be smaller than the equivalent dense matrix. This is controlled by a new sparsify argument.\nUsers will now be automatically prompted to install packages if they try to use a simulation for which the suggested dependencies are not available"
  },
  {
    "objectID": "posts/2020-10-30-bioconductor-3-12-wrap-up/index.html#zellkonverterzellkonverter",
    "href": "posts/2020-10-30-bioconductor-3-12-wrap-up/index.html#zellkonverterzellkonverter",
    "title": "Bioconductor 3.12 wrap-up",
    "section": "{zellkonverter}",
    "text": "{zellkonverter}\nThis is a new package (with help from Aaron Lun) that contains methods to convert between SingleCellExperiment and Python AnnData objects."
  },
  {
    "objectID": "posts/2016-05-03-bioconductor-3-3-packages/index.html",
    "href": "posts/2016-05-03-bioconductor-3-3-packages/index.html",
    "title": "Bioconductor 3.3 packages",
    "section": "",
    "text": "Bioconductor 3.3 has just been released. You can find the complete list of new packages (and changes to existing packages) here but here are a few I thought might be interesting based on the description. I might have more to say once I‚Äôve had time to try a few out."
  },
  {
    "objectID": "posts/2016-05-03-bioconductor-3-3-packages/index.html#single-cell",
    "href": "posts/2016-05-03-bioconductor-3-3-packages/index.html#single-cell",
    "title": "Bioconductor 3.3 packages",
    "section": "Single-cell",
    "text": "Single-cell\nThese packages are specific to single-cell RNA-seq analysis. A couple of them I am already familiar with, particularly scater.\n\ncellity - identifying low-quality cells\ncelTree - model the relationship between individual cells over time or space.\nscater - tools for analysis of single-cell RNA-seq data (particularly QC)\nscde - single-cell differential expression\nscran - normalisation, cell-cycle assignment, gene detection"
  },
  {
    "objectID": "posts/2024-09-15-scverse-conference/index.html",
    "href": "posts/2024-09-15-scverse-conference/index.html",
    "title": "scverse conference",
    "section": "",
    "text": "Summary\nThis week was the first ever scverse conference held in Munich from 10-12 September. While it was based around the scverse software community the conference covered more than just those core packages for single-cell analysis and included talks on a range of biological topics as well as a diverse range of workshops. Putting together any conference is a lot of work, but particularly the first attempt for what is still a new community. I was very impressed with what the organisers were able to put together, how smoothly everything ran and the number of attendees from around the world. It is great to see these growing into a real community that is more than just the core maintainers from a few packages and I look forward to seeing what they do in the years ahead. As with any effort on the work of students, the difficulty is always maintaining momentum as those people move on and everything is based to a new generation but I am hopeful they are building something that will be sustainable with support from senior academics and industry.\n\n\nKeynote sketchotes\nHere are my sketchnotes summarising the keynote talks (click to expand):\n\n\n\n\n\n\n\n\n\nRob Patro - ‚ÄúUpstream of the single-cell data deluge: On the importance of accurate, efficient and open methods for preprocessing single-cell data‚Äù\n\n\n\n\n\n\n\nAngela Oliveira Pisco - ‚ÄúMultimodal Atlas for Biological Data Anlaysis and Drug Discovery‚Äù\n\n\n\n\n\n\n\n\n\nChristina Leslie - ‚ÄúMachine learning for regulatory genomics at single-cell resolution‚Äù\n\n\n\n\n\n\n\nAlex Wolf - ‚ÄúMany anecdotes make a novel? Study-centered analysis & training models‚Äù\n\n\n\n\n\n\n\n\n\nMaria Brbic - ‚ÄúTowards AI-driven discoveries in Single-Cell genomics‚Äù\n\n\n\n\n\n\n\nFabian Theis - ‚ÄúFrom scanpy to the virtual cell: the coming-of-age of single cell analysis‚Äù"
  },
  {
    "objectID": "posts/2016-08-18-pyconau-2016/index.html",
    "href": "posts/2016-08-18-pyconau-2016/index.html",
    "title": "PyConAU 2016",
    "section": "",
    "text": "Over the weekend I attended PyCon Australia. This was my first time at a purely tech conference and I couldn‚Äôt help but compare it to my previous experiences at scientific conferences.\nDISCLAIMER: Like I said this was my first tech conference and my scientific conference experience is also fairly limited so some of the comments I make might be generalisations that don‚Äôt always apply.\nPyCon started with miniconfs on Friday and continued coding sprints on Monday and Tuesday. I didn‚Äôt attend any of these so my experience was only of the main conference on Saturday and Sunday. Here are some of the highlights for me in terms of presentations:\n\nAndrew Lonsdale - Python for science, side projects and stuff!\nAlexander Hogue - Graphing when your Facebook friends are awake - Story of discovering a hidden Facebook API and using it to track when your friends are online. Thoroughly entertaining while still providing the technical details.\nRachel Bunder - I wish I learnt that earlier! - Description of some of the slightly more advanced features available in Python. Could be a great intro for someone new to Python.\nRussell Keith-Magee - Python All the Things \nSebastian Vetter - Click: A Pleasure To Write, A Pleasure To Use - Click is an argument parsing library with additional features beyond argparse. Also apparently becoming the standard at Facebook (didn‚Äôt learn that at the conference, but it‚Äôs a fun fact).\nJustin Warren - Predicting the TripleJ Hottest 100 With Python - Overview of predicting the Hottest 100 for the last few years, starting with the method used by the Warmest 100 and continuing on how to extract and process information from Instagram.\nJackson Fairchild - Hitting the Wall and How to Get Up Again - Tackling Burnout and Strategies for Self Care \n\n(Full schedules for Saturday and Sunday and links to videos are available on the PyCon website)\nOverall I was really impressed by the quality of the talks. There were a couple that I thought could be improved a bit or where I wasn‚Äôt that interested in the content but there were no flat-out bad talks like you often see in the scientific context. It was clear that the presenters had put a lot of effort into planning what they were going to say and how to make that interesting and engaging for an audience that might be new to the topic. I don‚Äôt think I saw any slides that were walls of text or full of multiple plots. On the other had there was lots of code in slides, including live snippets. I‚Äôm not usually a fan of this but in the context it makes sense, particularly as you can assume that everyone has a basic grasp of Python. There were also lots of live demos, some of which were pretty impressive, and I don‚Äôt think I saw any fail.\nWhat struck me as being the biggest differences at PyCon compared to a scientific conference was the sense of a community and awareness of wider social issues. There was a big effort to be inclusive to all genders, sexualities, ethnic groups etc. and several of the talks touched on ethical issues or the speaker‚Äôs own experience in the community. While I would hope that a scientific gathering wouldn‚Äôt be discriminatory I can‚Äôt see diversity being embraced in the same way, but hopefully that will continue to improve. There was a sense of everyone being in it together and it was common for speakers to praise work that they hadn‚Äôt been involved in, but thought was interesting or useful. I didn‚Äôt see anyone described using their titles and it seemed that someone who had learned Python in the last year was as valued as someone who had been a major contributor for the last 10 years (although there may had been power dynamics that I wasn‚Äôt aware of).\nI think that a lot of the differences come from the work/volunteer divide. While PyCon was an opportunity to network or advertise your work the focus seemed to be on contributing to the community and the speakers were enthusiastic and keen to present. In contrast a scientific conference is a professional opportunity. As a scientist you are judged on your ability to get a talk which means more competition and sometimes speakers who aren‚Äôt interested in presenting. Every talk is a demonstration of your worth which makes it hard to present unfinished work and encourages people to try and fit to much in. It would be great for scientific conferences to spend more time discussing issues around thecommunities they represent but to do so they might have to sacrificeopportunities. For example it would be great to see a talk about mental health issues like Jackson Fairchild‚Äôs but that would mean taking away a spot from someone that might need it to progress their career. Personally I think we could maybe do with less talks from whichever well known person is doing the rounds in favour of some outside experts.\nOverall I enjoyed my time at PyCon. It was a bit different to a scientific conference and I think there are probably things they can learn from each other. Congratulations to all the speakers and everyone involved in organising. Given that it is in Melbourne again I hope to be back next year."
  },
  {
    "objectID": "posts/2020-07-11-requestival/index.html",
    "href": "posts/2020-07-11-requestival/index.html",
    "title": "triple j‚Äôs Requestival",
    "section": "",
    "text": "From 25 to 31 May triple j ran an event they called the ‚ÄúRequestival‚Äù. For anyone not from Australia, triple j is a national public radio station with a mandate to target a youth audience and promote alternative and Australian music. For many Australians, particularly those that grew up in regional areas, triple j is responsible for providing their first exposure to music outside the current top 50 or golden oldies. The idea behind the Requestival was fairly simple. To make up for the cancellation of many music festivals due to the coronavirus triple j would hold their own virtual festival with the twist being that every song they played would be requested by listeners. The second twist was that they would play any request, not just the kind of new alternative they usually play. And they did mean anything including Beethoven, TV show themes and Taylor Swift who all got some air time during the week.\nI thought this would be a cool dataset to have a play around with. I‚Äôll show some of the highlights here but have a look at the {workflowr} analysis website for more details or check out the code on GitHub."
  },
  {
    "objectID": "posts/2020-07-11-requestival/index.html#exploration",
    "href": "posts/2020-07-11-requestival/index.html#exploration",
    "title": "triple j‚Äôs Requestival",
    "section": "Exploration",
    "text": "Exploration\nThe first kind of analysis I wanted to do was some basic exploration of the final dataset. What I did was plot a histogram or barplot of each column and pick out the top and bottom five scoring songs. You can see all the details on the exploration page but I‚Äôll just list a few highlights here.\n\nThere were 43 songs played more than once (some of these are probably errors)\nThe most played artists were BENEE, Childish Gambino, CHVRCHES, DMA‚Äôs and The Chats with five plays each. There were 209 artists with more than one play.\nThe most played release was ‚ÄúLive At The Wireless‚Äù with 32 plays. These are songs that triple j have recorded at festivals, concerts etc. The ‚ÄúLike A Version‚Äù segment from triple j also contributed nine plays.\n312 songs (26%) of played songs are available on Unearthed.\nMost of the songs are fairly recent but there are some older ones (and probably a few where the dates are wrong)\n\n\n\nThe longest song played was ‚ÄúFools Gold‚Äù by The Stone Roses at almost 10 minutes long (9:54) and the shortest was ‚ÄúCounting Worms‚Äù by ‚ÄúKnocked Loose‚Äù at just over a minute (1:12)\nThe most popular songs played (according to Spotify) were ‚Äúgoosebumps‚Äù and ‚ÄúHIGHEST IN THE ROOM‚Äù by Travis Scott and ‚ÄúWHATS POPPIN‚Äù by Jack Harlow\nThe loudest song was ‚ÄúAsk For The Anthem‚Äù by Ocean Grove and the quietest was ‚ÄúWhat‚Äôs Up‚Äù by 4 Non Blondes\nThe fastest song was ‚Äú93 ‚ÄôTil Infinity‚Äù by Souls of Mischief and the slowest was ‚ÄúSoon‚Äù by Angie McMahon\nThe song with highest ‚Äúvalence‚Äù was ‚ÄúSeptember‚Äù by Earth, Wind & Fire and the lowest was ‚ÄúRaining Blood‚Äù by Slayer\nThe song with highest ‚Äúenergy‚Äù was ‚ÄúRaining Blood‚Äù by Slayer and the lowest was ‚ÄúIn Disguise‚Äù by Ashe\nThe song with highest ‚Äúdanceability‚Äù was ‚ÄúWash & Set‚Äù by Leikeli47 and the lowest was ‚ÄúI Still Dream About You‚Äù by The Smith Street Band\nThe song with highest ‚Äúspeechiness‚Äù was ‚ÄúRNP‚Äù by YBN Cordae and the lowest was ‚ÄúStrangers‚Äù by Tia Gostelow\nThe song with highest ‚Äúacousticness‚Äù was ‚ÄúPunching In A Dream‚Äù by The Naked And Famous1 and the lowest was ‚ÄúGo‚Äù by Pearl Jam\nThe song with highest ‚Äúliveness‚Äù was ‚ÄúFormation‚Äù by Beyonc√©2 and the lowest was ‚ÄúFit But You Know It‚Äù by The Streets"
  },
  {
    "objectID": "posts/2020-07-11-requestival/index.html#embedding",
    "href": "posts/2020-07-11-requestival/index.html#embedding",
    "title": "triple j‚Äôs Requestival",
    "section": "Embedding",
    "text": "Embedding\nNow that I had a look at each variable individually I wanted to see what the dataset looked like as a whole. The first thing you always do with a new dataset is a PCA so for the songs with Spotify data I took the duration, loudness, tempo, valence, energy, danceability, speechiness, acousticness and liveness. The scatter plots don‚Äôt look great but the loadings are interesting.\n\nFor example you can see that PC1 separates loudness and enery from acousticness and PC6 separates speeciness from valence and tempo.\nI then did a t-SNE using these principal components. I had hoped that this information might be enough to see some clear separation between genres or styles but this isn‚Äôt really the case. There are few variable which are restricted to one part of the space, for example liveness:\n\nBut most of the other variables just show a general trend like loudness.\n\nSee the embedding page if you would like to see what all the other variables look like."
  },
  {
    "objectID": "posts/2020-07-11-requestival/index.html#footnotes",
    "href": "posts/2020-07-11-requestival/index.html#footnotes",
    "title": "triple j‚Äôs Requestival",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThis got matched to the ‚ÄúStripped‚Äù version on Spotify‚Ü©Ô∏é\nThis got matched to the version from ‚ÄúHomecoming: The Live Album‚Äù‚Ü©Ô∏é"
  },
  {
    "objectID": "posts/2018-04-21-my-afl-elo-model/index.html",
    "href": "posts/2018-04-21-my-afl-elo-model/index.html",
    "title": "My AFL-Elo model",
    "section": "",
    "text": "Over the last few years I have followed a lot of the work done by FiveThiryEight, particularly their attempts to model and predict sport. More recently I have discovered there is a community of people trying to do similar things for the AFL, including The Arc, Squiggle, Matter of Stats and Hurling People Now.\nMany of these modelling projects are based around the Elo system. If you haven‚Äôt heard of it before this model is a ranking system originally designed for chess by a Hungarian physicist. In the simplest form each player (or team) is assigned a ranking. When a match is played you can estimate a win probability based on the differences between the rankings. The rankings are then adjusted based on the result in such a way that unexpected results cause bigger changes than those that are closer to what was predicted. This model is relatively naive and simple to implement, no knowledge of the players or teams themselves is required, just the results of matches, but can still produce good predictions.\nGiven this I thought it would be a good place to start. My version of the model is closely based on the one described by The Arc here. There were a few different things I wanted to try but (as always) everything took longer than I planned, so what I have done in the end is very similar. The one area where I have done things differently is the process used to select the parameters of the model. This part wasn‚Äôt really described in the post on The Arc so I was left to my own devices. Here are brief descriptions of the parameters, but if you are interested I suggest you check out the outline of the model on The Arc which has a lot more detail:\nTo select these parameters I chose to use a genetic optimisation algorithm. Partly because it is potentially able to explore a wider parameter space, but also because I think they are cool. To do this we need a measure of fitness that we are aiming for. For sport predictions there are generally two things we want to know, who is going to win and by how much. Estimating these can often be best done using different sets of parameters. For this reason I ran the optimisation procedure three times, once optimising for win prediction accuracy, once optimising for the mean absolute error in predicting the margin and once for a 50/50 balance between the two. Each optimisation procedure was run for 100 generations with 100 individuals in each generation, training the model on all AFL games from 1997 to 2016 and assessing performance on the games from 2000 to 2016. This leaves the 2017 season as a validation set to check the selected parameters. Here the best performing parameter sets from each of the optimisations compared to the default parameters based on The Arc:\nBased on the 2017 results I decided to go with the Margin model. Despite being optimised for margin accuracy it also performed the best at predicting results in 2017. This might suggest that the optimisation procedure is not ideal, but that is a problem for another day‚Ä¶ Encouragingly, all three of my models outperform the defaults, which suggests that the results will be somewhere in the range of the The Arc, and I am more than happy with that.\nIf you are interested in how I have done things I have made an aflelo R package which you can install from GitHub and my analysis and predictions for each round will be available here.\nNow that I have a model I can use it to make predictions about the 2018 season!"
  },
  {
    "objectID": "posts/2018-04-21-my-afl-elo-model/index.html#summary",
    "href": "posts/2018-04-21-my-afl-elo-model/index.html#summary",
    "title": "My AFL-Elo model",
    "section": "Summary",
    "text": "Summary\n\n\n\n\n\nTeam\n\n\nRating\n\n\nChange\n\n\nPoints\n\n\nPercentage\n\n\nProjRating\n\n\nProjPoints\n\n\nTop2\n\n\nTop4\n\n\nTop8\n\n\n\n\n\n\nRichmond\n\n\n1570\n\n\n19\n\n\n12\n\n\n130\n\n\n1555\n\n\n56.5\n\n\n28.2\n\n\n49.8\n\n\n78.9\n\n\n\n\nSydney\n\n\n1561\n\n\n-6\n\n\n12\n\n\n108\n\n\n1546\n\n\n56.9\n\n\n27.9\n\n\n49.4\n\n\n79.0\n\n\n\n\nGW Sydney\n\n\n1558\n\n\n0\n\n\n12\n\n\n140\n\n\n1544\n\n\n56.3\n\n\n27.5\n\n\n48.7\n\n\n79.4\n\n\n\n\nWest Coast\n\n\n1556\n\n\n21\n\n\n12\n\n\n136\n\n\n1545\n\n\n54.7\n\n\n23.0\n\n\n42.7\n\n\n74.9\n\n\n\n\nHawthorn\n\n\n1553\n\n\n34\n\n\n12\n\n\n127\n\n\n1539\n\n\n56.3\n\n\n26.9\n\n\n48.2\n\n\n78.7\n\n\n\n\nAdelaide\n\n\n1546\n\n\n-44\n\n\n8\n\n\n107\n\n\n1535\n\n\n50.7\n\n\n13.3\n\n\n29.7\n\n\n63.1\n\n\n\n\nGeelong\n\n\n1542\n\n\n10\n\n\n8\n\n\n109\n\n\n1532\n\n\n50.0\n\n\n12.0\n\n\n27.6\n\n\n61.3\n\n\n\n\nCollingwood\n\n\n1530\n\n\n44\n\n\n8\n\n\n107\n\n\n1521\n\n\n49.6\n\n\n11.1\n\n\n26.8\n\n\n59.1\n\n\n\n\nPort Adelaide\n\n\n1529\n\n\n-18\n\n\n12\n\n\n117\n\n\n1522\n\n\n51.9\n\n\n15.4\n\n\n32.5\n\n\n64.6\n\n\n\n\nNorth Melbourne\n\n\n1497\n\n\n28\n\n\n8\n\n\n134\n\n\n1499\n\n\n43.2\n\n\n4.7\n\n\n12.6\n\n\n38.4\n\n\n\n\nEssendon\n\n\n1494\n\n\n18\n\n\n8\n\n\n99\n\n\n1499\n\n\n40.7\n\n\n3.0\n\n\n8.5\n\n\n28.2\n\n\n\n\nMelbourne\n\n\n1493\n\n\n-34\n\n\n8\n\n\n98\n\n\n1495\n\n\n43.1\n\n\n3.8\n\n\n11.3\n\n\n35.5\n\n\n\n\nWestern Bulldogs\n\n\n1463\n\n\n6\n\n\n4\n\n\n72\n\n\n1470\n\n\n36.0\n\n\n0.7\n\n\n3.2\n\n\n16.3\n\n\n\n\nFremantle\n\n\n1458\n\n\n0\n\n\n8\n\n\n89\n\n\n1466\n\n\n39.3\n\n\n1.8\n\n\n5.9\n\n\n23.3\n\n\n\n\nSt Kilda\n\n\n1438\n\n\n-10\n\n\n4\n\n\n68\n\n\n1456\n\n\n29.4\n\n\n0.2\n\n\n1.1\n\n\n6.4\n\n\n\n\nGold Coast\n\n\n1415\n\n\n-21\n\n\n8\n\n\n83\n\n\n1433\n\n\n32.7\n\n\n0.4\n\n\n1.6\n\n\n9.1\n\n\n\n\nBrisbane\n\n\n1407\n\n\n-19\n\n\n0\n\n\n64\n\n\n1426\n\n\n24.3\n\n\n0.1\n\n\n0.3\n\n\n2.7\n\n\n\n\nCarlton\n\n\n1390\n\n\n-28\n\n\n0\n\n\n61\n\n\n1415\n\n\n20.5\n\n\n0.0\n\n\n0.1\n\n\n1.2"
  },
  {
    "objectID": "posts/2018-04-21-my-afl-elo-model/index.html#predictions",
    "href": "posts/2018-04-21-my-afl-elo-model/index.html#predictions",
    "title": "My AFL-Elo model",
    "section": "Predictions",
    "text": "Predictions"
  },
  {
    "objectID": "posts/2018-04-21-my-afl-elo-model/index.html#projections",
    "href": "posts/2018-04-21-my-afl-elo-model/index.html#projections",
    "title": "My AFL-Elo model",
    "section": "Projections",
    "text": "Projections\n\nLadder\n\n\n\nPremiership points"
  },
  {
    "objectID": "posts/2018-04-21-my-afl-elo-model/index.html#history",
    "href": "posts/2018-04-21-my-afl-elo-model/index.html#history",
    "title": "My AFL-Elo model",
    "section": "History",
    "text": "History"
  },
  {
    "objectID": "posts/2020-04-09-caching-blogdown/index.html",
    "href": "posts/2020-04-09-caching-blogdown/index.html",
    "title": "Caching blogdown posts",
    "section": "",
    "text": "This website is built using blogdown which is a great package that let‚Äôs you easily turn R Markdown documents into a Hugo blog. While a normal Markdown blog can include code a blogdown blog runs that code and includes the output. One thing that blogdown does which isn‚Äôt necessarily desirable is re-knit every R Markdown document whenever the site is built.1 This can slow down the build process but it can also result in changes to the content of a post. For example imagine a post that scraps some data from the internet. If that code is run a month or a year from now that data could have changed in a way that affects the meaning of the post. Perhaps a more likely scenario is changes to package functionality which change results or stop code working altogether. This post describes the build process I have come up with to try and avoid this happening."
  },
  {
    "objectID": "posts/2020-04-09-caching-blogdown/index.html#only-render-some-.rmd-files",
    "href": "posts/2020-04-09-caching-blogdown/index.html#only-render-some-.rmd-files",
    "title": "Caching blogdown posts",
    "section": "Only render some .Rmd files",
    "text": "Only render some .Rmd files\nWhen finding files to render the script also checks to see if there is a .md.cached file in the same directory and that it is newer than the .Rmd file.\nrmd_files &lt;- blogdown:::list_rmds(\"content\", TRUE)\nmessage(\"Found \", length(rmd_files), \" R Markdown files\")\nmd_files &lt;- sub(\"\\\\.Rmd$\", \".md.cached\", rmd_files)\n\n# Only knit Rmd files if...\nto_render &lt;- !file.exists(md_files) |             # md file does not exist OR\n    utils::file_test(\"-ot\", md_files, rmd_files)  # it is older than the Rmd\nIf the .md.cached file exists (and is newer) it is rendered instead of the .Rmd file.\nmessage(\"Rendering \", sum(!to_render), \" cached Markdown files...\")\nfor (md in md_files[!to_render]) {\n    message(\"Rendering \", md, \"...\")\n    render_md(md, base)\n}\nOtherwise the .Rmd file is rendered when required.\nmessage(\"Rendering \", sum(to_render), \" R Markdown files...\")\nfor (rmd in rmd_files[to_render]) {\n    message(\"Rendering \", rmd, \"...\")\n    render_rmd(rmd, base)\n}\nOne thing I found is important during the rendering process is that the YAML frontmatter is preprended to the output HTML file. I‚Äôm not entirely sure why but if you don‚Äôt do this the files aren‚Äôt included in the website properly by Hugo.\nblogdown:::prepend_yaml(md, out, x, callback = function(s) {\n    if (!getOption(\"blogdown.draft.output\", FALSE)) {\n        return(s)\n    }\n    if (length(s) &lt; 2 || length(grep(\"^draft: \", s)) &gt; 0) {\n        return(s)\n    }\n    append(s, \"draft: yes\", 1)\n})"
  },
  {
    "objectID": "posts/2020-04-09-caching-blogdown/index.html#keeping-intermediate-markdown-files",
    "href": "posts/2020-04-09-caching-blogdown/index.html#keeping-intermediate-markdown-files",
    "title": "Caching blogdown posts",
    "section": "Keeping intermediate Markdown files",
    "text": "Keeping intermediate Markdown files\nIn theory it should be possible to keep the intermediate Markdown file simply by setting keep_md: true in the document YAML frontmatter (or a central _output.yml file). Unfortunately that argument currently isn‚Äôt passed on in a way that works (see issue here). This means that we also need to create a custom render_page.R script. This script makes sure that the keep_md option is set when rendering .Rmd files.\noutput_format &lt;- rmarkdown::resolve_output_format(input)\noutput_format$keep_md &lt;- TRUE\nThe other thing we do is rename the kept intermediate Markdown files. If we Left them with the .md extension they would be rendered by Hugo after running the build script. I chose to name them .md.cached but they could have any extension."
  },
  {
    "objectID": "posts/2020-04-09-caching-blogdown/index.html#footnotes",
    "href": "posts/2020-04-09-caching-blogdown/index.html#footnotes",
    "title": "Caching blogdown posts",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nI‚Äôm not entirely sure this is correct and based on some comments from Yihui it might be possible to avoid this happening in a standard way but I have seen enough similar questions that it seems other people have run into the same problem.‚Ü©Ô∏é\nIt is acutally slightly more complicated than that. When method = \"html\" the R/build.R script is actually run after the normal process (if it exists) and can be used to do various things.‚Ü©Ô∏é"
  },
  {
    "objectID": "posts/2014-07-20-open-science-workshops/index.html",
    "href": "posts/2014-07-20-open-science-workshops/index.html",
    "title": "Open science workshops",
    "section": "",
    "text": "This Saturday I attended the first workshop run by Open Science Workshops at the Inspire9 collaborative workspace. Open Source Workshops is a new initiative aiming to promote open source tools and techniques to the scientific community.\nThe workshop consisted of two main parts: an introduction to the basics of Github (creating repositories, commiting, forking, merging‚Ä¶) and the SageMathCloud; and a serious of talks:\n\nGeneral discussion of how and why you should take an open approach to scientific research (Alex Ghitza, Pure Maths Lecturer, University of Melbourne).\nAuthorea - An online platform for collaborative manuscript editing designed for digital publishing that can combines Latex, Markdown etc. with interactive visualisations, embedded IPython notebooks and built in citation management (Andrea Bedini, Maths and Stats, University of Melbourne).\nSciRate - A social media approach to rating and sharing the papers available in at arXiv.org (Jaiden Mispy).\nSageMathCloud - Collaborative cloud platform set up with particular support for IPython and Latex as well as a terminal. Kind of like Google docs meets a VM.\nNeCTAR - Cloud facility available to Australian researchers. Also the Genomics Virtual Laboratory set up that allows quick launching of a VM with Galaxy and other bioinformatics tools as well as IPython and RStudio (Clare Sloggett, VLSCI).\nSoftware Capentry - Bootcamps for training in scientific computing includiang Git (work tracking), UNIX (automation), Programming (modularisation) and SQL (structured data) (Scott Ritchie).\neLIFE - A new open access life sciences journal in the UK that uses a consulative peer review process as well as their eLIFE Lens and oline system for viewing their papers or anything in PubMed via the OA Sandbox (Ian Mulvany).\n\nA common theme running through the talks (apart from open access) was the need to move towards 21st century tools and processes, both for collaboration and publishing.\nOverall it was a worthwhile experience and hopefully there will be more in the future, if you are interested in the details the talks and agenda are available here on Github."
  },
  {
    "objectID": "posts/index.html",
    "href": "posts/index.html",
    "title": "Posts",
    "section": "",
    "text": "scverse conference\n\n\n\n\n\n\nscverse\n\n\nconference\n\n\nsketchnotes\n\n\n\nRecap of the first scverse conference and sketchnotes of keynote talks\n\n\n\n\n\nSep 15, 2024\n\n\n2 min\n\n\n\n\n\n\n\n\n\n\n\n\nscRNA-tools low-maintenance mode\n\n\n\n\n\n\nscRNA-tools\n\n\ndatabase\n\n\n\nAnnouncement of the scRNA-tools database entering low-maintenance mode, some more detail and various thoughts\n\n\n\n\n\nMar 4, 2024\n\n\n3 min\n\n\n\n\n\n\n\n\n\n\n\n\nBioconductor 3.12 wrap-up\n\n\n\n\n\n\nbioconductor\n\n\nR\n\n\n\nMy wrap-up of the Bioconductor 3.12 release\n\n\n\n\n\nOct 30, 2020\n\n\n3 min\n\n\n\n\n\n\n\n\n\n\n\n\ntriple j‚Äôs Requestival\n\n\n\n\n\n\nanalysis\n\n\nmusic\n\n\n\nAnalysis of the songs played during triple j‚Äôs Requestival event\n\n\n\n\n\nJul 11, 2020\n\n\n9 min\n\n\n\n\n\n\n\n\n\n\n\n\nBack to the SCE-verse!\n\n\n\n\n\n\nbioconductor\n\n\nR\n\n\nscrna-seq\n\n\nSingleCellExperiment\n\n\nanalysis\n\n\n\nUpdated analysis of packages that use the SingleCellExperiment object in 2020\n\n\n\n\n\nMay 12, 2020\n\n\n10 min\n\n\n\n\n\n\n\n\n\n\n\n\nBioconductor 3.11 wrap-up\n\n\n\n\n\n\nbioconductor\n\n\nR\n\n\n\nMy wrap-up of the Bioconductor 3.11 release\n\n\n\n\n\nApr 29, 2020\n\n\n3 min\n\n\n\n\n\n\n\n\n\n\n\n\nCaching blogdown posts\n\n\n\n\n\n\nblogdown\n\n\nR\n\n\n\nDescription of how I cache blogdown Markdown files\n\n\n\n\n\nApr 9, 2020\n\n\n6 min\n\n\n\n\n\n\n\n\n\n\n\n\nExploring the SCE-verse\n\n\n\n\n\n\nbioconductor\n\n\nR\n\n\nscrna-seq\n\n\nSingleCellExperiment\n\n\nanalysis\n\n\n\nAnalysis of packages that use the SingleCellExperiment object\n\n\n\n\n\nJun 9, 2018\n\n\n14 min\n\n\n\n\n\n\n\n\n\n\n\n\nBioconductor 3.7 wrap-up\n\n\n\n\n\n\nbioconductor\n\n\nR\n\n\nscrna-seq\n\n\n\nA wrap-up of the Bioconductor 3.7 release\n\n\n\n\n\nMay 4, 2018\n\n\n4 min\n\n\n\n\n\n\n\n\n\n\n\n\nMy AFL-Elo model\n\n\n\n\n\n\nafl\n\n\nelo\n\n\nsport\n\n\n\nMy Elo model for predicting AFL games\n\n\n\n\n\nApr 21, 2018\n\n\n13 min\n\n\n\n\n\n\n\n\n\n\n\n\nWelcome to Blogdown!\n\n\n\n\n\n\nblogdown\n\n\n\nMy new Blogdown blog\n\n\n\n\n\nMar 24, 2018\n\n\n1 min\n\n\n\n\n\n\n\n\n\n\n\n\nJoining the Dots Twitter analysis\n\n\n\n\n\n\nconference\n\n\nvisualisation\n\n\ntwitter\n\n\n\nAnalysis of Twitter activity at the Joining the Dots visualisation symposium\n\n\n\n\n\nAug 18, 2017\n\n\n9 min\n\n\n\n\n\n\n\n\n\n\n\n\nBuilding a clustering tree\n\n\n\n\n\n\nR\n\n\nscrna-seq\n\n\nclustering tree\n\n\n\nIntroductory post to building a clustering tree\n\n\n\n\n\nJul 19, 2017\n\n\n32 min\n\n\n\n\n\n\n\n\n\n\n\n\nPyConAU 2016\n\n\n\n\n\n\npython\n\n\nconference\n\n\nthoughts\n\n\n\nMy thoughts after attending PyConAU 2016\n\n\n\n\n\nAug 18, 2016\n\n\n5 min\n\n\n\n\n\n\n\n\n\n\n\n\nGantt charts in R\n\n\n\n\n\n\nR\n\n\nproject management\n\n\ngantt chart\n\n\nexcel\n\n\n\nSteps for creating Gantt charts in R\n\n\n\n\n\nJun 13, 2016\n\n\n8 min\n\n\n\n\n\n\n\n\n\n\n\n\nBioconductor 3.3 packages\n\n\n\n\n\n\nR\n\n\nbioconductor\n\n\n\nWrap up of new packages in the Bioconductor 3.3 release\n\n\n\n\n\nMay 3, 2016\n\n\n1 min\n\n\n\n\n\n\n\n\n\n\n\n\nExtracting alignment statistics using Python\n\n\n\n\n\n\npython\n\n\nalignment\n\n\nstatistics\n\n\n\nA Python script for extracting alignment statistics from BAM files\n\n\n\n\n\nMar 30, 2016\n\n\n2 min\n\n\n\n\n\n\n\n\n\n\n\n\nMy Markdown thesis\n\n\n\n\n\n\nwriting\n\n\nmarkdown\n\n\nthesis\n\n\nlatex\n\n\n\nA description of the setup for building my Masters thesis using Markdown and Pandoc\n\n\n\n\n\nSep 13, 2015\n\n\n3 min\n\n\n\n\n\n\n\n\n\n\n\n\nOpen science workshops\n\n\n\n\n\n\nopen science\n\n\nworkshop\n\n\ncollaboration\n\n\n\nThis Saturday I attended the first workshop run by Open Science Workshops at the Inspire9 collaborative workspace\n\n\n\n\n\nJul 20, 2014\n\n\n2 min\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/2018-05-04-bioconductor-3-7-wrap-up/index.html",
    "href": "posts/2018-05-04-bioconductor-3-7-wrap-up/index.html",
    "title": "Bioconductor 3.7 wrap-up",
    "section": "",
    "text": "The Bioconductor 3.7 release was announced this week. I thought I would have a look through the new packages and changes to existing packages and point out some of my highlights. The descriptions below are my summaries, if you want to see more detail you can read the full release notes here."
  },
  {
    "objectID": "posts/2018-05-04-bioconductor-3-7-wrap-up/index.html#new-packages",
    "href": "posts/2018-05-04-bioconductor-3-7-wrap-up/index.html#new-packages",
    "title": "Bioconductor 3.7 wrap-up",
    "section": "New packages",
    "text": "New packages\n\nBEARscc - noise estimation tool to assess scRNA-seq clusters\nccfindR - collection of tools for cancer scRNA-seq analysis, including meta-gene identification and trees of cell clusters\nDESingle - detects three types of differential expression betweeen two groups of cells, differential expression status, differential expression abundance and general differential expression\nDropletUtils - utility functions for handling data from droplet technologies like the 10x Chromium\niSEE - Interactive SummarizedExperiment Explorer, Shiny-based GUI for exploring data in SummarizedExperiment objects, with special attention given to SingleCellExperiment\n\n\n\n\nExample iSEE window\n\n\n\nLineagePulse - differential expression and expression model fitting package for scRNA-seq, accounting for batch effects, dropout and sequencing depth\nMetaNeighbour - quantify cell type replicability across datasets\nnetSmooth - imputation of scRNA-seq data using biological networks\nscFeatureFilter - correlation based method for removing genes affected by systematic noise\nsingleCellTK - Shiny-based interactive scRNA-seq analysis toolkit\nTENxBrainData - scRNA-seq data from 1.3 million mouse brain cells\nsimpleSingleCell - workflow implementing low-level scRNA-seq analysis using scran, scater and other Bioconductor packages"
  },
  {
    "objectID": "posts/2018-05-04-bioconductor-3-7-wrap-up/index.html#updates",
    "href": "posts/2018-05-04-bioconductor-3-7-wrap-up/index.html#updates",
    "title": "Bioconductor 3.7 wrap-up",
    "section": "Updates",
    "text": "Updates\n\nAUCell - new Shiny app and plotting functions, support for sparse matrices\nclusterExperiment - support for hdf5 files and SingleCellExperiment objects\nmonocle - changes to clustering algorithms\nscater - changes to calculateQCMetrics() and plotting functions, some functionality moved to new packages\nscDD - proportion of zeros test now use the Wald test instead of likelihood ratio, performance improvements\nscran - various bug fixes, improvments and new arguments\nSingleCellExperiment - new functions for clearing and setting information\nsplatter - new options for Splat simulation library size and dropout parameters, new SparseDC simulation, improvfed print output\nzinbwave - now uses counts assay by default, uses can specify which assay to use, computational weights now saved as an assay, improved documentation"
  },
  {
    "objectID": "posts/2018-05-04-bioconductor-3-7-wrap-up/index.html#new-packages-1",
    "href": "posts/2018-05-04-bioconductor-3-7-wrap-up/index.html#new-packages-1",
    "title": "Bioconductor 3.7 wrap-up",
    "section": "New packages",
    "text": "New packages\n\nenrichplot - ggplot2 based functions for visualising gene-set enrichment results\n\n\n\n\nnetwork plot from enrichplot\n\n\n\nGARS - feature selection for high-dimensional datasets using genetic algorithms\nplyranges - dplyr-like interface for Range and GenomicRanges objects\nPowerExplorer - simulation based power calculations\nsingscore - rank-based single-sample gene set scoring method\nSummarizedBenchmark - BenchDesign and SummarizedBenchmark classes for building, executing and evaluating software benchmark experiments\nvidger - function for visualising differential expression results from Cuffdiff, DESeq2 and edgeR\n\n\n\n\nExample plot from vidger\n\n\n\nBiocMetaWorkflow - workflow describing how to use BiocWorkflowTools to submit a single R Markdown document to both Bioconductor and F1000Research"
  },
  {
    "objectID": "posts/2018-05-04-bioconductor-3-7-wrap-up/index.html#updates-1",
    "href": "posts/2018-05-04-bioconductor-3-7-wrap-up/index.html#updates-1",
    "title": "Bioconductor 3.7 wrap-up",
    "section": "Updates",
    "text": "Updates\n\nDESeq2 - performance improvements and deprecation of designs without replicates\nedgeR - new read10X(), nearestTSS(), nearestReftoX(), modelMatrixMeth() and filterByExpr() functions\nGenomicRanges - GenomicRanges is now a list subclass, performance improvements\nminfi - preliminary support for DelayedArray minfi objects\nSummarizedExperiment - new subset method\ntximport - support for StringTie output"
  },
  {
    "objectID": "posts/2018-03-24-welcome-to-blogdown/index.html",
    "href": "posts/2018-03-24-welcome-to-blogdown/index.html",
    "title": "Welcome to Blogdown!",
    "section": "",
    "text": "Welcome to Blogdown!\nI‚Äôve just finished migrating this blog from Ghost to Blogdown. Ghost was great in a lot a ways but Blogdown adds the ability to write in RMarkdown which I‚Äôm hoping will encourage me to post more often, particularly on things that include some code or analysis.\nThanks to everyone who has written about their experiences with Blogdown. I didn‚Äôt keep track of the resources I found useful so I can‚Äôt point them out but they definitely made the process easier.\nSee you around!"
  },
  {
    "objectID": "posts/2020-05-12-back-to-the-sce-verse/index.html",
    "href": "posts/2020-05-12-back-to-the-sce-verse/index.html",
    "title": "Back to the SCE-verse!",
    "section": "",
    "text": "A few weeks ago I did a short wrap up of the latest Bioconductor 3.11 release. The last time I did that (for the 3.7 release in 2018) I followed it up with a post looking at packages which depend on the {SingleCellExperiment} package. A lot has changed in the scRNA-seq world over the last two years and we have grown from around 200 analysis tools to almost 650. Given that growth I thought it would be good to repeat that analysis and see what the SCE-verse looks like in 2020."
  },
  {
    "objectID": "posts/2020-05-12-back-to-the-sce-verse/index.html#where-are-the-packages-from",
    "href": "posts/2020-05-12-back-to-the-sce-verse/index.html#where-are-the-packages-from",
    "title": "Back to the SCE-verse!",
    "section": "Where are the packages from?",
    "text": "Where are the packages from?\nBefore we look at the relationships between packages let‚Äôs look at the reverse dependencies themselves. We expect that most of the dependencies will be other Bioconductor packages but are there any in CRAN?\nggplot(revdeps, aes(x = Repo, fill = Repo)) +\n    geom_bar() +\n    scale_fill_brewer(palette = \"Dark2\") +\n    theme_minimal()\n\nThere are only 2 packages from CRAN, which are the same two we saw last time. These are {Seurat}, which contains the other major R object for scRNA-seq data and includes functions for converting from {SingleCellExperiment} objects, and {clustree}, my package for visualising clustering across resolutions which includes a {SingleCellExperiment} interface."
  },
  {
    "objectID": "posts/2020-05-12-back-to-the-sce-verse/index.html#what-dependency-do-they-have",
    "href": "posts/2020-05-12-back-to-the-sce-verse/index.html#what-dependency-do-they-have",
    "title": "Back to the SCE-verse!",
    "section": "What dependency do they have?",
    "text": "What dependency do they have?\nWhat about the types of dependencies?\nedges %&gt;%\n    filter(dependency == \"SingleCellExperiment\") %&gt;%\n    ggplot(aes(x = edgetype, fill = edgetype)) +\n    geom_bar() +\n    scale_fill_brewer(palette = \"Dark2\") +\n    theme_minimal()\n\nMost of the packages either ‚Äúimport‚Äù or ‚Äúdepend‚Äù on {SingleCellExperiment}. This is unsurprising given that is a core data structure. I suspect most of the ‚Äúsuggests‚Äù packages work with several data structures but we would have to check this and see."
  },
  {
    "objectID": "posts/2020-05-12-back-to-the-sce-verse/index.html#what-do-they-do",
    "href": "posts/2020-05-12-back-to-the-sce-verse/index.html#what-do-they-do",
    "title": "Back to the SCE-verse!",
    "section": "What do they do?",
    "text": "What do they do?\nAll packages in Bioconductor are annotated with ‚ÄúbiocViews‚Äù. There are a set of labels designed to show what a package can be used for. They provide a convenient way to get a overview of what the packages in the SCE-verse do.\nbioc_views &lt;- bioc_pkgs %&gt;%\n    filter(Package %in% revdeps$Package) %&gt;%\n    select(biocViews) %&gt;%\n    unnest(biocViews) %&gt;%\n    mutate(biocViews = fct_lump_n(fct_infreq(biocViews), 30))\n\nggplot(bioc_views, aes(x = fct_rev(biocViews))) +\n    geom_bar() +\n    coord_flip() +\n    ggtitle(\"Most common biocViews\") +\n    ylab(\"Number of packages\") +\n    theme_minimal() +\n    theme(axis.title.y = element_blank())\n\nMany of the most common biocViews are fairly general terms but there is a set that stands out as being specific to scRNA-seq data including ‚ÄúSingleCell‚Äù, ‚ÄúGeneExpression‚Äù, ‚ÄúRNASeq‚Äù and ‚ÄúTranscriptomics‚Äù. Further down the list we see terms related to specific analysis tasks (‚ÄúClustering‚Äù, ‚ÄúVisualization‚Äù, ‚ÄúDifferentialExpression‚Äù, ‚ÄúDimensionReduction‚Äù, ‚ÄúNormalization‚Äù etc.). Many of these are similar to the categories we came up with to group tools on scRNA-tools. It would be interesting to look at the differences in ranking but I suspect there are enough differences in how the terms are used that it would be difficult to compare them."
  },
  {
    "objectID": "posts/2018-05-20-exploring-the-sce-verse/index.html",
    "href": "posts/2018-05-20-exploring-the-sce-verse/index.html",
    "title": "Exploring the SCE-verse",
    "section": "",
    "text": "Over the last few years the number of methods for analysing scRNA-seq has exploded and there is now well over 200 software tools available. Each of these tools need to make a choice about how they store and represent the data used during their analysis. One attempt to standardise the data structures that are used is the SingleCellExperiment package created by Davide Risso and Aaron Lun, with help from Keegan Korthauer. This package became publicly available as part of the Bioconductor 3.6 release in October 2017. Since we have recently had another Bioconductor release I thought I would have a look at the community of tools that has been developed around SingleCellExperiment.\n\nWhat is a SingleCellExperiment?\nBefore we have a look at what packages use the SingleCellExperiment it‚Äôs probably useful to briefly discuss what it is. The SingleCellExperiment object is an extension of the older SummarizedExperiment object. This is an S4 class developed for use in Bioconductor packages with the main parts being a central set of matrix ‚Äúassays‚Äù along with tables providing extra information about the rows and columns. There is also a metadata slot which is a list containing any other information related to the experiment.\n\n\n\nDiagram of a SummarizedExperiment object\n\n\nOne of the key benefits of using a structure like the SummarizedExperiment is that all the data related to an analysis is held in one spot. This makes it easier to pass things between functions or output results as well as reducing the possibilities for mismatches. The SingleCellExperiment adds some extra features that are useful for scRNA-seq analysis including:\n\nSlots for holding:\n\nDimenstionality reductions\nSpike-in information\nSize factors for normalisation\n\nConvenient access for named assays - counts, normcounts, cpm etc.\n\nThe idea is then that the SingleCellExperiment can be used by a range of packages to store data during analysis and extended when required. Let‚Äôs have a look at what those packages are currently by seeing what depends on SingleCellExperiment.\n\n\nGetting package information\nFirst let‚Äôs load the packages we need for this analysis. BiocPkgTools will need to be installed from GitHub but the rest are on CRAN.\nlibrary(\"BiocPkgTools\") # https://github.com/seandavi/BiocPkgTools\nlibrary(\"tidygraph\")\nlibrary(\"ggraph\")\nlibrary(\"tidyverse\")\nWe can use Sean Davis‚Äô BiocPkgTools package to get information about Bioconductor packages, but then we need to do some filtering to get the information we want. It turns out I needed to do this multiple times so here is a function I wrote to make it a bit easier. It takes the database of information about all Bioconductor packages, the name of a package we are interested in and a flag indicating if we want normal or reverse dependencies.\nget_bioc_deps &lt;- function(bpi, pkg, reverse) {\n    deps &lt;- bpi %&gt;%\n        filter(Package == pkg)\n\n    if (reverse) {\n        deps &lt;- deps %&gt;%\n            select(depends = dependsOnMe, imports = importsMe,\n                   suggests = suggestsMe)\n    } else {\n        deps &lt;- deps %&gt;%\n            select(depends = Depends, imports = Imports,\n                   suggests = Suggests)\n    }\n\n    deps &lt;- deps %&gt;%\n        gather(key = \"type\", value = \"package\") %&gt;%\n        separate_rows() %&gt;%\n        filter(!is.na(package))\n\n    if (reverse) {\n        deps &lt;- deps %&gt;%\n            mutate(package2 = pkg) %&gt;%\n            rename(package1 = package)\n    } else {\n        deps &lt;- deps %&gt;%\n            mutate(package1 = pkg) %&gt;%\n            rename(package2 = package)\n    }\n\n    deps &lt;- deps %&gt;% select(package1, uses = type, package2)\n}\nIf we use it to search for reverse dependencies of SingleCellExperiment we can see it returns a data frame with which Bioconductor packages use SingleCellExperiment and the relationship between them.\nbpi &lt;- getBiocPkgList()\nbioc_revdeps &lt;- get_bioc_deps(bpi, \"SingleCellExperiment\", reverse = TRUE)\nhead(bioc_revdeps)\nWe can do a similar thing for CRAN packages with use of the tools::package_dependencies function.\nget_cran_deps &lt;- function(pkg, db, reverse) {\n\n    types &lt;- c(\"Depends\", \"Imports\", \"Suggests\")\n\n    deps &lt;- sapply(types, function(type) {\n        deps &lt;- tools::package_dependencies(pkg, db, which = type,\n                                            reverse = reverse)\n        c(type = type, package = paste(deps[[1]], collapse = \", \"))\n    })\n\n    deps &lt;- deps %&gt;%\n        t() %&gt;%\n        as_data_frame() %&gt;%\n        mutate(type = tolower(type)) %&gt;%\n        filter(package != \"\") %&gt;%\n        separate_rows(package)\n\n    if (nrow(deps) == 0) {\n        return(tibble(package1 = character(), uses = character(),\n                      package2 = character()))\n    }\n\n    if (reverse) {\n        deps &lt;- deps %&gt;%\n            mutate(package2 = pkg) %&gt;%\n            rename(package1 = package)\n    } else {\n        deps &lt;- deps %&gt;%\n            mutate(package1 = pkg) %&gt;%\n            rename(package2 = package)\n    }\n\n    deps &lt;- deps %&gt;% select(package1, uses = type, package2)\n}\ndb &lt;- available.packages(repos = \"http://cran.r-project.org\")\ncran_revdeps &lt;- get_cran_deps(\"SingleCellExperiment\", db, reverse = TRUE)\nhead(cran_revdeps)\n\n\nWhat uses SingleCellExperiment?\nWe now have two tables showing us which Bioconductor and CRAN packages make use of SingleCellExperiment. Tables can be fairly boring to look at though so let‚Äôs use the relationships to construct a graph using tidygraph.\nnodes &lt;- bioc_revdeps %&gt;%\n    bind_rows(cran_revdeps) %&gt;%\n    select(-uses) %&gt;%\n    gather(key = id, value = package) %&gt;%\n    select(-id) %&gt;%\n    distinct() %&gt;%\n    mutate(repo = if_else(package %in% bpi$Package, \"Bioconductor\", \"CRAN\"))\nedges &lt;- bioc_revdeps %&gt;%\n    bind_rows(cran_revdeps) %&gt;%\n    rename(from = package1, to = package2)\ngraph &lt;- tbl_graph(nodes = nodes, edges = edges)\nWe can now visualise the relationships using ggraph:\nggraph(graph, layout = \"fr\") +\n    geom_edge_fan(aes(colour = uses),\n                  arrow = arrow(length = unit(4, 'mm')),\n                  end_cap = circle(3, 'mm')) +\n    geom_node_point(aes(colour = repo)) +\n    geom_node_text(aes(label = package, colour = repo), repel = TRUE) +\n    scale_color_brewer(palette = \"Set1\") +\n    scale_edge_color_brewer(palette = \"Dark2\") +\n    theme_graph()\n\nThis doesn‚Äôt tell us a lot we didn‚Äôt already know but it does allow us to see everything in one place. We can see that there are only a couple of CRAN packages, which is unsurprising given that SingleCellExperiment is part of Bioconductor, and that most packages either ‚Äúimport‚Äù or ‚Äúdepend‚Äù on SingleCellExperiment.\nWhat about the relationships between the packages that depend on SingleCellExperiment? Are there communitites of related scRNA-seq analysis tools?\n\n\nAdding an extra hop\nWe can reuse the functions we wrote earlier to get the dependencies (and reverse dependencies) of our list of scRNA-seq packages. We will also do a little bit of extra processing to tidy up some of the results.\nmore_deps &lt;- map2(nodes$package, nodes$repo, function(x, y) {\n    if (y == \"Bioconductor\") {\n        get_bioc_deps(bpi, x, FALSE)\n    } else {\n        get_cran_deps(x, db, FALSE)\n    }\n}) %&gt;%\n    bind_rows() %&gt;%\n    mutate(package2 = str_remove(package2, \" ?\\\\(\\\\D+[0-9\\\\.]+\\\\)\")) %&gt;%\n    filter(package2 != \"R\")\nmore_revdeps &lt;- map2(nodes$package, nodes$repo, function(x, y) {\n    if (y == \"Bioconductor\") {\n        get_bioc_deps(bpi, x, TRUE)\n    } else {\n        get_cran_deps(x, db, TRUE)\n    }\n}) %&gt;% bind_rows()\nLet‚Äôs build another graph and plot what we get. As you can see it‚Äôs a bit crowded so I have left off the package labels.\nnodes &lt;- more_deps %&gt;%\n    bind_rows(more_revdeps) %&gt;%\n    select(-uses) %&gt;%\n    gather(key = id, value = package) %&gt;%\n    select(-id) %&gt;%\n    distinct() %&gt;%\n    mutate(repo = if_else(package %in% bpi$Package, \"Bioconductor\", \"CRAN\"))\nedges &lt;- more_deps %&gt;%\n    bind_rows(more_revdeps) %&gt;%\n    rename(from = package1, to = package2) %&gt;%\n    distinct()\ngraph &lt;- tbl_graph(nodes = nodes, edges = edges)\nggraph(graph, layout = \"fr\") +\n    geom_edge_fan(aes(colour = uses),\n                  arrow = arrow(length = unit(4, 'mm')),\n                  end_cap = circle(3, 'mm')) +\n    geom_node_point(aes(colour = repo)) +\n    #geom_node_text(aes(label = package, colour = repo), repel = TRUE) +\n    scale_color_brewer(palette = \"Set1\") +\n    scale_edge_color_brewer(palette = \"Dark2\") +\n    theme_graph()\n\nOur graph has a lot more information now, but is probably too complext to tell us anything useful. In particularly we can see there are a lot of nodes around the edges that have one package depending on them. Let‚Äôs get rid of those by removing sink node.\ngraph &lt;- tbl_graph(nodes = nodes, edges = edges) %&gt;%\n    activate(nodes) %&gt;%\n    filter(!node_is_sink())\nggraph(graph, layout = \"fr\") +\n    geom_edge_fan(aes(colour = uses),\n                   arrow = arrow(length = unit(4, 'mm')),\n                   end_cap = circle(3, 'mm')) +\n    geom_node_point(aes(colour = repo)) +\n    geom_node_text(aes(label = package, colour = repo), size = 2,\n                   repel = TRUE) +\n    scale_color_brewer(palette = \"Set1\") +\n    scale_edge_color_brewer(palette = \"Dark2\") +\n    theme_graph()\n\nThat‚Äôs much better! We can now see some of the structure between our packages. There are quite few packages that rely on SingleCellExperiment but nothing else. Removing source nodes as well will tidy this up a bit more.\ngraph &lt;- tbl_graph(nodes = nodes, edges = edges) %&gt;%\n    activate(nodes) %&gt;%\n    filter(!node_is_sink()) %&gt;%\n    filter(!node_is_source())\nggraph(graph, layout = \"fr\") +\n    geom_edge_fan(aes(colour = uses),\n                   arrow = arrow(length = unit(4, 'mm')),\n                   end_cap = circle(3, 'mm')) +\n    geom_node_point(aes(colour = repo)) +\n    geom_node_text(aes(label = package, colour = repo),\n                   repel = TRUE) +\n    scale_color_brewer(palette = \"Set1\") +\n    scale_edge_color_brewer(palette = \"Dark2\") +\n    theme_graph()\n\nNow we can see the core SingleCellExperiment package network. Apart from SingleCellExperiment itself there are three main packages: scater, scran and splatter. Scater and scran are two low-level scRNA-seq analysis package with scater providing functions for tasks such as visualisation and filtering and scran focusing more on normalisation and removal of batch effects. It is unsurprising that these packages show up as Aaron Lun is heavily involved in the development of both of them as well as SingleCellExperiment. Splatter is a bit of a different case as it suggests many packages that provide the core functions for it‚Äôs simulations but isn‚Äôt used by any other analysis packages. There are a few other influential packages on the periphery of this network, particularly monocle and Seurat.\n\n\nWhat do these packages do?\nWe have had a look at how packages that use SingleCellExperiment are related but what do they actually do? Bioconductor categorises packages using ‚ÄúbiocViews‚Äù, tags that describe software in various ways. Let‚Äôs summarise those for the packages that use SingleCellExperiment.\nplot_data &lt;- bpi %&gt;%\n    filter(Package %in% bioc_revdeps$package1) %&gt;%\n    select(Package, biocViews) %&gt;%\n    separate_rows(biocViews) %&gt;%\n    group_by(biocViews) %&gt;%\n    summarise(count = n()) %&gt;%\n    arrange(-count) %&gt;%\n    mutate(prop = count / n()) %&gt;%\n    mutate(biocViews = factor(biocViews, level = biocViews))\nggplot(plot_data, aes(x = biocViews, y = prop)) +\n    geom_col() +\n    scale_y_continuous(labels = scales::percent) +\n    ggtitle(\"biocViews for packages that use SingleCellExperiment\") +\n    theme_minimal() +\n    theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5),\n          axis.title = element_blank(),\n          panel.grid = element_blank())\n\nUnsurprisingly the top few categories (‚ÄúSingleCell‚Äù, ‚ÄúGeneExpression‚Äù, ‚ÄúRNASeq‚Äù, ‚ÄúTranscriptomics‚Äù, ‚ÄúSequencing‚Äù) are related to scRNA-seq data in general, along with the ‚ÄúSoftware‚Äù tag. I actually find it a bit surprising that these aren‚Äôt more common with only  66 percent of packages labelled as ‚ÄúSingleCell‚Äù. After these we have some of the most common scRNA-seq analysis tasks, ‚ÄúClustering‚Äù, ‚ÄúVisualization‚Äù, ‚ÄúDifferentialExpression‚Äù and ‚ÄúDimensionReduction‚Äù. This is similar to what we see in the scRNA-tools database, but obviously from a much smaller sample.\nWe can‚Äôt do the same thing for the CRAN packages, but as there are only a couple of these we can just describe them. Seurat is perhaps the most complete R scRNA-seq analysis covering most steps in a standard workflow. It‚Äôs connection to SingleCellExperiment is through functions that have recently been added to convert to/from it‚Äôs own object. Clustree is a package for visualising clustering results in general and suggests SingleCellExperiment to provide a convenience function for people working with scRNA-seq data.\n\n\nWhere to from here?\nIt‚Äôs only been about six months since SingleCellExperiment joined Bioconductor release but we are already seeing a community of packages growing up around it. Hopefully we see this continue and there is a new batch of packages using it in the next Bioconductor release. For anyone who is working on a scRNA-seq package I strongly encourage you to consider basing it around SingleCellExperiment. It can take some time to get your head around how it works but the infrastructure it provides will save you a lot of time in the long run. It also makes things a lot easier for your uses who won‚Äôt have to learn a new data structure to use your package and can make use of a range of packages without having to convert between objects. If you don‚Äôt want to be locked into the Bioconductor ecosystem think about using the Seurat object instead or if you work in Python consider the anndata object. There is also the loom format which has both R and Python interfaces. Whatever standard works for you everyone will be better off if the community can make use of a small number of data structure rather than each package using their own."
  },
  {
    "objectID": "posts/2016-06-13-gantt-charts-in-r/index.html",
    "href": "posts/2016-06-13-gantt-charts-in-r/index.html",
    "title": "Gantt charts in R",
    "section": "",
    "text": "Gantt charts are a project management tool designed to visualise the tasks in a project, how long they will take and what order they must be completed. If you haven‚Äôt seen one before essentially they look like a modified horizontal bar chart. Along the horizontal axis is time with tasks along the vertical. Each task consists of a bar where the ends are the start and end times. Often there are also arrows indicating dependencies and a line showing the current date.\nAs part of the proposal for my PhD project I wanted to include a Gantt chart, both as a way of showing what I planned to do and as a way of keeping track of my progress. I expected there to be a simple template for Excel or Google Sheets but there wasn‚Äôt much and they didn‚Äôt quite fit what I wanted. Looking elsewhere didn‚Äôt turn up much either. What I wanted was a tool where I could enter tasks and dates in text format and produce a relatively attractive chart that I could easily update. In the end I turned to faithful old R, which had the added advantage that I could easily incorporate the chart into R Markdown documents.\nThere are a couple of packages that can make Gantt charts in R including plotrix and plan but in the end I went with DiagrammeR. The Gantt functionality of DiagrammeR depends on Mermaid which has a simple, almost markdown-like syntax.\ngantt\ndateFormat  YYYY-MM-DD\ntitle My Gantt chart\n\nsection First section\nTask 1            :done,    des1, 2014-01-06, 2014-01-08\nTask 2            :active,  des2, 2014-01-09, 3d\nTask 3            :         des3, after des2, 5d\nTask 4            :         des4, after des3, 5d\nBasically each task is written as:\nTask name         :status, label, start_date, end_date\nWhere the start and end dates can also include durations or references to other tasks.\nWhile this format is easy to use I prefer to use a standard delimited format which is easier to edit and read into R. To this end I created some functions which will take a CSV or XLSX file and produce a Gantt chart.\nlibrary(\"magrittr\")\n\n# Take a data.frame containing tasks and build a Mermaid string\ntasks2string &lt;- function(tasks) {\n\n    tasks.list &lt;- split(tasks,\n                        factor(tasks$Section, levels = unique(tasks$Section)))\n\n    strings &lt;- sapply(names(tasks.list),\n                      function(section) {\n                          tasks.list[[section]] %&gt;%\n                              dplyr::select(-Section) %&gt;%\n                              tidyr::unite(Part1, Task, Priority,\n                                           sep = \": \") %&gt;%\n                              tidyr::unite(String, Part1, Status, Name, Start,\n                                           End, sep = \", \") %&gt;%\n                              magrittr::use_series(\"String\") %&gt;%\n                              paste(collapse = \"\\n\") %&gt;%\n                              gsub(\" ,\", \"\", .) # Remove empty columns\n                          }\n                      )\n\n    string &lt;- \"\"\n\n    for(section in names(strings)) {\n        string &lt;- paste0(string, \"\\n\",\n                         \"section \", section, \"\\n\",\n                         strings[section],\n                         \"\\n\")\n    }\n\n    return(string)\n}\n\n# Produce a Gantt chart from data.frame of tasks\n# Adds the Mermaid header to the tasks string\nbuildGantt &lt;- function(tasks) {\n\n    gantt.string &lt;- paste0(\"gantt\", \"\\n\",\n                           \"dateformat YYYY-MM-DD\", \"\\n\",\n                           \"title My Gantt Chart\",\n                           \"\\n\")\n\n    gantt.string &lt;- paste0(gantt.string, tasks2string(tasks))\n\n    gantt &lt;- DiagrammeR::mermaid(gantt.string)\n\n    gantt$x$config = list(ganttConfig = list(\n        # Make sure the axis labels are formatted correctly\n        axisFormatter = list(list(\n            \"%m-%y\", # New data format\n            htmlwidgets::JS('function(d){ return d}') # Select dates to format\n        ))\n    ))\n\n    return(gantt)\n}\n\n# Read a file and return a Gantt chart\nbuildGanttFromFile &lt;- function(tasks.file, format = c(\"csv\", \"xlsx\")) {\n\n    format &lt;- match.arg(format)\n\n    switch(format,\n           csv = {\n               tasks &lt;- read.csv(tasks.file, stringsAsFactors = FALSE)\n           },\n           xlsx = {\n               tasks &lt;- gdata::read.xls(tasks.file)\n           })\n\n    return(buildGantt(tasks))\n}\nI can now construct my tasks by editing a CSV file and produce a Gantt chart directly from that by calling a single function. You may wonder why I have included XLSX as an input option? Surely using Excel is against the principles of data science? Firstly I‚Äôm not that opposed to Excel (when it is used correctly) but the reason in this case it is to get around one of the limitations of DiagrammeR. The Mermaid syntax allows you to define a task as starting after another task but you can‚Äôt say that a task ends before another. There are often situations where you have a hard end deadline (such as a PhD committee meeting) and you need to work backwards from that. By using Excel I can use simple formulas to calculate the dates which are then passed to R. I could do this programmatically in R (and I might at some stage) but Excel was a quicker solution that let me get on to writing."
  },
  {
    "objectID": "posts/2017-08-18-joining-the-dots-twitter-analysis/index.html",
    "href": "posts/2017-08-18-joining-the-dots-twitter-analysis/index.html",
    "title": "Joining the Dots Twitter analysis",
    "section": "",
    "text": "Today I attended the Joining the Dots visualisation symposium. You can see the slides for my talk about clustering trees here. It was a great event and hope we see more meetings like this in the future. Here is an analysis of the Twitter activity on the #jtdwehi hashtag, thanks to code from Neil Saunders. You can see it on Github."
  },
  {
    "objectID": "posts/2017-08-18-joining-the-dots-twitter-analysis/index.html#search-all-the-hashtags",
    "href": "posts/2017-08-18-joining-the-dots-twitter-analysis/index.html#search-all-the-hashtags",
    "title": "Joining the Dots Twitter analysis",
    "section": "Search all the hashtags!",
    "text": "Search all the hashtags!"
  },
  {
    "objectID": "posts/2017-08-18-joining-the-dots-twitter-analysis/index.html#tweets-by-day",
    "href": "posts/2017-08-18-joining-the-dots-twitter-analysis/index.html#tweets-by-day",
    "title": "Joining the Dots Twitter analysis",
    "section": "Tweets by day",
    "text": "Tweets by day"
  },
  {
    "objectID": "posts/2017-08-18-joining-the-dots-twitter-analysis/index.html#tweets-by-day-and-time",
    "href": "posts/2017-08-18-joining-the-dots-twitter-analysis/index.html#tweets-by-day-and-time",
    "title": "Joining the Dots Twitter analysis",
    "section": "Tweets by day and time",
    "text": "Tweets by day and time\nFiltered for dates July 21-26, Prague time."
  },
  {
    "objectID": "posts/2017-08-18-joining-the-dots-twitter-analysis/index.html#top-tweeters",
    "href": "posts/2017-08-18-joining-the-dots-twitter-analysis/index.html#top-tweeters",
    "title": "Joining the Dots Twitter analysis",
    "section": "Top tweeters",
    "text": "Top tweeters"
  },
  {
    "objectID": "posts/2017-08-18-joining-the-dots-twitter-analysis/index.html#sources",
    "href": "posts/2017-08-18-joining-the-dots-twitter-analysis/index.html#sources",
    "title": "Joining the Dots Twitter analysis",
    "section": "Sources",
    "text": "Sources"
  },
  {
    "objectID": "posts/2017-08-18-joining-the-dots-twitter-analysis/index.html#replies",
    "href": "posts/2017-08-18-joining-the-dots-twitter-analysis/index.html#replies",
    "title": "Joining the Dots Twitter analysis",
    "section": "Replies",
    "text": "Replies\nThe ‚Äúreplies network‚Äù, composed from users who reply directly to one another, coloured by page rank.\nBetter to view the original PNG file in the data directory."
  },
  {
    "objectID": "posts/2017-08-18-joining-the-dots-twitter-analysis/index.html#mentions",
    "href": "posts/2017-08-18-joining-the-dots-twitter-analysis/index.html#mentions",
    "title": "Joining the Dots Twitter analysis",
    "section": "Mentions",
    "text": "Mentions\nThe ‚Äúmentions network‚Äù, where users mention other users in their tweets. Filtered for k-core &gt;= 4 and coloured by modularity class.\nBetter to view the original PNG file in the data directory."
  },
  {
    "objectID": "posts/2017-08-18-joining-the-dots-twitter-analysis/index.html#retweet-proportion",
    "href": "posts/2017-08-18-joining-the-dots-twitter-analysis/index.html#retweet-proportion",
    "title": "Joining the Dots Twitter analysis",
    "section": "Retweet proportion",
    "text": "Retweet proportion"
  },
  {
    "objectID": "posts/2017-08-18-joining-the-dots-twitter-analysis/index.html#retweet-count",
    "href": "posts/2017-08-18-joining-the-dots-twitter-analysis/index.html#retweet-count",
    "title": "Joining the Dots Twitter analysis",
    "section": "Retweet count",
    "text": "Retweet count"
  },
  {
    "objectID": "posts/2017-08-18-joining-the-dots-twitter-analysis/index.html#top-retweets",
    "href": "posts/2017-08-18-joining-the-dots-twitter-analysis/index.html#top-retweets",
    "title": "Joining the Dots Twitter analysis",
    "section": "Top retweets",
    "text": "Top retweets\n\n\n\n\nscreen_name\n\n\ntext\n\n\nretweet_count\n\n\n\n\n\n\nlazappi\n\n\nSlides from my #jtdwehi talk today about building a clustering tree https://t.co/lwTztVstOC\n\n\n12\n\n\n\n\nlazappi\n\n\n.@bestqualitycrab Visualising creative research (more creatively) #jtdwehi #sketchnotes https://t.co/DXhk1u22nf\n\n\n10\n\n\n\n\nFCTweedie\n\n\n.@claresloggett‚Äôs tips on where to start with data viz in Python #jtdwehi https://t.co/jN626uOAqd\n\n\n10\n\n\n\n\nFCTweedie\n\n\nVisualising grant recipients: Davids most funded but Richards get more money #jtdwehi https://t.co/iPImbK4paf\n\n\n9\n\n\n\n\nmikejonesmelb\n\n\nReally valuable point from @KathyReid: sometimes #dataviz decisions affected by need to consider political priorities and buy-in #jtdwehi\n\n\n9\n\n\n\n\ngravitron\n\n\n@bestqualitycrab demoing dataviz: ask the tricky Q‚Äôs not the obvious. Consider the felt not just the instrumental.‚Ä¶ https://t.co/ca1zCn4oSO\n\n\n8\n\n\n\n\nmikejonesmelb\n\n\nMore on the Transport Network Strategic Investment Tool (TraNSIT) here https://t.co/z5v827bfjd @Xavier_Ho #jtdwehi\n\n\n8\n\n\n\n\nmikejonesmelb\n\n\nTo visualise data is to encode it; how can we decode it? So Isabelle created Tracey McTraceface https://t.co/4YoxS4T6OS #jtdwehi\n\n\n7\n\n\n\n\noldmateo\n\n\n:: \"Research publishing methods stuck in the Stone Age\" :: Brendan Ansell on balancing completeness and salience i‚Ä¶ https://t.co/7WVV2Ni31U\n\n\n7\n\n\n\n\ngravitron\n\n\n@bestqualitycrab leading a chorus of Slipping Away. Just your run of the mill dataviz conference. #JoiningTheDots‚Ä¶ https://t.co/6oxUMXZfpm\n\n\n7"
  },
  {
    "objectID": "posts/2017-08-18-joining-the-dots-twitter-analysis/index.html#favourite-proportion",
    "href": "posts/2017-08-18-joining-the-dots-twitter-analysis/index.html#favourite-proportion",
    "title": "Joining the Dots Twitter analysis",
    "section": "Favourite proportion",
    "text": "Favourite proportion"
  },
  {
    "objectID": "posts/2017-08-18-joining-the-dots-twitter-analysis/index.html#favourite-count",
    "href": "posts/2017-08-18-joining-the-dots-twitter-analysis/index.html#favourite-count",
    "title": "Joining the Dots Twitter analysis",
    "section": "Favourite count",
    "text": "Favourite count"
  },
  {
    "objectID": "posts/2017-08-18-joining-the-dots-twitter-analysis/index.html#top-favourites",
    "href": "posts/2017-08-18-joining-the-dots-twitter-analysis/index.html#top-favourites",
    "title": "Joining the Dots Twitter analysis",
    "section": "Top favourites",
    "text": "Top favourites\n\n\n\n\nscreen_name\n\n\ntext\n\n\nfavorite_count\n\n\n\n\n\n\nlazappi\n\n\nSlides from my #jtdwehi talk today about building a clustering tree https://t.co/lwTztVstOC\n\n\n19\n\n\n\n\nXavier_Ho\n\n\nPeople are flowing back in #jtdwehi https://t.co/t4aU8WXoX9\n\n\n16\n\n\n\n\nWEHI_research\n\n\nWelcome to delegates attending today‚Äôs symposium Joining the Dots: The Art and Science of Data Visualisation! #jtdwehi #dataviz\n\n\n16\n\n\n\n\nFCTweedie\n\n\nVisualising grant recipients: Davids most funded but Richards get more money #jtdwehi https://t.co/iPImbK4paf\n\n\n12\n\n\n\n\nlazappi\n\n\n.@bestqualitycrab Visualising creative research (more creatively) #jtdwehi #sketchnotes https://t.co/DXhk1u22nf\n\n\n11\n\n\n\n\nrobbie_bonelli\n\n\nSo inspired by the talk given by @bestqualitycrab on the problem of #genderequality and how #dataviz can help us! Thanks Deb! #jtdwehi\n\n\n11\n\n\n\n\nKathyReid\n\n\nThe incredible @bestqualitycrab keynoting #jtdwehi https://t.co/mLgKdVt4IX\n\n\n11\n\n\n\n\nFCTweedie\n\n\n.@claresloggett‚Äôs tips on where to start with data viz in Python #jtdwehi https://t.co/jN626uOAqd\n\n\n11\n\n\n\n\npeterneish\n\n\nBuilding a clustering tree https://t.co/KDgdRfBejZ #jtdwehi\n\n\n11\n\n\n\n\nFCTweedie\n\n\nRepresenting Greek films via olive trees (which are are actually Markov chains) #jtdwehi https://t.co/SB2CG4oH8D\n\n\n10"
  },
  {
    "objectID": "posts/2017-08-18-joining-the-dots-twitter-analysis/index.html#quote-proportion",
    "href": "posts/2017-08-18-joining-the-dots-twitter-analysis/index.html#quote-proportion",
    "title": "Joining the Dots Twitter analysis",
    "section": "Quote proportion",
    "text": "Quote proportion"
  },
  {
    "objectID": "posts/2017-08-18-joining-the-dots-twitter-analysis/index.html#quote-count",
    "href": "posts/2017-08-18-joining-the-dots-twitter-analysis/index.html#quote-count",
    "title": "Joining the Dots Twitter analysis",
    "section": "Quote count",
    "text": "Quote count"
  },
  {
    "objectID": "posts/2017-08-18-joining-the-dots-twitter-analysis/index.html#top-quotes",
    "href": "posts/2017-08-18-joining-the-dots-twitter-analysis/index.html#top-quotes",
    "title": "Joining the Dots Twitter analysis",
    "section": "Top quotes",
    "text": "Top quotes\n\n\n\n\nscreen_name\n\n\ntext\n\n\nquote_count\n\n\n\n\n\n\npeterneish\n\n\nWould love to see some taxonomic data plotted like this. #jtdwehi https://t.co/EbBL872fum\n\n\n5\n\n\n\n\nXavier_Ho\n\n\noverlaying clusters: the datavis movie #jtdwehi https://t.co/KA5ovvvW6r\n\n\n5\n\n\n\n\nfrostickle\n\n\nWhere can people go from here, to take advantage of things they‚Äôve learnt at #jtdwehi? @ResPlat? @OKFNau?\n#dataviz https://t.co/TM6ngns9RS\n\n\n4\n\n\n\n\nrowlandm\n\n\nThe money shot from @_lazappi_ ! #jtdwehi https://t.co/nqynLrC7Vg\n\n\n3\n\n\n\n\nXavier_Ho\n\n\nSlide here: https://t.co/o2E59HHoZE #jtdwehi https://t.co/L98WV1tXgu\n\n\n3\n\n\n\n\nkarinv\n\n\nThanks to @FCTweedie and @rubin_af for a great day of #dataviz! #jtdwehi https://t.co/Hti5FQtMGz\n\n\n3\n\n\n\n\nrowlandm\n\n\nLImited funding ‚Ä¶ sounds like research! #jtdwehi https://t.co/gZwllFhtRe\n\n\n2\n\n\n\n\npeterneish\n\n\nFascinating insights into the life sciences #jtdwehi https://t.co/LpRwfP00ns\n\n\n2\n\n\n\n\nkarinv\n\n\nAdding the correct hashtag! (sorry folks) #jtdwehi https://t.co/PoGZe8k1k8\n\n\n2\n\n\n\n\nrobbie_bonelli\n\n\nDepressing and motivating! #jtdwehi https://t.co/YCGB1ibYkw\n\n\n2"
  },
  {
    "objectID": "posts/2017-08-18-joining-the-dots-twitter-analysis/index.html#media-count",
    "href": "posts/2017-08-18-joining-the-dots-twitter-analysis/index.html#media-count",
    "title": "Joining the Dots Twitter analysis",
    "section": "Media count",
    "text": "Media count"
  },
  {
    "objectID": "posts/2017-08-18-joining-the-dots-twitter-analysis/index.html#top-media",
    "href": "posts/2017-08-18-joining-the-dots-twitter-analysis/index.html#top-media",
    "title": "Joining the Dots Twitter analysis",
    "section": "Top media",
    "text": "Top media\n\n\n\n\nscreen_name\n\n\ntext\n\n\nfavorite_count\n\n\n\n\n\n\nXavier_Ho\n\n\nPeople are flowing back in #jtdwehi https://t.co/t4aU8WXoX9\n\n\n16\n\n\n\n\nFCTweedie\n\n\nVisualising grant recipients: Davids most funded but Richards get more money #jtdwehi https://t.co/iPImbK4paf\n\n\n12\n\n\n\n\nlazappi\n\n\n.@bestqualitycrab Visualising creative research (more creatively) #jtdwehi #sketchnotes https://t.co/DXhk1u22nf\n\n\n11\n\n\n\n\nKathyReid\n\n\nThe incredible @bestqualitycrab keynoting #jtdwehi https://t.co/mLgKdVt4IX\n\n\n11\n\n\n\n\nFCTweedie\n\n\n.@claresloggett‚Äôs tips on where to start with data viz in Python #jtdwehi https://t.co/jN626uOAqd\n\n\n11\n\n\n\n\nFCTweedie\n\n\nRepresenting Greek films via olive trees (which are are actually Markov chains) #jtdwehi https://t.co/SB2CG4oH8D\n\n\n10\n\n\n\n\nfrostickle\n\n\nNow @Xavier_Ho from the @CSIROnews is talking about Visualising the Australian Transport Network\n#jtdwehi #dataviz https://t.co/DcvXYmD45F\n\n\n10\n\n\n\n\nFCTweedie\n\n\nGetting underway for #jtdwehi with acknowledgement of country from @WEHI_research‚Äôs director https://t.co/oNcnu5wtd9\n\n\n10\n\n\n\n\nFCTweedie\n\n\nPatriarchy looks like this! What happens when we can describe the shape of injustice #jtdwehi https://t.co/8A7EhnFmt5\n\n\n9\n\n\n\n\ngravitron\n\n\nBest URL of the day goes to @Isa_Kiko‚Äôs https://t.co/kapY0Aeacy A great looking tool! #JoiningTheDots #jtdwehi https://t.co/gal2v1PUJY\n\n\n7\n\n\n\n\n\nMost liked media image"
  },
  {
    "objectID": "publications/2018-phipson-variability/index.html",
    "href": "publications/2018-phipson-variability/index.html",
    "title": "Evaluation of variability in human kidney organoids",
    "section": "",
    "text": "CitationBibTeX citation:@article{phipson2018,\n  author = {Phipson, Belinda and X Er, Pei and N Combes, Alexander and A\n    Forbes, Thomas and E Howden, Sara and Zappia, Luke and Yen, Hsan-Jan\n    and T Lawlor, Kynan and J Hale, Lorna and Sun, Jane and Wolvetang,\n    Ernst and Takasato, Minoru and Oshlack, Alicia and H Little,\n    Melissa},\n  title = {Evaluation of Variability in Human Kidney Organoids},\n  journal = {Nature methods},\n  volume = {16},\n  number = {1},\n  pages = {79-87},\n  date = {2018-12-01},\n  url = {https://lazappi.id.au/publications/2018-phipson-variability/},\n  doi = {10.1038/s41592-018-0253-2},\n  issn = {1548-7091, 1548-7105},\n  langid = {en},\n  abstract = {The utility of human pluripotent stem cell‚Äìderived kidney\n    organoids relies implicitly on the robustness and transferability of\n    the protocol. Here we analyze the sources of transcriptional\n    variation in a specific kidney organoid protocol. Although\n    individual organoids within a differentiation batch showed strong\n    transcriptional correlation, we noted significant variation between\n    experimental batches, particularly in genes associated with temporal\n    maturation. Single-cell profiling revealed shifts in nephron\n    patterning and proportions of component cells. Distinct induced\n    pluripotent stem cell clones showed congruent transcriptional\n    programs, with interexperimental and interclonal variation also\n    strongly associated with nephron patterning. Epithelial cells\n    isolated from organoids aligned with total organoids at the same day\n    of differentiation, again implicating relative maturation as a\n    confounder. This understanding of experimental variation facilitated\n    an optimized analysis of organoid-based disease modeling, thereby\n    increasing the utility of kidney organoids for personalized medicine\n    and functional genomics.}\n}\nFor attribution, please cite this work as:\nPhipson, Belinda, Pei X Er, Alexander N Combes, Thomas A Forbes, Sara E\nHowden, Luke Zappia, Hsan-Jan Yen, et al. 2018. ‚ÄúEvaluation of\nVariability in Human Kidney Organoids.‚Äù Nature Methods\n16 (1): 79‚Äì87. https://doi.org/10.1038/s41592-018-0253-2."
  },
  {
    "objectID": "publications/2020-leeming-HiTIME/index.html",
    "href": "publications/2020-leeming-HiTIME/index.html",
    "title": "HiTIME: An efficient model-selection approach for the detection of unknown drug metabolites in LC-MS data",
    "section": "",
    "text": "CitationBibTeX citation:@article{g_leeming2020,\n  author = {G Leeming, Michael and P Isaac, Andrew and Zappia, Luke and\n    A J O‚ÄôHair, Richard and A Donald, William and J Pope, Bernard},\n  title = {HiTIME: {An} Efficient Model-Selection Approach for the\n    Detection of Unknown Drug Metabolites in {LC-MS} Data},\n  journal = {SoftwareX},\n  pages = {100559},\n  date = {2020-07-07},\n  url = {https://lazappi.id.au/publications/2020-leeming-HiTIME/},\n  doi = {10.1016/j.softx.2020.100559},\n  langid = {en},\n  abstract = {The identification of metabolites plays an important role\n    in understanding drug efficacy and safety however these compounds\n    are often difficult to identify in complex mixtures. One approach to\n    identify drug metabolites involves utilising differentially\n    isotopically labelled drug compounds to create unique isotopic\n    signals that can be detected by liquid chromatography-mass\n    spectrometry (LC-MS). User-friendly, efficient, computational tools\n    that allow selective detection of these signals are lacking. We have\n    developed an efficient open-source software tool called HiTIME\n    (High-Resolution Twin-Ion Metabolite Extraction) which filters\n    twin-ion signals in LC-MS data. The intensity of each data point in\n    the input is replaced by a Z-score describing how well the point\n    matches an idealised twin-ion signal versus alternative ion\n    signatures. Here we provide a detailed description of the algorithm\n    and demonstrate its performance on simulated and experimental data.}\n}\nFor attribution, please cite this work as:\nG Leeming, Michael, Andrew P Isaac, Luke Zappia, Richard A J O‚ÄôHair,\nWilliam A Donald, and Bernard J Pope. 2020. ‚ÄúHiTIME: An Efficient\nModel-Selection Approach for the Detection of Unknown Drug Metabolites\nin LC-MS Data.‚Äù SoftwareX, July, 100559. https://doi.org/10.1016/j.softx.2020.100559."
  },
  {
    "objectID": "publications/2023-deDonno-scPoli/index.html",
    "href": "publications/2023-deDonno-scPoli/index.html",
    "title": "Population-level integration of single-cell datasets enables multi-scale analysis across samples",
    "section": "",
    "text": "CitationBibTeX citation:@article{de_donno2023,\n  author = {De Donno, Carlo and Hediyeh-Zadeh, Soroor and Ali Moinfar,\n    Amir and Wagenstetter, Marco and Zappia, Luke and Lotfollahi,\n    Mohammad and J. Theis, Fabian},\n  title = {Population-Level Integration of Single-Cell Datasets Enables\n    Multi-Scale Analysis Across Samples},\n  journal = {Nature Methods},\n  volume = {20},\n  number = {11},\n  pages = {1683-1692},\n  date = {2023-10-09},\n  url = {https://lazappi.id.au/publications/2023-deDonno-scPoli/},\n  doi = {10.1038/s41592-023-02035-2},\n  issn = {1548-7091},\n  langid = {en},\n  abstract = {The increasing generation of population-level single-cell\n    atlases has the potential to link sample metadata with cellular\n    data. Constructing such references requires integration of\n    heterogeneous cohorts with varying metadata. Here we present\n    single-cell population level integration (scPoli), an open-world\n    learner that incorporates generative models to learn sample and cell\n    representations for data integration, label transfer and reference\n    mapping. We applied scPoli on population-level atlases of lung and\n    peripheral blood mononuclear cells, the latter consisting of 7.8\n    million cells across 2,375 samples. We demonstrate that scPoli can\n    explain sample-level biological and technical variations using\n    sample embeddings revealing genes associated with batch effects and\n    biological effects. scPoli is further applicable to single-cell\n    sequencing assay for transposase-accessible chromatin and\n    cross-species datasets, offering insights into chromatin\n    accessibility and comparative genomics. We envision scPoli becoming\n    an important tool for population-level single-cell data integration\n    facilitating atlas use but also interpretation by means of\n    multi-scale analyses.}\n}\nFor attribution, please cite this work as:\nDe Donno, Carlo, Soroor Hediyeh-Zadeh, Amir Ali Moinfar, Marco\nWagenstetter, Luke Zappia, Mohammad Lotfollahi, and Fabian J. Theis.\n2023. ‚ÄúPopulation-Level Integration of Single-Cell Datasets\nEnables Multi-Scale Analysis Across Samples.‚Äù Nature\nMethods 20 (11): 1683‚Äì92. https://doi.org/10.1038/s41592-023-02035-2."
  },
  {
    "objectID": "publications/2021-fischer-sfaira/index.html",
    "href": "publications/2021-fischer-sfaira/index.html",
    "title": "Sfaira accelerates data and model reuse in single cell genomics",
    "section": "",
    "text": "CitationBibTeX citation:@article{s_fischer2021,\n  author = {S Fischer, David and Dony, Leander and K√∂nig, Martin and\n    Moeed, Abdul and Zappia, Luke and Heumos, Lukas and Tritschler,\n    Sophie and Holmberg, Olle and Aliee, Hananeh and J Theis, Fabian},\n  title = {Sfaira Accelerates Data and Model Reuse in Single Cell\n    Genomics},\n  journal = {Genome biology},\n  volume = {22},\n  number = {1},\n  pages = {248},\n  date = {2021-08-25},\n  url = {https://lazappi.id.au/publications/2021-fischer-sfaira/},\n  doi = {10.1186/s13059-021-02452-6},\n  issn = {1465-6906},\n  langid = {en},\n  abstract = {Single-cell RNA-seq datasets are often first analyzed\n    independently without harnessing model fits from previous studies,\n    and are then contextualized with public data sets, requiring\n    time-consuming data wrangling. We address these issues with sfaira,\n    a single-cell data zoo for public data sets paired with a model zoo\n    for executable pre-trained models. The data zoo is designed to\n    facilitate contribution of data sets using ontologies for metadata.\n    We propose an adaption of cross-entropy loss for cell type\n    classification tailored to datasets annotated at different levels of\n    coarseness. We demonstrate the utility of sfaira by training models\n    across anatomic data partitions on 8 million cells.}\n}\nFor attribution, please cite this work as:\nS Fischer, David, Leander Dony, Martin K√∂nig, Abdul Moeed, Luke Zappia,\nLukas Heumos, Sophie Tritschler, Olle Holmberg, Hananeh Aliee, and\nFabian J Theis. 2021. ‚ÄúSfaira Accelerates Data and Model Reuse in\nSingle Cell Genomics.‚Äù Genome Biology 22 (1): 248. https://doi.org/10.1186/s13059-021-02452-6."
  },
  {
    "objectID": "publications/2024-luecken-OpenProblems/index.html",
    "href": "publications/2024-luecken-OpenProblems/index.html",
    "title": "Defining and benchmarking open problems in single-cell analysis",
    "section": "",
    "text": "CitationBibTeX citation:@misc{d._luecken2024,\n  author = {D. Luecken, Malte and Gigante, Scott and B. Burkhardt,\n    Daniel and Cannoodt, Robrecht and C. Strobl, Daniel and S. Markov,\n    Nikolay and Zappia, Luke and Palla, Giovanni and Lewis, Wesley and\n    Dimitrov, Daniel and E. Vinyard, Michael and Magruder, D.S. and\n    Andersson, Alma and Dann, Emma and Qin, Qian and J. Otto, Dominik\n    and Klein, Michal and Borisovna Botvinnik, Olga and Deconinck,\n    Louise and Waldrant, Kai and Open Problems Jamboree Members, The and\n    M. Bloom, Jonathan and Oliveira Pisco, Angela and Saez-Rodriguez,\n    Julio and Wulsin, Drausin and Pinello, Luca and Saeys, Yvan and J\n    Theis, Fabian and Krishnaswamy, Smita},\n  title = {Defining and Benchmarking Open Problems in Single-Cell\n    Analysis},\n  date = {2024-03-03},\n  url = {https://lazappi.id.au/publications/2024-luecken-OpenProblems/},\n  doi = {10.21203/rs.3.rs-4181617/v1},\n  langid = {en},\n  abstract = {With the growing number of single-cell analysis tools,\n    benchmarks are increasingly important to guide analysis and method\n    development. However, a lack of standardisation and extensibility in\n    current benchmarks limits their usability, longevity, and relevance\n    to the community. We present Open Problems, a living, extensible,\n    community-guided benchmarking platform including 10 current\n    single-cell tasks that we envision will raise standards for the\n    selection, evaluation, and development of methods in single-cell\n    analysis.}\n}\nFor attribution, please cite this work as:\nD. Luecken, Malte, Scott Gigante, Daniel B. Burkhardt, Robrecht\nCannoodt, Daniel C. Strobl, Nikolay S. Markov, Luke Zappia, et al. 2024.\n‚ÄúDefining and Benchmarking Open Problems in Single-Cell\nAnalysis.‚Äù Research Square. https://doi.org/10.21203/rs.3.rs-4181617/v1."
  },
  {
    "objectID": "publications/2019-ma-influenza/index.html",
    "href": "publications/2019-ma-influenza/index.html",
    "title": "Unique transcriptional architecture in airway epithelial cells and macrophages shapes distinct responses following influenza virus infection ex vivo",
    "section": "",
    "text": "CitationBibTeX citation:@article{z_ma2019,\n  author = {Z Ma, Joel and Ching Ng, Wy and Zappia, Luke and J Gearing,\n    Linden and Olshansky, Moshe and Pham, Kym and Cheong, Karey and Hsu,\n    Arthur and J Turner, Stephen and Wijburg, Odilia and L Londrigan,\n    Sarah and G Brooks, Andrew and C Reading, Patrick},\n  title = {Unique Transcriptional Architecture in Airway Epithelial\n    Cells and Macrophages Shapes Distinct Responses Following Influenza\n    Virus Infection Ex Vivo},\n  journal = {Journal of virology},\n  date = {2019-01-01},\n  url = {https://lazappi.id.au/publications/2019-ma-influenza/},\n  doi = {10.1128/JVI.01986-18},\n  issn = {0022-538X, 1098-5514},\n  langid = {en},\n  abstract = {Airway epithelial cells and macrophages differ markedly in\n    their responses to influenza A virus (IAV) infection. To investigate\n    transcriptional responses underlying these differences, purified\n    subsets of type II airway epithelial cells (ATII) and alveolar\n    macrophages (AM) recovered from the lungs of mock- or IAV-infected\n    mice at 9 h postinfection were subjected to RNA sequencing. This\n    time point was chosen to allow for characterization of cell types\n    first infected with the virus inoculum, prior to multicycle virus\n    replication and the infiltration of inflammatory cells into the\n    airways. In the absence of infection, AM predominantly expressed\n    genes related to immunity, whereas ATII expressed genes consistent\n    with their physiological roles in the lung. Following IAV infection,\n    AM almost exclusively activated cell-intrinsic antiviral pathways\n    that were dependent on interferon (IFN) regulatory factor 3/7\n    (IRF3/7) and/or type I IFN signaling. In contrast, IAV-infected ATII\n    activated a broader range of physiological responses, including\n    cell-intrinsic antiviral pathways, which were both independent of\n    and dependent on IRF3/7 and/or type I IFN. These data suggest that\n    transcriptional profiles hardwired during development are a major\n    determinant underlying the different responses of ATII and AM to IAV\n    infection. **IMPORTANCE** Airway epithelial cells (AEC) and airway\n    macrophages (AM) represent major targets of influenza A virus (IAV)\n    infection in the lung, yet the two cell types respond very\n    differently to IAV infection. We have used RNA sequencing to define\n    the host transcriptional responses in each cell type under\n    steady-state conditions as well as following IAV infection. To do\n    this, different cell subsets isolated from the lungs of mock- and\n    IAV-infected mice were subjected to RNA sequencing. Under\n    steady-state conditions, AM and AEC express distinct transcriptional\n    activities, consistent with distinct physiological roles in the\n    airways. Not surprisingly, these cells also exhibited major\n    differences in transcriptional responses following IAV infection.\n    These studies shed light on how the different transcriptional\n    architectures of airway cells from two different lineages drive\n    transcriptional responses to IAV infection.}\n}\nFor attribution, please cite this work as:\nZ Ma, Joel, Wy Ching Ng, Luke Zappia, Linden J Gearing, Moshe Olshansky,\nKym Pham, Karey Cheong, et al. 2019. ‚ÄúUnique Transcriptional\nArchitecture in Airway Epithelial Cells and Macrophages Shapes Distinct\nResponses Following Influenza Virus Infection Ex Vivo.‚Äù\nJournal of Virology, January. https://doi.org/10.1128/JVI.01986-18."
  },
  {
    "objectID": "publications/index.html",
    "href": "publications/index.html",
    "title": "Publications",
    "section": "",
    "text": "An open-source framework for end-to-end analysis of electronic health record data\n\n\n\n\n\n\nmedical records\n\n\nsoftware\n\n\n\n\n\n\nSep 12, 2024\n\n\nLukas Heumos, Philipp Ehmele, Tim Treis, Julius Upmeier zu Belzen, Eljas Roellin, Lilly May, Altana Namsaraeva, Nastassya Horlava, Vladimir A. Shitov, Xinyue Zhang, Luke Zappia, Rainer Knoll, Niklas J. Lang, Leon Hetzel, Isaac Virshup, Lisa Sikkema, Fabiola Curion, Roland Eils, Herbert B. Schiller, Anne Hilgendorff, Fabian J. Theis\n\n\n\n\n\n\n\nDefining and benchmarking open problems in single-cell analysis\n\n\n\n\n\n\nbenchmarking\n\n\nscrna-seq\n\n\nwebsite\n\n\n\n\n\n\nMar 3, 2024\n\n\nMalte D. Luecken, Scott Gigante, Daniel B. Burkhardt, Robrecht Cannoodt, Daniel C. Strobl, Nikolay S. Markov, Luke Zappia, Giovanni Palla, Wesley Lewis, Daniel Dimitrov, Michael E. Vinyard, D.S. Magruder, Alma Andersson, Emma Dann, Qian Qin, Dominik J. Otto, Michal Klein, Olga Borisovna Botvinnik, Louise Deconinck, Kai Waldrant, The Open Problems Jamboree Members, Jonathan M. Bloom, Angela Oliveira Pisco, Julio Saez-Rodriguez, Drausin Wulsin, Luca Pinello, Yvan Saeys, Fabian J Theis, Smita Krishnaswamy\n\n\n\n\n\n\n\nOptimal distance metrics for single-cell RNA-seq populations\n\n\n\n\n\n\nscrna-seq\n\n\nrna-seq\n\n\ndistances\n\n\nbenchmarking\n\n\n\n\n\n\nDec 26, 2023\n\n\nYuge Ji, Tessa D. Green, Stefan Peidli, Mojtaba Bahrami, Meiqi Liu,, Luke Zappia, Karin Hrovatin, Chris Sander, Fabian J. Theis\n\n\n\n\n\n\n\nIntegrating single-cell RNA-seq datasets with substantial batch effects\n\n\n\n\n\n\nsingle-cell\n\n\nrna-seq\n\n\nintegration\n\n\nbatch effects\n\n\nmethods\n\n\n\n\n\n\nNov 3, 2023\n\n\nKarin Hrovatin, Amir Ali Moinfar, Luke Zappia, Alejandro Tejada Lapuerta, Benjamin Lengerich, Manolis Kellis, Fabian J. Theis\n\n\n\n\n\n\n\nPopulation-level integration of single-cell datasets enables multi-scale analysis across samples\n\n\n\n\n\n\nsingle-cell\n\n\nrna-seq\n\n\nmethods\n\n\nintegration\n\n\nsoftware\n\n\n\n\n\n\nOct 9, 2023\n\n\nCarlo De Donno, Soroor Hediyeh-Zadeh, Amir Ali Moinfar, Marco Wagenstetter, Luke Zappia, Mohammad Lotfollahi, Fabian J. Theis\n\n\n\n\n\n\n\nDelineating mouse Œ≤-cell identity during lifetime and in diabetes with a single cell atlas\n\n\n\n\n\n\nsingle-cell\n\n\nrna-seq\n\n\nmouse\n\n\npancreas\n\n\natlas\n\n\n\n\n\n\nSep 11, 2023\n\n\nKarin Hrovatin, Aim√©e Bastidas-Ponce, Mostafa Bakhti, Luke Zappia, Maren B√ºttner, Ciro Sallino, Michael Sterr, Anika B√∂ttcher, Adriana Migliorini, Heiko Lickert, Fabian J Theis\n\n\n\n\n\n\n\nAn integrated cell atlas of the lung in health and disease\n\n\n\n\n\n\nsingle-cell\n\n\nrna-seq\n\n\nlung\n\n\natlas\n\n\n\n\n\n\nAug 6, 2023\n\n\nLisa Sikkema, Ciro Ram√≠rez-Su√°stegui, Daniel C. Strobl, Tessa E. Gillett, Luke Zappia, Elo Madissoon, Nikolay S. Markov, Laure-Emmanuelle Zaragosi, Yuge Ji, Meshal Ansari, Marie-Jeanne Arguel, Leonie Apperloo, Martin Banchero, Christophe B√©cavin, Marijn Berg, Evgeny Chichelnitskiy, Mei-i Chung, Antoine Collin, Aurore C. A. Gay, Janine Gote-Schniering, Baharak Hooshiar Kashani, Kemal Inecik, Manu Jain, Theodore S. Kapellos, Tessa M. Kole, Sylvie Leroy, Christoph H. Mayr, Amanda J. Oliver, Michael von Papen, Lance Peter, Chase J. Taylor, Thomas Walzthoeni, Chuan Xu, Linh T. Bui, Carlo De Donno, Leander Dony, Alen Faiz, Minzhe Guo, Austin J. Gutierrez, Lukas Heumos, Ni Huang, Ignacio L. Ibarra, Nathan D. Jackson, Preetish Kadur Lakshminarasimha Murthy, Mohammad Lotfollahi, Tracy Tabib, Carlos Talavera-L√≥pez, Kyle J. Travaglini, Anna Wilbrey-Clark, Kaylee B. Worlock, Masahiro Yoshida, Lung Biological Network Consortium, Maarten van den Berge, Yohan Boss√©, Tushar J. Desai, Oliver Eickelberg, Naftali Kaminski, Mark A. Krasnow, Robert Lafyatis, Marko Z. Nikolic, Joseph E. Powell, Jayaraj Rajagopal, Mauricio Rojas, Orit Rozenblatt-Rosen, Max A. Seibold, Dean Sheppard, Douglas P. Shepherd, Don D. Sin, Wim Timens, Alexander M. Tsankov, Jeffrey Whitsett, Yan Xu, Nicholas E. Banovich, Pascal Barbry, Thu Elizabeth Duong, Christine S. Falk, Kerstin B. Meyer, Jonathan A. Kropski, Dana Pe‚Äôer, Herbert B. Schiller, Purushothama Rao Tata, Joachim L. Schultze, Sara A. Teichmann, Alexander V. Misharin, Martijn C. Nawijn, Malte D. Luecken, Fabian J. Theis\n\n\n\n\n\n\n\nBest practices for single-cell analysis across modalities\n\n\n\n\n\n\nsingle-cell\n\n\nmultiomics\n\n\nbest practices\n\n\nreview\n\n\n\n\n\n\nMar 31, 2023\n\n\nLukas Heumos, Anna C. Schaar, Christopher Lance, Anastasia Litinetskaya, Felix Drost, Luke Zappia, Malte D. L√ºcken, Daniel C. Strobl, Juan Henao, Fabiola Curion, Single-cell Best Practices Consortium, Herbert B. Schiller, Fabian J. Theis\n\n\n\n\n\n\n\nBenchmarking atlas-level data integration in single-cell genomics\n\n\n\n\n\n\nsingle-cell\n\n\nrna-seq\n\n\nintegration\n\n\nbenchmarking\n\n\n\n\n\n\nDec 23, 2021\n\n\nMalte D Luecken, Maren B√ºttner, Kridsadakorn Chaichoompu, Anna Danese, Marta Interlandi, Michaela F Mueller, Daniel C Strobl, Luke Zappia, Martin Dugas, Maria Colom√©-Tatch√©, Fabian J Theis\n\n\n\n\n\n\n\nsplatPop: simulating population scale single-cell RNA sequencing data\n\n\n\n\n\n\nsingle-cell\n\n\nrna-seq\n\n\nsimulation\n\n\npopulation\n\n\nsoftware\n\n\nmethods\n\n\n\n\n\n\nDec 15, 2021\n\n\nChristina B Azodi, Luke Zappia, Alicia Oshlack, Davis J McCarthy\n\n\n\n\n\n\n\nOver 1000 tools reveal trends in the single-cell RNA-seq analysis landscape\n\n\n\n\n\n\nsingle-cell\n\n\nrna-seq\n\n\ndatabase\n\n\n\n\n\n\nOct 29, 2021\n\n\nLuke Zappia, Fabian J Theis\n\n\n\n\n\n\n\nSfaira accelerates data and model reuse in single cell genomics\n\n\n\n\n\n\nsingle-cell\n\n\nrna-seq\n\n\ndatabase\n\n\nwebsite\n\n\n\n\n\n\nAug 25, 2021\n\n\nDavid S Fischer, Leander Dony, Martin K√∂nig, Abdul Moeed, Luke Zappia, Lukas Heumos, Sophie Tritschler, Olle Holmberg, Hananeh Aliee, Fabian J Theis\n\n\n\n\n\n\n\nHiTIME: An efficient model-selection approach for the detection of unknown drug metabolites in LC-MS data\n\n\n\n\n\n\nmass spectrometry\n\n\nsoftware\n\n\n\n\n\n\nJul 7, 2020\n\n\nMichael G Leeming, Andrew P Isaac, Luke Zappia, Richard A J O‚ÄôHair, William A Donald, Bernard J Pope\n\n\n\n\n\n\n\nOpportunities and challenges in long-read sequencing data analysis\n\n\n\n\n\n\ndata analysis\n\n\nlong read\n\n\ndatabase\n\n\nwebsite\n\n\n\n\n\n\nFeb 1, 2020\n\n\nShanika L Amarasinghe, Shian Su, Xueyi Dong, Luke Zappia, Matthew E Ritchie, Quentin Gouil\n\n\n\n\n\n\n\nTools and techniques for single-cell RNA sequencing data\n\n\n\n\n\n\nsingle-cell\n\n\nrna-seq\n\n\nmethods\n\n\nthesis\n\n\nPhD\n\n\n\n\n\n\nAug 12, 2019\n\n\nLuke Zappia\n\n\n\n\n\n\n\nSingle cell analysis of the developing mouse kidney provides deeper insight into marker gene expression and ligand-receptor crosstalk\n\n\n\n\n\n\norganogenesis\n\n\nsingle-cell\n\n\nrna-seq\n\n\nmouse\n\n\nkidney\n\n\ndevelopment\n\n\nnephron\n\n\n\n\n\n\nJun 1, 2019\n\n\nAlexander N Combes, Belinda Phipson, Kynan T Lawlor, Aude Dorison, Ralph Patrick, Luke Zappia, Richard P Harvey, Alicia Oshlack, Melissa H Little\n\n\n\n\n\n\n\nKidney micro-organoids in suspension culture as a scalable source of human pluripotent stem cell-derived kidney cells\n\n\n\n\n\n\nnephron\n\n\nstem cell\n\n\nsuspension culture\n\n\nsingle-cell\n\n\nrna-seq\n\n\nkidney\n\n\norganoids\n\n\n\n\n\n\nMar 1, 2019\n\n\nSanthosh V Kumar, Pei X Er, Kynan T Lawlor, Ali Motazedian, Michelle Scurr, Irene Ghobrial, Alexander N Combes, Luke Zappia, Alicia Oshlack, Edouard G Stanley, Melissa H Little\n\n\n\n\n\n\n\nUnique transcriptional architecture in airway epithelial cells and macrophages shapes distinct responses following influenza virus infection ex vivo\n\n\n\n\n\n\nrna-seq\n\n\nmouse\n\n\nvirus\n\n\nimmune\n\n\n\n\n\n\nJan 1, 2019\n\n\nJoel Z Ma, Wy Ching Ng, Luke Zappia, Linden J Gearing, Moshe Olshansky, Kym Pham, Karey Cheong, Arthur Hsu, Stephen J Turner, Odilia Wijburg, Sarah L Londrigan, Andrew G Brooks, Patrick C Reading\n\n\n\n\n\n\n\nNephron progenitor commitment is a stochastic process influenced by cell migration\n\n\n\n\n\n\nsingle-cell\n\n\nrna-seq\n\n\nmouse\n\n\nkidney\n\n\nnephron\n\n\n\n\n\n\nJan 1, 2019\n\n\nKynan T Lawlor, Luke Zappia, James Lefevre, Joo-Seop Park, Nicholas A Hamilton, Alicia Oshlack, Melissa H Little, Alexander Nicholas Combes\n\n\n\n\n\n\n\nSingle-cell analysis reveals congruence between kidney organoids and human fetal kidney\n\n\n\n\n\n\nsingle-cell\n\n\nrna-seq\n\n\nkidney\n\n\norganoids\n\n\n\n\n\n\nJan 1, 2019\n\n\nAlexander N Combes, Luke Zappia, Pei Xuan Er, Alicia Oshlack, Melissa H Little\n\n\n\n\n\n\n\nEvaluation of variability in human kidney organoids\n\n\n\n\n\n\nkidney\n\n\norganoids\n\n\nvariability\n\n\nrna-seq\n\n\nsingle-cell\n\n\n\n\n\n\nDec 1, 2018\n\n\nBelinda Phipson, Pei X Er, Alexander N Combes, Thomas A Forbes, Sara E Howden, Luke Zappia, Hsan-Jan Yen, Kynan T Lawlor, Lorna J Hale, Jane Sun, Ernst Wolvetang, Minoru Takasato, Alicia Oshlack, Melissa H Little\n\n\n\n\n\n\n\nClustering trees: a visualization for evaluating clusterings at multiple resolutions\n\n\n\n\n\n\nmethods\n\n\nvisualisation\n\n\nclustering\n\n\nsoftware\n\n\n\n\n\n\nJul 1, 2018\n\n\nLuke Zappia, Alicia Oshlack\n\n\n\n\n\n\n\nExploring the single-cell RNA-seq analysis landscape with the scRNA-tools database\n\n\n\n\n\n\nsingle-cell\n\n\nrna-seq\n\n\ndatabase\n\n\n\n\n\n\nJun 1, 2018\n\n\nLuke Zappia, Belinda Phipson, Alicia Oshlack\n\n\n\n\n\n\n\nSplatter: simulation of single-cell RNA sequencing data\n\n\n\n\n\n\nsingle-cell\n\n\nrna-seq\n\n\nmethods\n\n\nsoftware\n\n\nsimulation\n\n\n\n\n\n\nSep 1, 2017\n\n\nLuke Zappia, Belinda Phipson, Alicia Oshlack\n\n\n\n\n\n\n\nGene length and detection bias in single cell RNA sequencing protocols\n\n\n\n\n\n\nsingle-cell\n\n\nrna-seq\n\n\ngene length\n\n\n\n\n\n\nApr 1, 2017\n\n\nBelinda Phipson, Luke Zappia, Alicia Oshlack\n\n\n\n\n\n\n\nCirculating tumour cells from patients with colorectal cancer have cancer stem cell hallmarks in ex vivo culture\n\n\n\n\n\n\ndrug toxicity\n\n\ncancer\n\n\ncolorectal\n\n\nstem cell\n\n\nrna-seq\n\n\n\n\n\n\nJul 1, 2016\n\n\nFanny Grillet, Elsa Bayet, Olivia Villeronce, Luke Zappia, Ebba Louise Lagerqvist, Sebastian Lunke, Emmanuelle Charafe-Jauffret, Kym Pham, Christina Molck, Nathalie Rolland, Jean Fran√ßois Bourgaux, Michel Prudhomme, Claire Philippe, Sophie Bravo, Jean Christophe Boyer, Lucile Canterel-Thouennon, Graham Roy Taylor, Arthur Hsu, Jean Marc Pascussi, Fr√©d√©ric Hollande, Julie Pannequin\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "publications/2019-lawlor-nephron-commitment/index.html",
    "href": "publications/2019-lawlor-nephron-commitment/index.html",
    "title": "Nephron progenitor commitment is a stochastic process influenced by cell migration",
    "section": "",
    "text": "CitationBibTeX citation:@article{t_lawlor2019,\n  author = {T Lawlor, Kynan and Zappia, Luke and Lefevre, James and\n    Park, Joo-Seop and A Hamilton, Nicholas and Oshlack, Alicia and H\n    Little, Melissa and Nicholas Combes, Alexander},\n  title = {Nephron Progenitor Commitment Is a Stochastic Process\n    Influenced by Cell Migration},\n  journal = {eLife},\n  volume = {8},\n  pages = {e41156},\n  date = {2019-01-01},\n  url = {https://lazappi.id.au/publications/2019-lawlor-nephron-commitment/},\n  doi = {10.7554/eLife.41156},\n  issn = {2050-084X},\n  langid = {en},\n  abstract = {**Background** Human kidney organoids hold promise for\n    studying development, disease modelling and drug screening. However,\n    the utility of stem cell-derived kidney tissues will depend on how\n    faithfully these replicate normal fetal development at the level of\n    cellular identity and complexity. **Methods** Here, we present an\n    integrated analysis of single cell datasets from human kidney\n    organoids and human fetal kidney to assess similarities and\n    differences between the component cell types. **Results** Clusters\n    in the combined dataset contained cells from both organoid and fetal\n    kidney with transcriptional congruence for key stromal, endothelial\n    and nephron cell type-specific markers. Organoid enriched neural,\n    glial and muscle progenitor populations were also evident. Major\n    transcriptional differences between organoid and human tissue were\n    likely related to technical artefacts. Cell type-specific\n    comparisons revealed differences in stromal, endothelial and nephron\n    progenitor cell types including expression of WNT2B in the human\n    fetal kidney stroma. **Conclusions** This study supports the\n    fidelity of kidney organoids as models of the developing kidney and\n    affirms their potential in disease modelling and drug screening.}\n}\nFor attribution, please cite this work as:\nT Lawlor, Kynan, Luke Zappia, James Lefevre, Joo-Seop Park, Nicholas A\nHamilton, Alicia Oshlack, Melissa H Little, and Alexander Nicholas\nCombes. 2019. ‚ÄúNephron Progenitor Commitment Is a Stochastic\nProcess Influenced by Cell Migration.‚Äù eLife 8\n(January): e41156. https://doi.org/10.7554/eLife.41156."
  },
  {
    "objectID": "publications/2023-hrovatin-batch-effects/index.html",
    "href": "publications/2023-hrovatin-batch-effects/index.html",
    "title": "Integrating single-cell RNA-seq datasets with substantial batch effects",
    "section": "",
    "text": "CitationBibTeX citation:@misc{hrovatin2023,\n  author = {Hrovatin, Karin and Ali Moinfar, Amir and Zappia, Luke and\n    Tejada Lapuerta, Alejandro and Lengerich, Benjamin and Kellis,\n    Manolis and J. Theis, Fabian},\n  title = {Integrating Single-Cell {RNA-seq} Datasets with Substantial\n    Batch Effects},\n  date = {2023-11-03},\n  url = {https://lazappi.id.au/publications/2023-hrovatin-batch-effects/},\n  doi = {10.1101/2023.11.03.565463},\n  langid = {en},\n  abstract = {Integration of single cell RNA sequencing (scRNAseq)\n    datasets has become a standard part of the analysis, with\n    conditional variational autoencoders (cVAE) being among the most\n    popular approaches. Increasingly, researchers are asking to map\n    cells across challenging cases such as cross-organs, species, or\n    organoids and primary tissue, as well as different scRNAseq\n    protocols, including single cell and single nuclei. Current\n    computational methods struggle to harmonize datasets with such\n    substantial differences, driven by technical or biological\n    variation. Here, we propose to address these challenges for the\n    popular cVAE based approaches by introducing and comparing a series\n    of regularization constraints. The two commonly used strategies for\n    increasing batch correction in cVAEs, that is Kullback Leibler\n    divergence (KL) regularization strength tuning and adversarial\n    learning, suffer from substantial loss of biological information.\n    Therefore, we adapt, implement, and assess alternative\n    regularization strategies for cVAEs and investigate how they improve\n    batch effect removal or better preserve biological variation,\n    enabling us to propose an optimal cVAE-based integration strategy\n    for complex systems. We show that using a VampPrior instead of the\n    commonly used Gaussian prior not only improves the preservation of\n    biological variation but also unexpectedly batch correction.\n    Moreover, we show that our implementation of cycle consistency loss\n    leads to significantly better biological preservation than\n    adversarial learning implemented in the previously proposed GLUE\n    model. Additionally, we do not recommend relying only on the KL\n    regularization strength tuning for increasing batch correction, as\n    it removes both biological and batch information without\n    discriminating between the two. Based on our findings, we propose a\n    new model that combines VampPrior and cycle-consistency loss. We\n    show that using it for datasets with substantial batch effects\n    improves downstream interpretation of cell states and biological\n    conditions. To ease the use of the newly proposed model, we make it\n    available in the scvitools package as an external model named sysVI.\n    Moreover, in the future, these regularization techniques could be\n    added to other established cVAE based models to improve the\n    integration of datasets with substantial batch effects.}\n}\nFor attribution, please cite this work as:\nHrovatin, Karin, Amir Ali Moinfar, Luke Zappia, Alejandro Tejada\nLapuerta, Benjamin Lengerich, Manolis Kellis, and Fabian J. Theis. 2023.\n‚ÄúIntegrating Single-Cell RNA-Seq Datasets with Substantial Batch\nEffects.‚Äù bioRxiv. https://doi.org/10.1101/2023.11.03.565463."
  },
  {
    "objectID": "publications/2019-zappia-thesis/index.html",
    "href": "publications/2019-zappia-thesis/index.html",
    "title": "Tools and techniques for single-cell RNA sequencing data",
    "section": "",
    "text": "CitationBibTeX citation:@phdthesis{zappia2019,\n  author = {Zappia, Luke},\n  editor = {Oshlack, Alicia and H Little, Melissa},\n  title = {Tools and Techniques for Single-Cell {RNA} Sequencing Data},\n  date = {2019-08-12},\n  url = {https://lazappi.id.au/publications/2019-zappia-thesis/},\n  doi = {10.1136/gutjnl-2016-311447},\n  langid = {en},\n  abstract = {RNA sequencing of individual cells allows us to take a\n    snapshot of the dynamic processes within a cell and explore\n    differences between cell types. As this technology has developed\n    over the last few years it has been rapidly adopted by researchers\n    in areas such as developmental biology, and many single-cell RNA\n    sequencing datasets are now available. Coinciding with the\n    development of protocols for producing single-cell RNA sequencing\n    data there has been a simultaneous burst in the development of\n    computational analysis methods. My thesis explores the computational\n    tools and techniques for analysing single-cell RNA sequencing data.\n    I present a database that charts the release of analysis software,\n    where it has been published and what it can be used for, as well as\n    a website that makes this information publicly available. I also\n    present two of my own tools and techniques including Splatter, a\n    software package for easily simulating single-cell datasets from\n    multiple models, and clustering trees, a visualisation approach for\n    inspecting clustering at multiple resolutions. In the final part of\n    my thesis I perform analysis of a dataset from kidney organoids to\n    demonstrate and compare some current analysis methods. Taken\n    together, my thesis covers many aspects of the tools and techniques\n    for single-cell RNA sequencing by describing the approaches that are\n    available, presenting software that can help in developing and\n    evaluating methods, introducing an approach for aiding one of the\n    most common analysis tasks, and showing how tools can be used to\n    extract meaning from a real dataset.}\n}\nFor attribution, please cite this work as:\nZappia, Luke. 2019. ‚ÄúTools and Techniques for Single-Cell RNA\nSequencing Data.‚Äù Edited by Alicia Oshlack and Melissa H Little.\nhttps://doi.org/10.1136/gutjnl-2016-311447."
  },
  {
    "objectID": "publications/2023-sikkema-HLCA/index.html",
    "href": "publications/2023-sikkema-HLCA/index.html",
    "title": "An integrated cell atlas of the lung in health and disease",
    "section": "",
    "text": "CitationBibTeX citation:@article{sikkema2023,\n  author = {Sikkema, Lisa and Ram√≠rez-Su√°stegui, Ciro and C. Strobl,\n    Daniel and E. Gillett, Tessa and Zappia, Luke and Madissoon, Elo and\n    S. Markov, Nikolay and Zaragosi, Laure-Emmanuelle and Ji, Yuge and\n    Ansari, Meshal and Arguel, Marie-Jeanne and Apperloo, Leonie and\n    Banchero, Martin and B√©cavin, Christophe and Berg, Marijn and\n    Chichelnitskiy, Evgeny and Chung, Mei-i and Collin, Antoine and C.\n    A. Gay, Aurore and Gote-Schniering, Janine and Hooshiar Kashani,\n    Baharak and Inecik, Kemal and Jain, Manu and S. Kapellos, Theodore\n    and M. Kole, Tessa and Leroy, Sylvie and H. Mayr, Christoph and J.\n    Oliver, Amanda and von Papen, Michael and Peter, Lance and J.\n    Taylor, Chase and Walzthoeni, Thomas and Xu, Chuan and T. Bui, Linh\n    and De Donno, Carlo and Dony, Leander and Faiz, Alen and Guo, Minzhe\n    and J. Gutierrez, Austin and Heumos, Lukas and Huang, Ni and L.\n    Ibarra, Ignacio and D. Jackson, Nathan and Kadur Lakshminarasimha\n    Murthy, Preetish and Lotfollahi, Mohammad and Tabib, Tracy and\n    Talavera-L√≥pez, Carlos and J. Travaglini, Kyle and Wilbrey-Clark,\n    Anna and B. Worlock, Kaylee and Yoshida, Masahiro and Biological\n    Network Consortium, Lung and van den Berge, Maarten and Boss√©, Yohan\n    and J. Desai, Tushar and Eickelberg, Oliver and Kaminski, Naftali\n    and A. Krasnow, Mark and Lafyatis, Robert and Z. Nikolic, Marko and\n    E. Powell, Joseph and Rajagopal, Jayaraj and Rojas, Mauricio and\n    Rozenblatt-Rosen, Orit and A. Seibold, Max and Sheppard, Dean and P.\n    Shepherd, Douglas and D. Sin, Don and Timens, Wim and M. Tsankov,\n    Alexander and Whitsett, Jeffrey and Xu, Yan and E. Banovich,\n    Nicholas and Barbry, Pascal and Elizabeth Duong, Thu and S. Falk,\n    Christine and B. Meyer, Kerstin and A. Kropski, Jonathan and Pe‚Äôer,\n    Dana and B. Schiller, Herbert and Rao Tata, Purushothama and L.\n    Schultze, Joachim and A. Teichmann, Sara and V. Misharin, Alexander\n    and C. Nawijn, Martijn and D. Luecken, Malte and J. Theis, Fabian},\n  title = {An Integrated Cell Atlas of the Lung in Health and Disease},\n  journal = {Nature Medicine},\n  volume = {29},\n  number = {6},\n  pages = {1563-1577},\n  date = {2023-08-06},\n  url = {https://lazappi.id.au/publications/2023-sikkema-HLCA/},\n  doi = {10.1038/s41591-023-02327-2},\n  issn = {1078-8956},\n  langid = {en},\n  abstract = {Single-cell technologies have transformed our\n    understanding of human tissues. Yet, studies typically capture only\n    a limited number of donors and disagree on cell type definitions.\n    Integrating many single-cell datasets can address these limitations\n    of individual studies and capture the variability present in the\n    population. Here we present the integrated Human Lung Cell Atlas\n    (HLCA), combining 49 datasets of the human respiratory system into a\n    single atlas spanning over 2.4 million cells from 486 individuals.\n    The HLCA presents a consensus cell type re-annotation with matching\n    marker genes, including annotations of rare and previously\n    undescribed cell types. Leveraging the number and diversity of\n    individuals in the HLCA, we identify gene modules that are\n    associated with demographic covariates such as age, sex and body\n    mass index, as well as gene modules changing expression along the\n    proximal-to-distal axis of the bronchial tree. Mapping new data to\n    the HLCA enables rapid data annotation and interpretation. Using the\n    HLCA as a reference for the study of disease, we identify shared\n    cell states across multiple lung diseases, including SPP1+\n    profibrotic monocyte-derived macrophages in COVID-19, pulmonary\n    fibrosis and lung carcinoma. Overall, the HLCA serves as an example\n    for the development and use of large-scale, cross-dataset organ\n    atlases within the Human Cell Atlas.}\n}\nFor attribution, please cite this work as:\nSikkema, Lisa, Ciro Ram√≠rez-Su√°stegui, Daniel C. Strobl, Tessa E.\nGillett, Luke Zappia, Elo Madissoon, Nikolay S. Markov, et al. 2023.\n‚ÄúAn Integrated Cell Atlas of the Lung in Health and\nDisease.‚Äù Nature Medicine 29 (6): 1563‚Äì77. https://doi.org/10.1038/s41591-023-02327-2."
  },
  {
    "objectID": "publications/2017-zappia-splatter/index.html",
    "href": "publications/2017-zappia-splatter/index.html",
    "title": "Splatter: simulation of single-cell RNA sequencing data",
    "section": "",
    "text": "CitationBibTeX citation:@article{zappia2017,\n  author = {Zappia, Luke and Phipson, Belinda and Oshlack, Alicia},\n  title = {Splatter: Simulation of Single-Cell {RNA} Sequencing Data},\n  journal = {Genome Biology},\n  volume = {18},\n  number = {1},\n  pages = {174},\n  date = {2017-09-01},\n  url = {https://lazappi.id.au/publications/2017-zappia-splatter/},\n  doi = {10.1186/s13059-017-1305-0},\n  issn = {1465-6906, 1474-760X},\n  langid = {en},\n  abstract = {As single-cell RNA sequencing (scRNA-seq) technologies\n    have rapidly developed, so have analysis methods. Many methods have\n    been tested, developed, and validated using simulated datasets.\n    Unfortunately, current simulations are often poorly documented,\n    their similarity to real data is not demonstrated, or reproducible\n    code is not available. Here, we present the Splatter Bioconductor\n    package for simple, reproducible, and well-documented simulation of\n    scRNA-seq data. Splatter provides an interface to multiple\n    simulation methods including Splat, our own simulation, based on a\n    gamma-Poisson distribution. Splat can simulate single populations of\n    cells, populations with multiple cell types, or differentiation\n    paths.}\n}\nFor attribution, please cite this work as:\nZappia, Luke, Belinda Phipson, and Alicia Oshlack. 2017.\n‚ÄúSplatter: Simulation of Single-Cell RNA Sequencing Data.‚Äù\nGenome Biology 18 (September): 174. https://doi.org/10.1186/s13059-017-1305-0."
  },
  {
    "objectID": "publications/2019-combes-mouse-kidney/index.html",
    "href": "publications/2019-combes-mouse-kidney/index.html",
    "title": "Single cell analysis of the developing mouse kidney provides deeper insight into marker gene expression and ligand-receptor crosstalk",
    "section": "",
    "text": "CitationBibTeX citation:@article{n_combes2019,\n  author = {N Combes, Alexander and Phipson, Belinda and T Lawlor, Kynan\n    and Dorison, Aude and Patrick, Ralph and Zappia, Luke and P Harvey,\n    Richard and Oshlack, Alicia and H Little, Melissa},\n  title = {Single Cell Analysis of the Developing Mouse Kidney Provides\n    Deeper Insight into Marker Gene Expression and Ligand-Receptor\n    Crosstalk},\n  journal = {Development},\n  volume = {146},\n  number = {12},\n  date = {2019-06-01},\n  url = {https://lazappi.id.au/publications/2019-combes-mouse-kidney/},\n  doi = {10.1242/dev.178673},\n  issn = {0950-1991, 1477-9129},\n  langid = {en},\n  abstract = {Recent advances in the generation of kidney organoids and\n    the culture of primary nephron progenitors from mouse and human have\n    been based on knowledge of the molecular basis of kidney development\n    in mice. Although gene expression during kidney development has been\n    intensely investigated, single cell profiling provides new\n    opportunities to further subsect component cell types and the\n    signalling networks at play. Here, we describe the generation and\n    analysis of 6732 single cell transcriptomes from the fetal mouse\n    kidney {[}embryonic day (E)18.5{]} and 7853 sorted nephron\n    progenitor cells (E14.5). These datasets provide improved resolution\n    of cell types and specific markers, including subdivision of the\n    renal stroma and heterogeneity within the nephron progenitor\n    population. Ligand-receptor interaction and pathway analysis reveals\n    novel crosstalk between cellular compartments and associates new\n    pathways with differentiation of nephron and ureteric epithelium\n    cell types. We identify transcriptional congruence between the\n    distal nephron and ureteric epithelium, showing that most markers\n    previously used to identify ureteric epithelium are not specific.\n    Together, this work improves our understanding of metanephric kidney\n    development and provides a template to guide the regeneration of\n    renal tissue.}\n}\nFor attribution, please cite this work as:\nN Combes, Alexander, Belinda Phipson, Kynan T Lawlor, Aude Dorison,\nRalph Patrick, Luke Zappia, Richard P Harvey, Alicia Oshlack, and\nMelissa H Little. 2019. ‚ÄúSingle Cell Analysis of the Developing\nMouse Kidney Provides Deeper Insight into Marker Gene Expression and\nLigand-Receptor Crosstalk.‚Äù Development 146 (June). https://doi.org/10.1242/dev.178673."
  },
  {
    "objectID": "publications/2018-zappia-clustree/index.html",
    "href": "publications/2018-zappia-clustree/index.html",
    "title": "Clustering trees: a visualization for evaluating clusterings at multiple resolutions",
    "section": "",
    "text": "CitationBibTeX citation:@article{zappia2018,\n  author = {Zappia, Luke and Oshlack, Alicia},\n  title = {Clustering Trees: A Visualization for Evaluating Clusterings\n    at Multiple Resolutions},\n  journal = {GigaScience},\n  volume = {7},\n  number = {7},\n  date = {2018-07-01},\n  url = {https://lazappi.id.au/publications/2018-zappia-clustree/},\n  doi = {10.1093/gigascience/giy083},\n  issn = {2047-217X},\n  langid = {en},\n  abstract = {Clustering techniques are widely used in the analysis of\n    large datasets to group together samples with similar properties.\n    For example, clustering is often used in the field of single-cell\n    RNA-sequencing in order to identify different cell types present in\n    a tissue sample. There are many algorithms for performing\n    clustering, and the results can vary substantially. In particular,\n    the number of groups present in a dataset is often unknown, and the\n    number of clusters identified by an algorithm can change based on\n    the parameters used. To explore and examine the impact of varying\n    clustering resolution, we present clustering trees. This\n    visualization shows the relationships between clusters at multiple\n    resolutions, allowing researchers to see how samples move as the\n    number of clusters increases. In addition, meta-information can be\n    overlaid on the tree to inform the choice of resolution and guide in\n    identification of clusters. We illustrate the features of clustering\n    trees using a series of simulations as well as two real examples,\n    the classical iris dataset and a complex single-cell RNA-sequencing\n    dataset. Clustering trees can be produced using the clustree R\n    package, available from CRAN and developed on GitHub.}\n}\nFor attribution, please cite this work as:\nZappia, Luke, and Alicia Oshlack. 2018. ‚ÄúClustering Trees: A\nVisualization for Evaluating Clusterings at Multiple\nResolutions.‚Äù GigaScience 7 (July). https://doi.org/10.1093/gigascience/giy083."
  },
  {
    "objectID": "projects/nba-positions/index.html",
    "href": "projects/nba-positions/index.html",
    "title": "NBA positions",
    "section": "",
    "text": "This repository contains the NBA positions dataset. The main dataset is designed to replace the iris dataset and contains basic statistics about 150 NBA Centers, Point Guards and Shooting Guards from 2017. There is a also a expanded dataset (nba_positions_full) the includes the same statistics for all NBA players in 2017."
  },
  {
    "objectID": "projects/single-cell-best-practices/index.html",
    "href": "projects/single-cell-best-practices/index.html",
    "title": "Single-cell best practices",
    "section": "",
    "text": "Single-cell best practices is an online book that attempts to draw together established best practices for multiomic single-cell analysis, including extensive tutorials and code examples. It is not limited to any particular tools or platforms but instead tries to promote the best performing approaches for different tasks as determined by independent projects. This is intended to be a living resource that will be updated as best practices evole with contributions of all kinds welcome from the community. I was part of the team involved in planning the project within the Theis lab and have written the integration and interoperability chapters as well as contibuting to other parts of the book."
  },
  {
    "objectID": "projects/zellkonverter/index.html",
    "href": "projects/zellkonverter/index.html",
    "title": "zellkonverter",
    "section": "",
    "text": "zellkonverter is a Bioconductor R package that provides methods to convert between Python AnnData objects and SingleCellExperiment objects (https://bioconductor.org/packages/zellkonveter/). These are primarily intended for use by downstream Bioconductor packages that wrap Python methods for single-cell data analysis. It also includes functions to read and write H5AD files used for saving AnnData objects to disk."
  },
  {
    "objectID": "projects/open-problems-single-cell/index.html",
    "href": "projects/open-problems-single-cell/index.html",
    "title": "Open Problems in Single-Cell Analysis",
    "section": "",
    "text": "The ability to profile individual cells has revolutionised biological research but analysing this data is complex and there are now thousands of analysis tools available. Benchmarking studies provide a valuable insight into how tools perform at various tasks but have an inherent limitation in that they only capture a snapshot of the analysis landscape at a given time. Open Problems aims to define a set of standard problems in single-cell analysis and transform them into a living benchmark, inspired by standard tasks in maching learning fields. This relies on a community driven approach where tasks are defined by the community, methods, metrics and datasets are contributed and results are provided to help guide analysis decisions and inspire the development of new approaches. I participated in the jamboree in 2021 where I became the leader for the dimensionality reduction for 2D visualisation task. This involves coordinating code contributions to the task, as well as contributing to the overall project."
  },
  {
    "objectID": "projects/index.html",
    "href": "projects/index.html",
    "title": "Projects",
    "section": "",
    "text": "single-cell\n\n\nrna-seq\n\n\nsimulation\n\n\nsoftware\n\n\nR\n\n\nBioconductor\n\n\n\nBioconductor R package for simulating scRNA-seq data\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nsingle-cell\n\n\nrna-seq\n\n\ninteroperability\n\n\nsoftware\n\n\nR\n\n\nBioconductor\n\n\n\nBioconductor R package for converting between scRNA-seq objects\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nclustering\n\n\nvisualisation\n\n\nsoftware\n\n\nR\n\n\n\nCRAN R package for creating clustering trees, a visualisation for looking at clustering across resolutions\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntwitter\n\n\nanalysis\n\n\nsoftware\n\n\nR\n\n\n\nAn R package for setting up a website to display analysis of Twitter hashtags\n\n\n\n\n\n\n\n\n\n\n\n\n\nsoftware\n\n\nR\n\n\n\nAn R package for linking DOIs between preprints and publications\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nsoftware\n\n\npython\n\n\n\nA Python script for pretty printing of TeXcount output\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nsoftware\n\n\npython\n\n\norganisation\n\n\n\nA Python script for tidying directories\n\n\n\n\n\n\n\nNo matching items\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nanalysis\n\n\nhousing\n\n\npython\n\n\n\nSome basic analysis of housing data from the OECD performed in Python\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nvisualisation\n\n\nR\n\n\n\nFunctions for scraping git commits from repositories associated with a PhD (or anything else) and plotting them\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nwebsite\n\n\ntwitter\n\n\nanalysis\n\n\nR\n\n\n\nAnalysis of Twitter activity for hashtags from various events, usually academic conferences\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ndataset\n\n\n\nA dataset of NBA positions designed to replace the iris dataset\n\n\n\n\n\n\n\nNo matching items\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nsingle-cell\n\n\nrna-seq\n\n\ndatabase\n\n\nwebsite\n\n\n\nDatabase and website cataloguing software tools for analysing single-cell RNA sequencing data\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nsingle-cell\n\n\nrna-seq\n\n\ndatabase\n\n\nwebsite\n\n\nJavaScript\n\n\n\nA website built using Vue for viewing the sfaira database\n\n\n\n\n\n\n\nNo matching items\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nbenchmarking\n\n\nsingle-cell\n\n\nwebsite\n\n\n\nAn effort to formalise and benchmark open problems in single-cell genomics analysis\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nsingle-cell\n\n\nanalysis\n\n\nmultiomics\n\n\nbest practices\n\n\nbook\n\n\n\nAn online book covering the best practices for multiomic single-cell analysis with extensive tutorials and code examples\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nsingle-cell\n\n\nrna-seq\n\n\ninteroperability\n\n\npython\n\n\nscanpy\n\n\nR\n\n\ntutorial\n\n\n\nTutorial describing how to interact with the Scanpy Python package from R\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nworkshop\n\n\npackage development\n\n\nR\n\n\ntraining\n\n\n\nMaterials for the COMBINE Australia R package development workshop\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "projects/index.html#analysis-and-data",
    "href": "projects/index.html#analysis-and-data",
    "title": "Projects",
    "section": "",
    "text": "analysis\n\n\nhousing\n\n\npython\n\n\n\nSome basic analysis of housing data from the OECD performed in Python\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nvisualisation\n\n\nR\n\n\n\nFunctions for scraping git commits from repositories associated with a PhD (or anything else) and plotting them\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nwebsite\n\n\ntwitter\n\n\nanalysis\n\n\nR\n\n\n\nAnalysis of Twitter activity for hashtags from various events, usually academic conferences\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ndataset\n\n\n\nA dataset of NBA positions designed to replace the iris dataset\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "projects/index.html#web",
    "href": "projects/index.html#web",
    "title": "Projects",
    "section": "",
    "text": "single-cell\n\n\nrna-seq\n\n\ndatabase\n\n\nwebsite\n\n\n\nDatabase and website cataloguing software tools for analysing single-cell RNA sequencing data\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nsingle-cell\n\n\nrna-seq\n\n\ndatabase\n\n\nwebsite\n\n\nJavaScript\n\n\n\nA website built using Vue for viewing the sfaira database\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "projects/index.html#community-and-training",
    "href": "projects/index.html#community-and-training",
    "title": "Projects",
    "section": "",
    "text": "benchmarking\n\n\nsingle-cell\n\n\nwebsite\n\n\n\nAn effort to formalise and benchmark open problems in single-cell genomics analysis\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nsingle-cell\n\n\nanalysis\n\n\nmultiomics\n\n\nbest practices\n\n\nbook\n\n\n\nAn online book covering the best practices for multiomic single-cell analysis with extensive tutorials and code examples\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nsingle-cell\n\n\nrna-seq\n\n\ninteroperability\n\n\npython\n\n\nscanpy\n\n\nR\n\n\ntutorial\n\n\n\nTutorial describing how to interact with the Scanpy Python package from R\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nworkshop\n\n\npackage development\n\n\nR\n\n\ntraining\n\n\n\nMaterials for the COMBINE Australia R package development workshop\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "projects/clustree/index.html",
    "href": "projects/clustree/index.html",
    "title": "clustree",
    "section": "",
    "text": "Deciding what resolution to use can be a difficult question when approaching a clustering analysis. One way to approach this problem is to look at how samples move as the number of clusters increases. The clustree package is available from CRAN (https://cran.r-project.org/package=clustree) and allows you to produce clustering trees, a visualisation for interrogating clusterings as resolution increases."
  },
  {
    "objectID": "projects/Splatter/index.html",
    "href": "projects/Splatter/index.html",
    "title": "Splatter",
    "section": "",
    "text": "Splatter is a Bioconductor R package for the simulation of single-cell RNA sequencing count data (https://bioconductor.org/packages/splatter/). It provides a simple interface for creating complex simulations that are reproducible and well-documented. Parameters can be estimated from real data and functions are provided for comparing real and simulated datasets."
  },
  {
    "objectID": "projects/sfaira-portal/index.html",
    "href": "projects/sfaira-portal/index.html",
    "title": "sfaira portal",
    "section": "",
    "text": "sfaira is a single-cell data zoo for public data sets paired with a model zoo for executable pre-trained models. The sfaira portal is a website displaying the datasets available through sfaira with an easy-to-use interactive interface. The interface allows users to search for datasets using metadata such as organism, tissue, cell type labels, source, assay or publication date. sfaira portal was built using the Vue JavaScript framework."
  },
  {
    "objectID": "projects/phd-commits/index.html",
    "href": "projects/phd-commits/index.html",
    "title": "PhD commits",
    "section": "",
    "text": "R scripts that can be used to scrape the git commit history of a project. The commits can then be categorised and used to produce a animated plot of the project over time as shown below. This was originally created as a way of displaying activity of my PhD but could be used for any project."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Luke Zappia",
    "section": "",
    "text": "Hi, I‚Äôm Luke üëãüèª\nI am a data scientist, software engineer and bioinformation with an interest in interoperabilty, reproducible pipelines data visualisation.\nI was previously a postdoctoral researcher in the Theis Lab at the Helmholtz Munich Institute of Computational Biology and the Technische Universit√§t M√ºnchen and completed my PhD in the Oshlack Lab in Melbourne, Australia. My academic research focused on the analysis of single-cell RNA sequencing data including the development and benchmarking of computational methods.\nCheck out my posts, projects and publications to find out more about me and my work!"
  }
]